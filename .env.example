# Configuration PostgreSQL
POSTGRES_USER=mnemo
POSTGRES_PASSWORD= # METTRE_VOTRE_MOT_DE_PASSE_ICI
POSTGRES_DB=mnemolite
POSTGRES_PORT=5432 # Port interne PostgreSQL

# Configuration API
API_PORT=8001 # Port externe expos√© par Docker
SECRET_KEY= # GENERER_UNE_CLE_SECRETE_FORTE
DEBUG=True
ENVIRONMENT=development # Options: development, productionet celui 
LOG_LEVEL=INFO # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# Local Embedding Model Configuration (Sentence-Transformers)
# Dual embedding strategy: TEXT model + CODE model

# TEXT Model Options (768 dims, Apache 2.0, 100% local inference):
#
# Option 1: nomic-ai/nomic-embed-text-v1.5 (default)
#   - 137M params, MTEB ~65, fast on CPU
#   - Good general-purpose English embeddings
#
# Option 2: intfloat/multilingual-e5-base (RECOMMENDED for French)
#   - 278M params, MTEB ~58, +30% better French quality
#   - Requires "query: " and "passage: " prefixes (handled automatically)
#   - Best choice for multilingual content
#
# Option 3: intfloat/multilingual-e5-small (fast multilingual)
#   - 118M params, 384D dimension (requires EMBEDDING_DIMENSION=384)
#   - Fastest multilingual option
#
EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5
# EMBEDDING_MODEL=intfloat/multilingual-e5-base  # Better French support

# CODE Model: jinaai/jina-embeddings-v2-base-code (768 dims, Apache 2.0)
# - For: Source code, functions, classes
# - Specialized for code similarity and search
# - 100% local inference
CODE_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code

# Embedding dimension (must be 768 for both models)
EMBEDDING_DIMENSION=768

# EPIC-24 P2: Cross-encoder Reranking (optional, +20-30% quality)
# Reranker improves search quality by scoring query-document pairs directly.
# Options:
#   - cross-encoder/ms-marco-MiniLM-L-6-v2 (default, 22M params, fast)
#   - BAAI/bge-reranker-base (110M params, better quality, multilingual)
# RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2