# MnemoLite v2.0 - PrÃ©sentation HonnÃªte
## Un Projet Personnel d'Exploration Technique

---

## [Slide 1] ğŸ›ï¸ **MnemoLite v2.0**

```
     â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
     â•‘                                   â•‘
     â•‘         MnemoLite v2.0            â•‘
     â•‘   Un projet personnel             â•‘
     â•‘   d'embedding sur CPU             â•‘
     â•‘                                   â•‘
     â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ“ Projet perso (~1 semaine de dev)
    ğŸ’» Tourne sur CPU standard
    ğŸ”§ PostgreSQL + Python
```

**Ã€ dire** : "C'est un side project pour explorer les embeddings CPU"

---

## [Slide 2] ğŸ¯ **L'IdÃ©e de DÃ©part**

```
    Question Simple :

    "Peut-on faire de l'embedding et
     de la recherche sÃ©mantique sans GPU ?"

    Contexte :
    â€¢ Les GPUs coÃ»tent cher (2000â‚¬+)
    â€¢ Les APIs cloud aussi (300â‚¬/mois)
    â€¢ Pour un usage perso/PME, c'est overkill

    HypothÃ¨se :
    â€¢ Les modÃ¨les CPU rÃ©cents sont pas mal
    â€¢ PostgreSQL a pgvector maintenant
    â€¢ Voyons ce qu'on peut faire...
```

**Ã€ dire** : "J'ai voulu tester si c'Ã©tait faisable pour un usage modeste"

---

## [Slide 3] ğŸ”¬ **Ce Que J'ai Construit**

```
    MnemoLite = 2 modules :

    1. Agent Memory
       â€¢ Stocke des conversations
       â€¢ Recherche sÃ©mantique basique
       â€¢ Utilise pgvector

    2. Code Intelligence
       â€¢ Parse du code Python (surtout)
       â€¢ Construit un graphe de dÃ©pendances
       â€¢ Recherche dans le code

    Stack : FastAPI + PostgreSQL 18
    Temps : ~1 semaine (soirs et weekends)
```

**Ã€ dire** : "Rien de rÃ©volutionnaire, juste de l'assemblage intelligent"

---

## [Slide 4] ğŸ’¡ **Les Choix Techniques**

```
    ModÃ¨le : nomic-embed-text-v1.5
    â€¢ 137M paramÃ¨tres (petit)
    â€¢ OptimisÃ© CPU (ONNX)
    â€¢ 768 dimensions
    â€¢ Gratuit et open source

    Base : PostgreSQL 18
    â€¢ pgvector pour les embeddings
    â€¢ pg_trgm pour le texte
    â€¢ CTEs pour les graphes

    Pas de magie, juste des outils existants
```

**Ã€ dire** : "J'ai pris des briques qui existent et je les ai assemblÃ©es"

---

## [Slide 5] ğŸ“Š **Les RÃ©sultats (HonnÃªtes)**

```
    Ce qui marche bien :
    âœ“ Recherche sÃ©mantique : ~11ms
    âœ“ Embeddings : 50-100/sec sur mon laptop
    âœ“ Graphe de code : 0.155ms*
    âœ“ Pas besoin de GPU

    * Le 0.155ms c'est parce que :
    - Le graphe est petit (14 fichiers)
    - Tout est en cache PostgreSQL
    - La requÃªte est simple

    C'est pas un "record", c'est normal
```

**Ã€ dire** : "Les perfs sont correctes pour un usage lÃ©ger"

---

## [Slide 6] âš ï¸ **Les Vraies Limitations**

```
    Soyons clairs :

    âŒ Pas "production ready" (1 semaine de dev!)
    âŒ Single-instance only (pas de Redis)
    âŒ Python bien supportÃ©, le reste bof
    âŒ 4GB RAM minimum quand mÃªme
    âŒ TestÃ© sur quelques milliers d'items max
    âŒ Pas comparable Ã  OpenAI/Claude

    C'est un POC qui fonctionne,
    pas un produit fini
```

**Ã€ dire** : "C'est un projet perso, pas une solution entreprise"

---

## [Slide 7] ğŸ¯ **Pour Qui C'est Utile ?**

```
    Cas d'usage rÃ©alistes :

    âœ“ Side projects personnels
    âœ“ PME avec <1000 docs
    âœ“ Prototypes/POCs
    âœ“ Apprentissage/ExpÃ©rimentation

    PAS pour :
    âœ— Production critique
    âœ— Millions de documents
    âœ— Multi-utilisateurs intensif
    âœ— Remplacement d'OpenAI
```

**Ã€ dire** : "Si vous avez un petit projet, Ã§a peut servir"

---

## [Slide 8] ğŸ’» **DÃ©mo Rapide**

```
    Ce que Ã§a fait concrÃ¨tement :

    1. Stocke du texte
    2. Le transforme en vecteurs (CPU)
    3. Cherche par similaritÃ©
    4. Retourne des rÃ©sultats

    [Montrer l'interface]

    C'est basique mais Ã§a marche
```

**Ã€ dire** : "VoilÃ , pas de magie"

---

## [Slide 9] ğŸ”§ **Le Code (Simple)**

```python
# C'est vraiment pas compliquÃ©
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('nomic-embed-text-v1.5')
embedding = model.encode("votre texte")

# PostgreSQL fait le reste
SELECT * FROM events
WHERE embedding <-> %s < 0.8
ORDER BY embedding <-> %s
LIMIT 10;
```

**Ã€ dire** : "200 lignes de Python, le reste c'est PostgreSQL"

---

## [Slide 10] ğŸ“ˆ **Ce Que J'ai Appris**

```
    LeÃ§ons du projet :

    1. Les modÃ¨les CPU sont utilisables
       (pour des usages modestes)

    2. PostgreSQL + pgvector = combo solide

    3. Pas besoin de GPU pour explorer

    4. HTMX c'est vraiment simple

    5. 1 semaine = POC fonctionnel
```

**Ã€ dire** : "C'Ã©tait surtout pour apprendre"

---

## [Slide 11] ğŸ¤” **Comparaison RÃ©aliste**

```
    MnemoLite          vs      Solutions Pro
    â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Gratuit                    300â‚¬/mois
    11ms (local)               100ms (rÃ©seau)
    CPU 65W                    GPU 450W
    1 semaine dev              Ã‰quipes entiÃ¨res

    MAIS :

    CapacitÃ© limitÃ©e    vs     Scale infini
    Single-user         vs     Multi-tenant
    POC                 vs     Production
```

**Ã€ dire** : "Comparons ce qui est comparable"

---

## [Slide 12] ğŸš€ **Si Vous Voulez Essayer**

```bash
# C'est open source
git clone https://github.com/.../mnemolite
cd mnemolite
make up

# 2 minutes et Ã§a tourne

# Mais attention :
# - C'est un projet perso
# - Support limitÃ©
# - Bugs probables
```

**Ã€ dire** : "C'est dispo si Ã§a intÃ©resse quelqu'un"

---

## [Slide 13] ğŸ› ï¸ **Stack Technique DÃ©taillÃ©**

```
    Pour les curieux :

    â€¢ FastAPI (API REST)
    â€¢ PostgreSQL 18 + pgvector
    â€¢ SQLAlchemy Core (async)
    â€¢ Sentence-Transformers
    â€¢ tree-sitter (parsing Python)
    â€¢ HTMX 2.0 (interface web)
    â€¢ Docker Compose

    Rien d'exotique, que du standard
```

**Ã€ dire** : "Technologies mainstream, pas de rocket science"

---

## [Slide 14] ğŸ“Š **Les "245 Tests"**

```
    Oui il y a 245 tests MAIS :

    â€¢ Ã‰crits en 1 semaine
    â€¢ Coverage partiel
    â€¢ Pas de tests de charge
    â€¢ Pas de tests de sÃ©curitÃ©
    â€¢ Juste des tests unitaires/intÃ©gration

    C'est mieux que rien,
    mais c'est pas une certification
```

**Ã€ dire** : "Les tests c'est bien, mais restons modestes"

---

## [Slide 15] ğŸ“ **Aspects IntÃ©ressants**

```
    Ce qui peut vous intÃ©resser :

    1. Comment utiliser pgvector
    2. Embeddings CPU avec ONNX
    3. CTEs rÃ©cursives pour graphes
    4. HTMX sans JavaScript
    5. Architecture Repository Pattern

    Le code est dispo pour apprendre
```

**Ã€ dire** : "Si Ã§a peut aider quelqu'un Ã  apprendre"

---

## [Slide 16] ğŸ’­ **AmÃ©liorations Possibles**

```
    Si c'Ã©tait Ã  refaire / continuer :

    â€¢ Ajouter Redis pour le cache
    â€¢ Support multi-langages correct
    â€¢ Interface plus polie
    â€¢ Tests de charge sÃ©rieux
    â€¢ Documentation utilisateur
    â€¢ CI/CD propre

    Mais bon, 1 semaine...
```

**Ã€ dire** : "Il y a plein de choses Ã  amÃ©liorer"

---

## [Slide 17] ğŸ¤ **Contribution**

```
    Si Ã§a intÃ©resse quelqu'un :

    â€¢ Le code est sur GitHub
    â€¢ MIT License
    â€¢ PRs bienvenues
    â€¢ Issues aussi

    Pas de promesses de support,
    c'est un projet perso
```

**Ã€ dire** : "Si quelqu'un veut forker ou contribuer"

---

## [Slide 18] ğŸ“ **Le Vrai Message**

```
    Ce que je voulais prouver :

    "On peut faire des trucs sympas
     avec un CPU et PostgreSQL"

    Pas besoin de :
    â€¢ GPU Ã  2000â‚¬
    â€¢ Cloud Ã  300â‚¬/mois
    â€¢ Stack complexe

    Pour un usage modeste, Ã§a suffit
```

**Ã€ dire** : "L'idÃ©e c'Ã©tait de dÃ©mystifier"

---

## [Slide 19] ğŸ’¬ **Questions ?**

```
    Des questions ?

    (Rappel : c'est un projet d'1 semaine,
     soyez indulgents ğŸ˜…)
```

**Ã€ dire** : "N'hÃ©sitez pas mais gardez les expectations raisonnables"

---

## [Slide 20] ğŸ™ **Merci**

```
    MnemoLite v2.0

    Un projet personnel pour explorer
    les embeddings CPU et pgvector

    Pas rÃ©volutionnaire,
    mais Ã§a marche

    github.com/.../mnemolite
```

**Ã€ dire** : "Merci de votre attention"

---

# Notes pour le PrÃ©sentateur

## Ton de la PrÃ©sentation

- **Humble** : C'est un side project
- **HonnÃªte** : Sur les limitations
- **PÃ©dagogique** : Partager l'apprentissage
- **RÃ©aliste** : Sur les cas d'usage

## Messages ClÃ©s

1. "C'est faisable sur CPU pour des usages modestes"
2. "PostgreSQL + pgvector = combo intÃ©ressant"
3. "1 semaine = POC fonctionnel"
4. "Open source si Ã§a intÃ©resse"

## RÃ©ponses aux Questions

**"C'est vraiment production ready ?"**
> "Non, c'est 1 semaine de dev. C'est un POC qui fonctionne."

**"Ã‡a scale ?"**
> "TestÃ© jusqu'Ã  quelques milliers d'items. Au-delÃ , je ne sais pas."

**"Vs OpenAI ?"**
> "Pas comparable. OpenAI c'est pro, Ã§a c'est un projet perso."

**"Le 0.155ms ?"**
> "C'est sur 14 fichiers en cache. Rien d'extraordinaire."

## Ce qu'il NE FAUT PAS dire

- âŒ "RÃ©volutionnaire"
- âŒ "Production ready"
- âŒ "Remplace OpenAI"
- âŒ "Record de performance"
- âŒ "Solution entreprise"

## Ce qu'il FAUT dire

- âœ… "Projet personnel"
- âœ… "POC fonctionnel"
- âœ… "Pour apprendre"
- âœ… "Usage modeste"
- âœ… "1 semaine de dev"

---

**Le vrai message : "C'est possible de faire des embeddings sur CPU pour des petits projets. Voici comment."**