# MnemoLite ‚Äì Document d'Architecture (ARCH) d√©taill√©

> üìÖ **Derni√®re mise √† jour**: 2025-10-17
> üìù **Version**: v2.0.0
> ‚úÖ **Statut**: √Ä jour avec le code (PostgreSQL 18, Dual-Purpose System, Code Intelligence, Performance Optimizations)

## 1. Vue d'ensemble

MnemoLite v2.0.0 est un **syst√®me dual-purpose** combinant:
1. **Agent Memory** - M√©moire cognitive pour agents IA (√©v√©nements, recherche s√©mantique, graphe causal)
2. **Code Intelligence** - Indexation et recherche s√©mantique de code (AST parsing, dual embeddings, dependency graph)

L'architecture adopte une approche **CQRS cognitive et modulaire**, optimis√©e pour un d√©ploiement local. Elle repose **exclusivement sur PostgreSQL 18** avec ses extensions pour g√©rer:
- **Aspects relationnels** - Tables structur√©es (events, code_chunks, nodes, edges)
- **Aspects vectoriels** - Recherche s√©mantique via `pgvector` (HNSW indexes)
- **Partitionnement temporel** - `pg_partman` (mensuel, optionnel)
- **T√¢ches asynchrones** - Infrastructure `pgmq` (d√©sactiv√©e en Phase 3, mais disponible)
- **Graphe relationnel** - Graphes causaux (Agent Memory) et d√©pendances (Code Intelligence) via tables + CTE r√©cursives

L'interface utilisateur Web utilise **FastAPI + HTMX 2.0** pour une exp√©rience r√©active sans SPA complexe, avec un **design SCADA industriel** unifi√©.

**Performance Highlights (v2.0.0)**:
- **Agent Memory**: 245 tests passing, P95 search 11ms, throughput 100 req/s
- **Code Intelligence**: Graph traversal 0.155ms (129√ó faster than target), hybrid search <200ms P95
- **Optimizations**: Cache system (80%+ hit rate), connection pool 3 ‚Üí 20, image size -84%

---

## 2. Architecture logique d√©taill√©e

### Command Side (√âcriture)
```mermaid
flowchart TD
  CLI_API["CLI/API REST (FastAPI)"] --> WriteHandler["Write Handler"]
  WriteHandler --> Queue["pgmq Queue (Optionnel, via tembo-pgmq-python)"]
  Queue --> Worker["Ingestion/Async Worker"]
  WriteHandler --> DirectWrite["Write Directe (API -> Repo -> DB)"]
  
  subgraph PostgreSQL_18 ["(PostgreSQL 18)"]
    direction LR
    PG_Events[events Table]
    PG_Embeddings["embedding (vector column)"]
    PG_Graph[nodes/edges Tables]
    PG_Partitions["Partitions (pg_partman)"]
  end

  Worker --> PG_Events
  Worker --> PG_Embeddings
  Worker --> PG_Graph
  DirectWrite --> PG_Events
  DirectWrite --> PG_Embeddings
  DirectWrite --> PG_Graph
```
*Note: L'utilisation de `pgmq` et d'un worker est optionnelle pour un d√©couplage asynchrone, l'√©criture peut √™tre directe depuis l'API via les repositories.* 

### Query Side (Lecture)
```mermaid
flowchart TD
  UI["HTMX/Jinja2 UI"] --> FastAPI_Query["FastAPI Query Handler (Routes -> Services -> Repositories)"]
  
  subgraph PostgreSQL_18 ["(PostgreSQL 18)"]
     direction LR
     PG_VectorSearch["Recherche Vectorielle (pgvector HNSW)"]
     PG_SQLSearch["Recherche Relationnelle/Metadata"]
     PG_GraphSearch["Recherche Graph (CTE SQL)"]
  end

  FastAPI_Query --> PG_VectorSearch
  FastAPI_Query --> PG_SQLSearch
  FastAPI_Query --> PG_GraphSearch

  PG_VectorSearch --> Fusion["Fusion & Ranking (in Service/Repo)"]
  PG_SQLSearch --> Fusion
  PG_GraphSearch --> Fusion
  
  Fusion --> UI
```
*Toutes les recherches (vectorielle, SQL, graphe) sont initi√©es par l'API et ex√©cut√©es via les repositories directement dans PostgreSQL.*

### Couche Service et Auto-Embedding

**EventService** : Couche m√©tier introduite pour orchestrer la cr√©ation d'√©v√©nements avec g√©n√©ration automatique d'embeddings.

```mermaid
flowchart LR
  Route[Event Routes] --> EventService
  EventService --> EmbeddingService[Sentence-Transformers<br>nomic-embed-text-v1.5]
  EventService --> EventRepo[Event Repository]
  EventRepo --> PostgreSQL[(PostgreSQL)]

  style EventService fill:#e1f5fe
  style EmbeddingService fill:#fff3e0
```

**Fonctionnalit√©s** :
- **Auto-g√©n√©ration d'embeddings** : Si aucun embedding n'est fourni dans la requ√™te, EventService extrait automatiquement le texte depuis `content.text` (ou fields configurables) et g√©n√®re un embedding 768-dim via Sentence-Transformers
- **Configuration flexible** :
  - `EMBEDDING_AUTO_GENERATE` : active/d√©sactive la g√©n√©ration automatique (d√©faut: true)
  - `EMBEDDING_FAIL_STRATEGY` : `soft` (continue sans embedding) ou `hard` (√©choue la cr√©ation) (d√©faut: soft)
  - `EMBEDDING_SOURCE_FIELDS` : priorit√© des champs pour extraction de texte (d√©faut: `text,body,message,content,title`)
- **Fail-soft** : En cas d'√©chec de g√©n√©ration d'embedding, l'√©v√©nement est cr√©√© sans embedding (si `fail_strategy=soft`)
- **Injection de d√©pendances** : EventService inject√© via `Depends(get_event_service)` dans les routes

**Flux de cr√©ation** :
```
POST /v1/events
  ‚Üì
EventService.create_event()
  ‚Üì (si embedding absent)
EventService._extract_text_for_embedding()
  ‚Üì
EmbeddingService.generate_embedding(text)
  ‚Üì
EventRepository.add(event)
  ‚Üì
PostgreSQL INSERT
```

---

### Architecture Code Intelligence (EPIC-06/07)

MnemoLite v2.0.0 int√®gre un syst√®me complet d'intelligence de code permettant l'indexation, la recherche s√©mantique et l'analyse de d√©pendances de repositories de code.

#### Pipeline d'Indexation 7-Steps

```mermaid
flowchart LR
    Input["Code Files<br/>(Python, JS, Go, etc.)"] --> Step1["1. Language<br/>Detection"]
    Step1 --> Step2["2. AST Parsing<br/>(tree-sitter)"]
    Step2 --> Step3["3. Chunking<br/>(functions/classes)"]
    Step3 --> Step4["4. Metadata<br/>Extraction"]
    Step4 --> Step5["5. Dual Embedding<br/>(TEXT + CODE)"]
    Step5 --> Step6["6. Graph<br/>Construction"]
    Step6 --> Step7["7. Storage<br/>(PostgreSQL)"]
    Step7 --> Output["code_chunks<br/>+ nodes/edges"]

    style Step5 fill:#fff3cd
    style Step6 fill:#d1ecf1
    style Step7 fill:#d4edda
```

**Performance**: <100ms par fichier (pipeline complet)

#### Hybrid Code Search (Lexical + Vector + RRF)

```mermaid
flowchart TD
    Query["User Query:<br/>'calculate total'"] --> Parallel{"Parallel<br/>Search"}

    Parallel --> Lexical["Lexical Search<br/>(pg_trgm GIN)"]
    Parallel --> VectorText["Vector Search TEXT<br/>(HNSW 768D)"]
    Parallel --> VectorCode["Vector Search CODE<br/>(HNSW 768D)"]

    Lexical --> RRF["RRF Fusion<br/>(Reciprocal Rank)"]
    VectorText --> RRF
    VectorCode --> RRF

    RRF --> Results["Top-K Results<br/>(ranked)"]

    style Lexical fill:#e7f3ff
    style VectorText fill:#fff3cd
    style VectorCode fill:#ffd7a3
    style RRF fill:#d4edda
```

**Performance**: <200ms P95 (28√ó faster than 5s target)

#### Dependency Graph (Recursive CTEs)

```mermaid
flowchart TD
    Code["Source Code"] --> Parser["AST Parser<br/>(tree-sitter)"]
    Parser --> Extractor["Call Extractor"]
    Extractor --> Nodes["nodes table<br/>(functions/classes)"]
    Extractor --> Edges["edges table<br/>(calls/imports)"]

    Query["Traversal Query<br/>(max 3 hops)"] --> CTE["Recursive CTE"]
    Nodes --> CTE
    Edges --> CTE

    CTE --> Graph["Dependency Graph<br/>(0.155ms)"]

    style CTE fill:#d1ecf1
    style Graph fill:#d4edda
```

**Performance**: 0.155ms execution time (129√ó faster than 20ms target)

#### Services & Repositories

```mermaid
flowchart LR
    Routes["Code Routes<br/>/v1/code/*"] --> Services

    subgraph Services["Code Intelligence Services"]
        direction TB
        IndexService["CodeIndexService<br/>(7-step pipeline)"]
        SearchService["HybridSearchService<br/>(lexical+vector+RRF)"]
        GraphService["GraphConstructionService<br/>+ GraphTraversalService"]
    end

    Services --> Repos

    subgraph Repos["Repositories"]
        direction TB
        ChunkRepo["CodeChunkRepository<br/>(dual embeddings)"]
        GraphRepo["GraphRepository<br/>(nodes+edges)"]
    end

    Repos --> PG["PostgreSQL 18<br/>(code_chunks, nodes, edges)"]

    style Services fill:#e7f3ff
    style Repos fill:#fff3cd
    style PG fill:#d4edda
```

**Fonctionnalit√©s cl√©s**:
- **15+ langages support√©s** (Python, JavaScript, TypeScript, Go, Rust, Java, C++, etc.)
- **Dual embeddings** (TEXT 768D + CODE 768D) pour recherche s√©mantique
- **M√©tadonn√©es automatiques** (complexity, parameters, calls, imports, docstrings)
- **Graph queries** (calls, imports, inherits, contains) via CTEs r√©cursives
- **126 tests passing** (100% coverage services)

---

## 3. Mod√®le de donn√©es PostgreSQL

### Table `events`
```sql
-- Aligned with docs/bdd_schema.md v1.2.x
CREATE TABLE IF NOT EXISTS events (
    id          UUID NOT NULL DEFAULT gen_random_uuid(),
    timestamp   TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    content     JSONB NOT NULL,             -- Contenu flexible: { "type": "prompt", ... } ou { "type": "decision", ... }
    embedding   VECTOR(768),                -- Embedding (nomic-embed-text-v1.5)
    metadata    JSONB DEFAULT '{}'::jsonb,  -- Tags, source, IDs, types, etc.
    -- Cl√© primaire composite, incluant la cl√© de partitionnement
    PRIMARY KEY (id, timestamp)
)
PARTITION BY RANGE (timestamp);

COMMENT ON TABLE events IS 'Table principale stockant tous les evenements atomiques (partitionnee par mois sur timestamp).';
COMMENT ON COLUMN events.content IS 'Contenu detaille de l evenement au format JSONB.';
COMMENT ON COLUMN events.embedding IS 'Vecteur semantique du contenu (dimension 768 pour nomic-embed-text-v1.5).';
COMMENT ON COLUMN events.metadata IS 'Metadonnees additionnelles (tags, IDs, types) au format JSONB.';

-- Index B-tree sur timestamp (cl√© de partitionnement), h√©rit√© par les partitions
CREATE INDEX IF NOT EXISTS events_timestamp_idx ON events (timestamp);

-- Index GIN sur metadata pour recherches flexibles, h√©rit√© par les partitions
CREATE INDEX IF NOT EXISTS events_metadata_gin_idx ON events USING GIN (metadata jsonb_path_ops);

-- NOTE IMPORTANTE sur l'index vectoriel (HNSW/IVFFlat):
-- Il DOIT etre cree sur chaque partition individuelle, PAS sur la table mere.
-- Ceci est generalement gere via des hooks pg_partman ou des scripts de maintenance.
-- Exemple pour une partition 'events_pYYYY_MM':
-- CREATE INDEX CONCURRENTLY IF NOT EXISTS events_pYYYY_MM_embedding_hnsw_idx
-- ON events_pYYYY_MM USING hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64);
```
*Note: La gestion des index HNSW sur les partitions n√©cessite une attention particuli√®re (ex: via les fonctions hook de `pg_partman`).*

### Table `code_chunks` (Code Intelligence)

```sql
-- Code Intelligence: Stockage des chunks de code avec dual embeddings
CREATE TABLE IF NOT EXISTS code_chunks (
    chunk_id            UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    repository          TEXT NOT NULL,                  -- Nom du repository (ex: 'my-project')
    file_path           TEXT NOT NULL,                  -- Chemin relatif du fichier
    chunk_type          TEXT NOT NULL                   -- 'function', 'class', 'method', 'file'
                        CHECK (chunk_type IN ('function', 'class', 'method', 'file')),
    language            TEXT NOT NULL,                  -- 'python', 'javascript', 'go', etc.
    code_text           TEXT NOT NULL,                  -- Code source complet du chunk
    start_line          INTEGER,                        -- Ligne de d√©but dans le fichier
    end_line            INTEGER,                        -- Ligne de fin dans le fichier
    metadata            JSONB DEFAULT '{}'::jsonb,      -- M√©tadonn√©es: complexity, parameters, calls, imports, docstring
    embedding_text      VECTOR(768),                    -- Embedding TEXT (description s√©mantique)
    embedding_code      VECTOR(768),                    -- Embedding CODE (structure syntaxique)
    created_at          TIMESTAMPTZ DEFAULT NOW(),
    updated_at          TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE code_chunks IS 'Chunks de code indexes avec dual embeddings (TEXT + CODE).';
COMMENT ON COLUMN code_chunks.embedding_text IS 'Embedding TEXT: semantique naturelle du code (descriptions, commentaires).';
COMMENT ON COLUMN code_chunks.embedding_code IS 'Embedding CODE: structure syntaxique (AST, tokens).';
COMMENT ON COLUMN code_chunks.metadata IS 'Metadonnees extraites: complexity (cyclomatic), parameters, calls, imports, docstring.';

-- Index B-tree pour recherches par repository/file
CREATE INDEX IF NOT EXISTS code_chunks_repo_file_idx ON code_chunks (repository, file_path);
CREATE INDEX IF NOT EXISTS code_chunks_language_idx ON code_chunks (language);
CREATE INDEX IF NOT EXISTS code_chunks_type_idx ON code_chunks (chunk_type);

-- Index GIN pour recherche lexicale (pg_trgm)
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX IF NOT EXISTS code_chunks_text_gin_idx ON code_chunks USING GIN (code_text gin_trgm_ops);

-- Index HNSW pour recherche vectorielle (dual embeddings)
CREATE INDEX IF NOT EXISTS code_chunks_embedding_text_hnsw_idx
    ON code_chunks USING hnsw (embedding_text vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX IF NOT EXISTS code_chunks_embedding_code_hnsw_idx
    ON code_chunks USING hnsw (embedding_code vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);

-- Index GIN sur metadata pour recherches flexibles
CREATE INDEX IF NOT EXISTS code_chunks_metadata_gin_idx ON code_chunks USING GIN (metadata jsonb_path_ops);
```

*Note: Les dual embeddings permettent une recherche hybride combinant la s√©mantique naturelle (TEXT) et la structure syntaxique (CODE) pour des r√©sultats plus pertinents.*

### Tables `nodes` et `edges` (pour le graphe)
```sql
-- Aligned with docs/bdd_schema.md v1.2.x
CREATE TABLE IF NOT EXISTS nodes (
    node_id         UUID PRIMARY KEY, -- Generalement un event.id, mais peut etre autre chose (concept genere)
    node_type       TEXT NOT NULL,    -- Ex: 'event', 'concept', 'entity', 'rule', 'document'
    label           TEXT,             -- Nom lisible pour affichage/requete
    properties      JSONB DEFAULT '{}'::jsonb, -- Attributs additionnels du n≈ìud
    created_at      TIMESTAMPTZ DEFAULT NOW()
);
COMMENT ON TABLE nodes IS 'Noeuds du graphe conceptuel (evenements, concepts, entites).';

CREATE INDEX IF NOT EXISTS nodes_type_idx ON nodes(node_type);

CREATE TABLE IF NOT EXISTS edges (
    edge_id         UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_node_id  UUID NOT NULL, -- Reference logique nodes.node_id
    target_node_id  UUID NOT NULL, -- Reference logique nodes.node_id
    relation_type   TEXT NOT NULL, -- Ex: 'causes', 'mentions', 'related_to', 'follows', 'uses_tool', 'part_of'
    properties      JSONB DEFAULT '{}'::jsonb, -- Poids, timestamp de la relation, etc.
    created_at      TIMESTAMPTZ DEFAULT NOW()
);
COMMENT ON TABLE edges IS 'Relations (aretes) entre les noeuds du graphe conceptuel.';
COMMENT ON COLUMN edges.source_node_id IS 'ID du noeud source (pas de FK physique).';
COMMENT ON COLUMN edges.target_node_id IS 'ID du noeud cible (pas de FK physique).';

CREATE INDEX IF NOT EXISTS edges_source_idx ON edges(source_node_id);
CREATE INDEX IF NOT EXISTS edges_target_idx ON edges(target_node_id);
CREATE INDEX IF NOT EXISTS edges_relation_type_idx ON edges(relation_type);
```

**Usage Dual-Purpose** (Agent Memory + Code Intelligence):

1. **Agent Memory** - Graphe causal:
   - `node_type`: 'event', 'concept', 'entity', 'rule', 'document'
   - `relation_type`: 'causes', 'mentions', 'related_to', 'follows', 'uses_tool', 'part_of'
   - Exemple: `event_A --[causes]--> event_B`

2. **Code Intelligence** - Graphe de d√©pendances:
   - `node_type`: 'function', 'class', 'method', 'module'
   - `relation_type`: 'calls', 'imports', 'inherits', 'contains'
   - Exemple: `function_A --[calls]--> function_B --[imports]--> module_C`

**Interrogation**: CTEs r√©cursives (‚â§3 hops) pour les deux cas d'usage:
```sql
-- Exemple: Trouver toutes les fonctions appel√©es par function_X (max 3 hops)
WITH RECURSIVE call_chain AS (
    SELECT source_node_id, target_node_id, 1 AS depth
    FROM edges
    WHERE source_node_id = 'function_X_uuid' AND relation_type = 'calls'
    UNION ALL
    SELECT e.source_node_id, e.target_node_id, cc.depth + 1
    FROM edges e
    JOIN call_chain cc ON e.source_node_id = cc.target_node_id
    WHERE cc.depth < 3 AND e.relation_type = 'calls'
)
SELECT DISTINCT target_node_id FROM call_chain;
```
**Performance**: 0.155ms execution time (Code Intelligence), <100ms (Agent Memory)

*Note: La cr√©ation des n≈ìuds et des ar√™tes est g√©r√©e par la logique applicative. Pas de contraintes FK physiques sur edges pour flexibilit√©; coh√©rence g√©r√©e par l'application ou des checks p√©riodiques.*

### Autres tables (optionnelles)
*   `memory_types`, `event_types` : Pourraient √™tre cr√©√©es pour standardiser les types via cl√©s √©trang√®res si le besoin se confirme (actuellement g√©r√© via `metadata`).
*   Tables de configuration (si la configuration via `.env` n'est pas suffisante).

### Partitionnement Mensuel avec `pg_partman`
*   La table `events` est partitionn√©e par `RANGE` sur `timestamp`.
*   `pg_partman` est configur√© (`db/init/02-partman-config.sql`) pour cr√©er automatiquement les partitions mensuelles (ex: `events_p2025_05`).
*   Une politique de r√©tention (`retention` dans `part_config`) peut √™tre d√©finie pour supprimer/d√©tacher automatiquement les vieilles partitions (alternative au TTL par colonne).

---

## 4. Index vectoriel (`pgvector`)
*   **Stockage :** Directement dans la colonne `embedding VECTOR(768)` de la table `events` (ou ses partitions).
*   **Index :** **HNSW** (`USING hnsw`) est recommand√© pour l'√©quilibre vitesse/pr√©cision. `vector_cosine_ops` ou `vector_l2_ops` selon la m√©trique de distance utilis√©e par le mod√®le d'embedding.
*   **Gestion sur partitions :** L'index HNSW doit √™tre cr√©√© sur **chaque partition**. L'utilisation des fonctions `run_maintenance_proc()` de `pg_partman` avec des scripts personnalis√©s ou des fonctions trigger est la m√©thode recommand√©e pour automatiser la cr√©ation/maintenance des index sur les nouvelles partitions.
*   **Recherche :** Utilisation des op√©rateurs `<->` (distance L2), `<#>` (produit scalaire n√©gatif), ou `<=>` (distance cosinus) dans les requ√™tes SQL via les m√©thodes du repository.

---

## 5. Graphe mn√©sique (Tables + CTE SQL)
*   **Mod√®le :** Graphe de propri√©t√©s stock√© dans les tables `nodes` et `edges`.
*   **Cr√©ation :** La logique applicative (potentiellement dans un service ou worker d√©di√©) identifie les entit√©s ou concepts dans les `events` et cr√©e/lie les n≈ìuds et ar√™tes correspondants.
*   **Interrogation :** Utilisation de **Common Table Expressions (CTE) r√©cursives** en SQL pour explorer les relations sur une profondeur limit√©e (cible ‚â§ 3 sauts pour performance locale).
    ```sql
    -- Exemple : Trouver les √©v√©nements caus√©s par event_X (max 3 sauts)
    WITH RECURSIVE causal_chain AS (
        SELECT source_node_id, target_node_id, 1 AS depth
        FROM edges
        WHERE source_node_id = 'event_X_uuid' AND relation_type = 'causes'
        UNION ALL
        SELECT e.source_node_id, e.target_node_id, cc.depth + 1
        FROM edges e
        JOIN causal_chain cc ON e.source_node_id = cc.target_node_id
        WHERE cc.depth < 3 AND e.relation_type = 'causes'
    )
    SELECT target_node_id FROM causal_chain;
    ```
*   **Avantages :** Int√©gr√© √† PostgreSQL, transactionnel, utilise SQL standard.
*   **Limitations :** Moins performant que les bases de donn√©es graphe d√©di√©es pour des travers√©es tr√®s larges ou profondes, ou des algorithmes graphe complexes.

---

## 6. Coh√©rence & Cycle de vie des donn√©es (Local)

*   **Coh√©rence :** Assur√©e par les transactions PostgreSQL.
*   **Cycle de vie Hot/Warm simplifi√© :**
    *   **Partitionnement Mensuel :** G√©r√© par `pg_partman`.
    *   **Hot (0-12 mois) :** Partitions r√©centes, vecteurs FP32.
    *   **Warm (> 12 mois) :** Vecteurs quantis√©s en **INT8** par un job `pg_cron` (√† activer/configurer) pour √©conomiser l'espace disque. Le job cible les partitions de plus de 12 mois.
    *   **R√©tention :** Les vieilles partitions (> N mois/ann√©es, configurable dans `pg_partman`) peuvent √™tre d√©tach√©es ou supprim√©es pour g√©rer l'espace disque local.
    *   **Archivage Complexe Diff√©r√© :** Pas d'√©tape Cold (JSON) ou Archive (S3) initialement.

```mermaid
flowchart LR
  subgraph Partitions_Mensuelles
    P_M1[Mois 1]
    P_M2[Mois 2]
    P_Mdots[...]
    P_M12[Mois 12]
    P_M13[Mois 13]
    P_M14[Mois 14]
    P_Mdots2[...]
  end

  HotPartitions["Hot (0-12 mois)<br>Vecteur FP32"] --> P_M1
  HotPartitions --> P_M2
  HotPartitions --> P_Mdots
  HotPartitions --> P_M12
  
  WarmPartitions["Warm (> 12 mois)<br>Vecteur INT8"] --> P_M13
  WarmPartitions --> P_M14
  WarmPartitions --> P_Mdots2
  
  P_M12 -->|"pg_cron (&gt;12 mois)<br>Quantize INT8<br>(Needs activation)"| P_M13
  
  classDef hot fill:#fdebd0,stroke:#c8976c;
  classDef warm fill:#eaf2f8,stroke:#80a3bd;
  class HotPartitions,P_M1,P_M2,P_Mdots,P_M12 hot;
  class WarmPartitions,P_M13,P_M14,P_Mdots2 warm;
```
*   **Auditabilit√© :** Via logs applicatifs et potentiellement triggers PG sur modifications.
*   **Monitoring Local :** Focus sur les logs PostgreSQL, `pg_stat_statements`, `pg_stat_activity`, et les outils syst√®me (`htop`, `iotop`). Option via endpoint `/metrics` Prometheus.

---

## 7. D√©ploiement (Docker Compose Local)
```yaml
# Extrait simplifi√© et align√© sur le docker-compose.yml r√©el
# Voir docs/docker_setup.md pour la version compl√®te et comment√©e
version: '3.8'

services:
  db:
    build: ./db # Contient FROM pgvector/pgvector:pg18 et installe partman
    container_name: mnemo-postgres
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-mnemo}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mnemopass}
      POSTGRES_DB: ${POSTGRES_DB:-mnemolite}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d:ro # Scripts init SQL
    ports:
      - "127.0.0.1:${POSTGRES_PORT:-5432}:5432"
    healthcheck: # ... d√©fini dans le fichier r√©el
      # ...
    # ... autres configs (command, shm_size, networks, logging)

  api:
    build: .
    container_name: mnemo-api
    restart: unless-stopped
    ports:
      - "127.0.0.1:${API_PORT:-8001}:8000"
    environment:
      DATABASE_URL: "postgresql+asyncpg://${POSTGRES_USER:-mnemo}:${POSTGRES_PASSWORD:-mnemopass}@db:5432/${POSTGRES_DB:-mnemolite}"
      # ... autres env vars (EMBEDDING_MODEL, etc.)
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - ./api:/app # Montage pour dev
      # ... autres volumes (certs, tests, scripts, workers, logs, templates, static)
    deploy:
      resources:
        limits:
          cpus: '2'        # Increased for parallel embedding generation
          memory: 4G       # Increased for dual embeddings (TEXT + CODE)
    # ... autres configs (networks, logging, healthcheck)

  # Worker service DISABLED (Phase 3 consolidation)
  # All operations (embeddings, indexing) run synchronously in API
  # PGMQ infrastructure remains available for future async tasks if needed
  #
  # worker:
  #   build: .
  #   container_name: mnemo-worker
  #   restart: unless-stopped
  #   environment:
  #     DATABASE_URL: "postgresql://${POSTGRES_USER:-mnemo}:${POSTGRES_PASSWORD:-mnemopass}@db:5432/${POSTGRES_DB:-mnemolite}"
  #     # ... autres env vars
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #   volumes:
  #     - ./workers:/app
  #     # ... autres volumes (certs)
  #   # ... autres configs (networks, logging)

volumes:
  postgres_data:

networks:
  # ... (frontend, backend)

```
*Note : L'image Docker PostgreSQL (`db/Dockerfile`) doit inclure les extensions `pgvector` et `pg_partman`. `pgmq` est une d√©pendance Python (`tembo-pgmq-python`) utilis√©e par le worker, pas une extension PG √† installer ici.*

---

## 8. Risques & Mitigations (Local)

| Risque                        | Impact   | Mitigation                            |
|-------------------------------|----------|----------------------------------------|
| Recall‚Üì apr√®s INT8 quant.     | Moyen    | Validation locale (cible ‚â• 92%)        |
| Graphe CTE lent (> 3 sauts)   | Faible   | Confirmer besoin vs perf. locale      |
| **Sauvegarde locale √©choue**  | **√âlev√©**| Script `pg_dump` robuste, tests r√©guliers |
| Performance locale d√©grade    | Moyen    | Monitoring PG stats, optimisation conf |
| Gestion index sur partitions  | Moyen    | Automatisation via `pg_partman` hooks |
| Espace disque local insuffisant| Moyen    | Politique de r√©tention `pg_partman` agressive |
| `pg_cron` non activ√©/configur√© | Moyen    | Ajouter proc√©dure d'activation/test |

---

## 9. Performances attendues (Local)

*   **Recherche Vectorielle (Hot, k=10) :** ‚â§ 10 ms p95 (cible sur 10M vecteurs locaux).
*   **Recherche Vectorielle (Warm, k=10) :** ‚â§ 30 ms p95 (estimation apr√®s quantization).
*   **Requ√™tes Graphe (CTE ‚â§ 3 sauts) :** Variable, mais cible < 100ms sur donn√©es locales typiques.
*   **Ingestion :** D√©pend si directe ou via worker/pgmq, mais plusieurs centaines d'√©v√©nements/sec devraient √™tre atteignables localement.
*   **Optimisations cl√©s :** Tuning `postgresql.conf` pour la RAM locale, param√®tres HNSW (`ef_search`), batching c√¥t√© application si n√©cessaire.

---

## 10. Structure du projet (v2.0.0 - Align√©e)
```
mnemo-lite/
‚îú‚îÄ‚îÄ api/                # Code FastAPI (Agent Memory + Code Intelligence)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile      # Multi-stage build (1.92 GB, optimis√©)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ main.py         # Entry point + lifespan (connection pool, cache)
‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py # Dependency injection
‚îÇ   ‚îú‚îÄ‚îÄ db/             # Repositories SQLAlchemy Core + asyncpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py # Engine, connection pool (20 connections)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repositories/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ event_repository.py         # Agent Memory
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ code_chunk_repository.py    # Code Intelligence
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ graph_repository.py         # Nodes/Edges (dual-purpose)
‚îÇ   ‚îú‚îÄ‚îÄ interfaces/     # Protocol-based interfaces (DIP)
‚îÇ   ‚îú‚îÄ‚îÄ models/         # Pydantic models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code_chunk.py                   # NEW: EPIC-06
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph.py                        # NEW: EPIC-06
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ routes/         # FastAPI routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event_routes.py                 # Agent Memory: /v1/events/*
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_routes.py                # Agent Memory: /v1/search/*
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code_routes.py                  # NEW: Code Intelligence: /v1/code/*
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code_graph_routes.py            # NEW: Code Intelligence: /v1/code/graph/*
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health_routes.py                # /health, /metrics
‚îÇ   ‚îú‚îÄ‚îÄ services/       # Business logic services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event_service.py                # Agent Memory: event orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentence_transformer_embedding_service.py  # Embeddings (nomic-embed-text-v1.5)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_search_service.py        # Agent Memory: hybrid search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code_index_service.py           # NEW: 7-step indexing pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_search_service.py        # NEW: Lexical + Vector + RRF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_construction_service.py   # NEW: Build dependency graph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_traversal_service.py      # NEW: Recursive CTE traversal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ templates/      # Jinja2/HTMX 2.0 templates (SCADA design)
‚îÇ       ‚îú‚îÄ‚îÄ agent_memory/                   # Agent Memory UI
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dashboard.html
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ search.html
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ graph.html
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.html
‚îÇ       ‚îî‚îÄ‚îÄ code_intelligence/              # NEW: Code Intelligence UI (EPIC-07)
‚îÇ           ‚îú‚îÄ‚îÄ code_dashboard.html
‚îÇ           ‚îú‚îÄ‚îÄ repositories.html
‚îÇ           ‚îú‚îÄ‚îÄ code_search.html
‚îÇ           ‚îú‚îÄ‚îÄ dependency_graph.html
‚îÇ           ‚îî‚îÄ‚îÄ upload.html
‚îú‚îÄ‚îÄ db/                 # Configuration PostgreSQL 18
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile      # FROM pgvector/pgvector:pg18 + pg_partman
‚îÇ   ‚îî‚îÄ‚îÄ init/           # Scripts SQL d'initialisation
‚îÇ       ‚îú‚îÄ‚îÄ 01-extensions.sql               # pgvector, pg_trgm, pg_partman
‚îÇ       ‚îú‚îÄ‚îÄ 01-init.sql                     # tables: events, code_chunks, nodes, edges
‚îÇ       ‚îî‚îÄ‚îÄ 02-partman-config.sql           # Partitioning (optional)
‚îú‚îÄ‚îÄ workers/            # DISABLED (Phase 3) - Code conserv√© pour r√©f√©rence
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile      # (non utilis√©)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ worker.py       # PGMQ infrastructure disponible si besoin futur
‚îú‚îÄ‚îÄ static/             # Static assets (CSS, JS)
‚îÇ   ‚îú‚îÄ‚îÄ css/            # 16 CSS modules (SCADA design)
‚îÇ   ‚îî‚îÄ‚îÄ js/             # 6 JS modules (Cytoscape.js, Chart.js)
‚îú‚îÄ‚îÄ docs/               # Documentation compl√®te
‚îÇ   ‚îú‚îÄ‚îÄ agile/          # EPICs & User Stories (EPIC-06, 07, 08 completed)
‚îÇ   ‚îú‚îÄ‚îÄ DOCKER_OPTIMIZATIONS_SUMMARY.md     # NEW: Docker optimization results
‚îÇ   ‚îú‚îÄ‚îÄ DOCKER_ULTRATHINKING.md             # NEW: Deep dive Docker analysis
‚îÇ   ‚îú‚îÄ‚îÄ DOCKER_VALIDATION_2025.md           # NEW: 2025 best practices validation
‚îÇ   ‚îú‚îÄ‚îÄ docker_setup.md                     # Docker setup guide (v2.0.0)
‚îÇ   ‚îú‚îÄ‚îÄ Document Architecture.md            # Architecture overview (v2.0.0)
‚îÇ   ‚îú‚îÄ‚îÄ Specification_API.md                # API specification (v2.0.0)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/              # Tests automatis√©s (pytest-asyncio)
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py     # Fixtures (async engine, test DB)
‚îÇ   ‚îú‚îÄ‚îÄ test_event_*.py                     # Agent Memory tests (40/42 passing)
‚îÇ   ‚îú‚îÄ‚îÄ test_code_*.py                      # NEW: Code Intelligence tests (126 passing)
‚îÇ   ‚îú‚îÄ‚îÄ test_graph_*.py                     # NEW: Graph tests (20 passing)
‚îÇ   ‚îî‚îÄ‚îÄ integration/                        # NEW: Integration tests (17 passing)
‚îú‚îÄ‚îÄ scripts/            # Utilities
‚îÇ   ‚îú‚îÄ‚îÄ generate_test_data.py
‚îÇ   ‚îî‚îÄ‚îÄ benchmarks/                         # Performance benchmarks
‚îú‚îÄ‚îÄ logs/               # Application logs
‚îú‚îÄ‚îÄ .env.example        # Environment variables template
‚îú‚îÄ‚îÄ .dockerignore       # NEW: Build context optimization (847 MB ‚Üí 23 MB)
‚îú‚îÄ‚îÄ docker-compose.yml  # Orchestration (db + api, worker disabled)
‚îú‚îÄ‚îÄ Makefile            # Development commands
‚îî‚îÄ‚îÄ README.md           # Project overview (v2.0.0)
```

**Changements v2.0.0**:
- ‚úÖ Worker d√©sactiv√© (Phase 3 consolidation)
- ‚úÖ Code Intelligence services & routes ajout√©s (EPIC-06)
- ‚úÖ Code Intelligence UI templates ajout√©s (EPIC-07)
- ‚úÖ `.dockerignore` cr√©√© (Phase 1 security)
- ‚úÖ Documentation Docker compl√®te (Phases 1-3)
- ‚úÖ PostgreSQL 17 ‚Üí 18 migration
- ‚úÖ 245 tests passing (102 + 126 + 17)

*Note: L'ancienne UI est int√©gr√©e dans `api/templates/`. Le worker est d√©sactiv√© mais le code est conserv√© pour r√©f√©rence future.*

---

## 11. Int√©gration avec Expanse
*La biblioth√®que client Python (`mnemo_client.py`) reste valide car elle interagit avec l'API FastAPI, qui abstrait la base de donn√©es.* 
*L'exemple d'int√©gration `.mdc` reste valide.* 

---

## 12. R√©silience et reprise apr√®s incident (Local)
*   **Strat√©gie de Sauvegarde :** Focus sur **PostgreSQL**. Utilisation de `pg_dump` (logique) pour des sauvegardes r√©guli√®res et/ou `pg_basebackup` + archivage WAL (physique) pour Point-in-Time Recovery. Stockage des sauvegardes sur un disque diff√©rent ou externe.
*   **Reprise :** Restauration standard PostgreSQL depuis les sauvegardes.
*   **Monitoring :** Alertes bas√©es sur les logs ou des v√©rifications p√©riodiques (espace disque, √©tat des jobs `pg_cron`, erreurs PG).

---

## 13. Documentation associ√©e
*V√©rifier et mettre √† jour les documents dans `docs/` (ex: `Specification_API.md`, `bdd_schema.md`) pour refl√©ter l'architecture 100% PostgreSQL, PGMQ, etc.*

---

## 14. √âvolutions futures
*Reste inchang√© conceptuellement, mais l'impl√©mentation se ferait dans l'√©cosyst√®me PostgreSQL.* 

---

**Version**: v2.0.0
**Derni√®re mise √† jour**: 2025-10-17
**Changements majeurs**:
- PostgreSQL 17 ‚Üí 18 (EPIC-06 migration)
- Architecture Dual-Purpose: Agent Memory + Code Intelligence (EPIC-06/07)
- Ajout table `code_chunks` (dual embeddings TEXT + CODE, 768D chacun)
- Tables `nodes`/`edges` √©tendues pour graphes causaux ET d√©pendances de code
- 7-step indexing pipeline (<100ms/file)
- Hybrid code search (lexical + vector + RRF, <200ms P95)
- Graph traversal avec CTEs r√©cursives (0.155ms, 129√ó faster than target)
- Performance optimizations EPIC-08 (cache, connection pool 3 ‚Üí 20)
- Worker service d√©sactiv√© (Phase 3 consolidation)
- RAM API: 2 GB ‚Üí 4 GB (dual embeddings support)
- 245 tests passing (102 agent memory + 126 code intelligence + 17 integration)

**Auteur**: Giak (mis √† jour par Claude Code)

