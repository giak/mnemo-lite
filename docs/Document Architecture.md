# MnemoLite ‚Äì Document d'Architecture (ARCH) d√©taill√©

> üìÖ **Derni√®re mise √† jour**: 2025-10-13
> üìù **Version**: v1.3.0
> ‚úÖ **Statut**: √Ä jour avec le code

## 1. Vue d'ensemble
MnemoLite adopte une architecture **CQRS cognitive et modulaire**, optimis√©e pour un d√©ploiement local. Elle repose **exclusivement sur PostgreSQL 17** avec ses extensions pour g√©rer les aspects relationnels, vectoriels (`pgvector`), le partitionnement temporel (`pg_partman`), les t√¢ches asynchrones (`pgmq` optionnel via lib Python) et le graphe relationnel (tables + CTE).
L'interface utilisateur Web utilise **FastAPI + HTMX** pour une exp√©rience r√©active sans SPA complexe.

---

## 2. Architecture logique d√©taill√©e

### Command Side (√âcriture)
```mermaid
flowchart TD
  CLI_API["CLI/API REST (FastAPI)"] --> WriteHandler["Write Handler"]
  WriteHandler --> Queue["pgmq Queue (Optionnel, via tembo-pgmq-python)"]
  Queue --> Worker["Ingestion/Async Worker"]
  WriteHandler --> DirectWrite["Write Directe (API -> Repo -> DB)"]
  
  subgraph PostgreSQL_17 ["(PostgreSQL 17)"]
    direction LR
    PG_Events[events Table]
    PG_Embeddings["embedding (vector column)"]
    PG_Graph[nodes/edges Tables]
    PG_Partitions["Partitions (pg_partman)"]
  end

  Worker --> PG_Events
  Worker --> PG_Embeddings
  Worker --> PG_Graph
  DirectWrite --> PG_Events
  DirectWrite --> PG_Embeddings
  DirectWrite --> PG_Graph
```
*Note: L'utilisation de `pgmq` et d'un worker est optionnelle pour un d√©couplage asynchrone, l'√©criture peut √™tre directe depuis l'API via les repositories.* 

### Query Side (Lecture)
```mermaid
flowchart TD
  UI["HTMX/Jinja2 UI"] --> FastAPI_Query["FastAPI Query Handler (Routes -> Services -> Repositories)"]
  
  subgraph PostgreSQL_17 ["(PostgreSQL 17)"]
     direction LR
     PG_VectorSearch["Recherche Vectorielle (pgvector HNSW)"]
     PG_SQLSearch["Recherche Relationnelle/Metadata"]
     PG_GraphSearch["Recherche Graph (CTE SQL)"]
  end

  FastAPI_Query --> PG_VectorSearch
  FastAPI_Query --> PG_SQLSearch
  FastAPI_Query --> PG_GraphSearch

  PG_VectorSearch --> Fusion["Fusion & Ranking (in Service/Repo)"]
  PG_SQLSearch --> Fusion
  PG_GraphSearch --> Fusion
  
  Fusion --> UI
```
*Toutes les recherches (vectorielle, SQL, graphe) sont initi√©es par l'API et ex√©cut√©es via les repositories directement dans PostgreSQL.*

### Couche Service et Auto-Embedding

**EventService** : Couche m√©tier introduite pour orchestrer la cr√©ation d'√©v√©nements avec g√©n√©ration automatique d'embeddings.

```mermaid
flowchart LR
  Route[Event Routes] --> EventService
  EventService --> EmbeddingService[Sentence-Transformers<br>nomic-embed-text-v1.5]
  EventService --> EventRepo[Event Repository]
  EventRepo --> PostgreSQL[(PostgreSQL)]

  style EventService fill:#e1f5fe
  style EmbeddingService fill:#fff3e0
```

**Fonctionnalit√©s** :
- **Auto-g√©n√©ration d'embeddings** : Si aucun embedding n'est fourni dans la requ√™te, EventService extrait automatiquement le texte depuis `content.text` (ou fields configurables) et g√©n√®re un embedding 768-dim via Sentence-Transformers
- **Configuration flexible** :
  - `EMBEDDING_AUTO_GENERATE` : active/d√©sactive la g√©n√©ration automatique (d√©faut: true)
  - `EMBEDDING_FAIL_STRATEGY` : `soft` (continue sans embedding) ou `hard` (√©choue la cr√©ation) (d√©faut: soft)
  - `EMBEDDING_SOURCE_FIELDS` : priorit√© des champs pour extraction de texte (d√©faut: `text,body,message,content,title`)
- **Fail-soft** : En cas d'√©chec de g√©n√©ration d'embedding, l'√©v√©nement est cr√©√© sans embedding (si `fail_strategy=soft`)
- **Injection de d√©pendances** : EventService inject√© via `Depends(get_event_service)` dans les routes

**Flux de cr√©ation** :
```
POST /v1/events
  ‚Üì
EventService.create_event()
  ‚Üì (si embedding absent)
EventService._extract_text_for_embedding()
  ‚Üì
EmbeddingService.generate_embedding(text)
  ‚Üì
EventRepository.add(event)
  ‚Üì
PostgreSQL INSERT
```

---

## 3. Mod√®le de donn√©es PostgreSQL

### Table `events`
```sql
-- Aligned with docs/bdd_schema.md v1.2.x
CREATE TABLE IF NOT EXISTS events (
    id          UUID NOT NULL DEFAULT gen_random_uuid(),
    timestamp   TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    content     JSONB NOT NULL,             -- Contenu flexible: { "type": "prompt", ... } ou { "type": "decision", ... }
    embedding   VECTOR(768),                -- Embedding (nomic-embed-text-v1.5)
    metadata    JSONB DEFAULT '{}'::jsonb,  -- Tags, source, IDs, types, etc.
    -- Cl√© primaire composite, incluant la cl√© de partitionnement
    PRIMARY KEY (id, timestamp)
)
PARTITION BY RANGE (timestamp);

COMMENT ON TABLE events IS 'Table principale stockant tous les evenements atomiques (partitionnee par mois sur timestamp).';
COMMENT ON COLUMN events.content IS 'Contenu detaille de l evenement au format JSONB.';
COMMENT ON COLUMN events.embedding IS 'Vecteur semantique du contenu (dimension 768 pour nomic-embed-text-v1.5).';
COMMENT ON COLUMN events.metadata IS 'Metadonnees additionnelles (tags, IDs, types) au format JSONB.';

-- Index B-tree sur timestamp (cl√© de partitionnement), h√©rit√© par les partitions
CREATE INDEX IF NOT EXISTS events_timestamp_idx ON events (timestamp);

-- Index GIN sur metadata pour recherches flexibles, h√©rit√© par les partitions
CREATE INDEX IF NOT EXISTS events_metadata_gin_idx ON events USING GIN (metadata jsonb_path_ops);

-- NOTE IMPORTANTE sur l'index vectoriel (HNSW/IVFFlat):
-- Il DOIT etre cree sur chaque partition individuelle, PAS sur la table mere.
-- Ceci est generalement gere via des hooks pg_partman ou des scripts de maintenance.
-- Exemple pour une partition 'events_pYYYY_MM':
-- CREATE INDEX CONCURRENTLY IF NOT EXISTS events_pYYYY_MM_embedding_hnsw_idx
-- ON events_pYYYY_MM USING hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64);
```
*Note: La gestion des index HNSW sur les partitions n√©cessite une attention particuli√®re (ex: via les fonctions hook de `pg_partman`).* 

### Tables `nodes` et `edges` (pour le graphe)
```sql
-- Aligned with docs/bdd_schema.md v1.2.x
CREATE TABLE IF NOT EXISTS nodes (
    node_id         UUID PRIMARY KEY, -- Generalement un event.id, mais peut etre autre chose (concept genere)
    node_type       TEXT NOT NULL,    -- Ex: 'event', 'concept', 'entity', 'rule', 'document'
    label           TEXT,             -- Nom lisible pour affichage/requete
    properties      JSONB DEFAULT '{}'::jsonb, -- Attributs additionnels du n≈ìud
    created_at      TIMESTAMPTZ DEFAULT NOW()
);
COMMENT ON TABLE nodes IS 'Noeuds du graphe conceptuel (evenements, concepts, entites).';

CREATE INDEX IF NOT EXISTS nodes_type_idx ON nodes(node_type);

CREATE TABLE IF NOT EXISTS edges (
    edge_id         UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_node_id  UUID NOT NULL, -- Reference logique nodes.node_id
    target_node_id  UUID NOT NULL, -- Reference logique nodes.node_id
    relation_type   TEXT NOT NULL, -- Ex: 'causes', 'mentions', 'related_to', 'follows', 'uses_tool', 'part_of'
    properties      JSONB DEFAULT '{}'::jsonb, -- Poids, timestamp de la relation, etc.
    created_at      TIMESTAMPTZ DEFAULT NOW()
);
COMMENT ON TABLE edges IS 'Relations (aretes) entre les noeuds du graphe conceptuel.';
COMMENT ON COLUMN edges.source_node_id IS 'ID du noeud source (pas de FK physique).';
COMMENT ON COLUMN edges.target_node_id IS 'ID du noeud cible (pas de FK physique).';

CREATE INDEX IF NOT EXISTS edges_source_idx ON edges(source_node_id);
CREATE INDEX IF NOT EXISTS edges_target_idx ON edges(target_node_id);
CREATE INDEX IF NOT EXISTS edges_relation_type_idx ON edges(relation_type);
```
*Note: La cr√©ation des n≈ìuds et des ar√™tes est g√©r√©e par la logique applicative. Pas de contraintes FK physiques sur edges pour flexibilit√©; coh√©rence g√©r√©e par l'application ou des checks p√©riodiques.*

### Autres tables (optionnelles)
*   `memory_types`, `event_types` : Pourraient √™tre cr√©√©es pour standardiser les types via cl√©s √©trang√®res si le besoin se confirme (actuellement g√©r√© via `metadata`).
*   Tables de configuration (si la configuration via `.env` n'est pas suffisante).

### Partitionnement Mensuel avec `pg_partman`
*   La table `events` est partitionn√©e par `RANGE` sur `timestamp`.
*   `pg_partman` est configur√© (`db/init/02-partman-config.sql`) pour cr√©er automatiquement les partitions mensuelles (ex: `events_p2025_05`).
*   Une politique de r√©tention (`retention` dans `part_config`) peut √™tre d√©finie pour supprimer/d√©tacher automatiquement les vieilles partitions (alternative au TTL par colonne).

---

## 4. Index vectoriel (`pgvector`)
*   **Stockage :** Directement dans la colonne `embedding VECTOR(768)` de la table `events` (ou ses partitions).
*   **Index :** **HNSW** (`USING hnsw`) est recommand√© pour l'√©quilibre vitesse/pr√©cision. `vector_cosine_ops` ou `vector_l2_ops` selon la m√©trique de distance utilis√©e par le mod√®le d'embedding.
*   **Gestion sur partitions :** L'index HNSW doit √™tre cr√©√© sur **chaque partition**. L'utilisation des fonctions `run_maintenance_proc()` de `pg_partman` avec des scripts personnalis√©s ou des fonctions trigger est la m√©thode recommand√©e pour automatiser la cr√©ation/maintenance des index sur les nouvelles partitions.
*   **Recherche :** Utilisation des op√©rateurs `<->` (distance L2), `<#>` (produit scalaire n√©gatif), ou `<=>` (distance cosinus) dans les requ√™tes SQL via les m√©thodes du repository.

---

## 5. Graphe mn√©sique (Tables + CTE SQL)
*   **Mod√®le :** Graphe de propri√©t√©s stock√© dans les tables `nodes` et `edges`.
*   **Cr√©ation :** La logique applicative (potentiellement dans un service ou worker d√©di√©) identifie les entit√©s ou concepts dans les `events` et cr√©e/lie les n≈ìuds et ar√™tes correspondants.
*   **Interrogation :** Utilisation de **Common Table Expressions (CTE) r√©cursives** en SQL pour explorer les relations sur une profondeur limit√©e (cible ‚â§ 3 sauts pour performance locale).
    ```sql
    -- Exemple : Trouver les √©v√©nements caus√©s par event_X (max 3 sauts)
    WITH RECURSIVE causal_chain AS (
        SELECT source_node_id, target_node_id, 1 AS depth
        FROM edges
        WHERE source_node_id = 'event_X_uuid' AND relation_type = 'causes'
        UNION ALL
        SELECT e.source_node_id, e.target_node_id, cc.depth + 1
        FROM edges e
        JOIN causal_chain cc ON e.source_node_id = cc.target_node_id
        WHERE cc.depth < 3 AND e.relation_type = 'causes'
    )
    SELECT target_node_id FROM causal_chain;
    ```
*   **Avantages :** Int√©gr√© √† PostgreSQL, transactionnel, utilise SQL standard.
*   **Limitations :** Moins performant que les bases de donn√©es graphe d√©di√©es pour des travers√©es tr√®s larges ou profondes, ou des algorithmes graphe complexes.

---

## 6. Coh√©rence & Cycle de vie des donn√©es (Local)

*   **Coh√©rence :** Assur√©e par les transactions PostgreSQL.
*   **Cycle de vie Hot/Warm simplifi√© :**
    *   **Partitionnement Mensuel :** G√©r√© par `pg_partman`.
    *   **Hot (0-12 mois) :** Partitions r√©centes, vecteurs FP32.
    *   **Warm (> 12 mois) :** Vecteurs quantis√©s en **INT8** par un job `pg_cron` (√† activer/configurer) pour √©conomiser l'espace disque. Le job cible les partitions de plus de 12 mois.
    *   **R√©tention :** Les vieilles partitions (> N mois/ann√©es, configurable dans `pg_partman`) peuvent √™tre d√©tach√©es ou supprim√©es pour g√©rer l'espace disque local.
    *   **Archivage Complexe Diff√©r√© :** Pas d'√©tape Cold (JSON) ou Archive (S3) initialement.

```mermaid
flowchart LR
  subgraph Partitions_Mensuelles
    P_M1[Mois 1]
    P_M2[Mois 2]
    P_Mdots[...]
    P_M12[Mois 12]
    P_M13[Mois 13]
    P_M14[Mois 14]
    P_Mdots2[...]
  end

  HotPartitions["Hot (0-12 mois)<br>Vecteur FP32"] --> P_M1
  HotPartitions --> P_M2
  HotPartitions --> P_Mdots
  HotPartitions --> P_M12
  
  WarmPartitions["Warm (> 12 mois)<br>Vecteur INT8"] --> P_M13
  WarmPartitions --> P_M14
  WarmPartitions --> P_Mdots2
  
  P_M12 -->|"pg_cron (&gt;12 mois)<br>Quantize INT8<br>(Needs activation)"| P_M13
  
  classDef hot fill:#fdebd0,stroke:#c8976c;
  classDef warm fill:#eaf2f8,stroke:#80a3bd;
  class HotPartitions,P_M1,P_M2,P_Mdots,P_M12 hot;
  class WarmPartitions,P_M13,P_M14,P_Mdots2 warm;
```
*   **Auditabilit√© :** Via logs applicatifs et potentiellement triggers PG sur modifications.
*   **Monitoring Local :** Focus sur les logs PostgreSQL, `pg_stat_statements`, `pg_stat_activity`, et les outils syst√®me (`htop`, `iotop`). Option via endpoint `/metrics` Prometheus.

---

## 7. D√©ploiement (Docker Compose Local)
```yaml
# Extrait simplifi√© et align√© sur le docker-compose.yml r√©el
# Voir docs/docker_setup.md pour la version compl√®te et comment√©e
version: '3.8'

services:
  db:
    build: ./db # Contient FROM pgvector/pgvector:pg17 et installe partman
    container_name: mnemo-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-mnemo}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mnemopass}
      POSTGRES_DB: ${POSTGRES_DB:-mnemolite}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d:ro # Scripts init SQL
    ports:
      - "127.0.0.1:${POSTGRES_PORT:-5432}:5432"
    healthcheck: # ... d√©fini dans le fichier r√©el
      # ...
    # ... autres configs (command, shm_size, networks, logging)

  api:
    build: .
    container_name: mnemo-api
    restart: unless-stopped
    ports:
      - "127.0.0.1:${API_PORT:-8001}:8000"
    environment:
      DATABASE_URL: "postgresql+asyncpg://${POSTGRES_USER:-mnemo}:${POSTGRES_PASSWORD:-mnemopass}@db:5432/${POSTGRES_DB:-mnemolite}"
      # ... autres env vars
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - ./api:/app # Montage pour dev
      # ... autres volumes (certs, tests, scripts)
    # ... autres configs (networks, logging, healthcheck)

  worker:
    build: .
    container_name: mnemo-worker
    restart: unless-stopped
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER:-mnemo}:${POSTGRES_PASSWORD:-mnemopass}@db:5432/${POSTGRES_DB:-mnemolite}"
      # ... autres env vars
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - ./workers:/app
      # ... autres volumes (certs)
    # ... autres configs (networks, logging)

volumes:
  postgres_data:

networks:
  # ... (frontend, backend)

```
*Note : L'image Docker PostgreSQL (`db/Dockerfile`) doit inclure les extensions `pgvector` et `pg_partman`. `pgmq` est une d√©pendance Python (`tembo-pgmq-python`) utilis√©e par le worker, pas une extension PG √† installer ici.*

---

## 8. Risques & Mitigations (Local)

| Risque                        | Impact   | Mitigation                            |
|-------------------------------|----------|----------------------------------------|
| Recall‚Üì apr√®s INT8 quant.     | Moyen    | Validation locale (cible ‚â• 92%)        |
| Graphe CTE lent (> 3 sauts)   | Faible   | Confirmer besoin vs perf. locale      |
| **Sauvegarde locale √©choue**  | **√âlev√©**| Script `pg_dump` robuste, tests r√©guliers |
| Performance locale d√©grade    | Moyen    | Monitoring PG stats, optimisation conf |
| Gestion index sur partitions  | Moyen    | Automatisation via `pg_partman` hooks |
| Espace disque local insuffisant| Moyen    | Politique de r√©tention `pg_partman` agressive |
| `pg_cron` non activ√©/configur√© | Moyen    | Ajouter proc√©dure d'activation/test |

---

## 9. Performances attendues (Local)

*   **Recherche Vectorielle (Hot, k=10) :** ‚â§ 10 ms p95 (cible sur 10M vecteurs locaux).
*   **Recherche Vectorielle (Warm, k=10) :** ‚â§ 30 ms p95 (estimation apr√®s quantization).
*   **Requ√™tes Graphe (CTE ‚â§ 3 sauts) :** Variable, mais cible < 100ms sur donn√©es locales typiques.
*   **Ingestion :** D√©pend si directe ou via worker/pgmq, mais plusieurs centaines d'√©v√©nements/sec devraient √™tre atteignables localement.
*   **Optimisations cl√©s :** Tuning `postgresql.conf` pour la RAM locale, param√®tres HNSW (`ef_search`), batching c√¥t√© application si n√©cessaire.

---

## 10. Structure du projet (Align√©e)
```
mnemo-lite/
‚îú‚îÄ‚îÄ api/                # Code FastAPI (inclut /templates pour HTMX et /services, /routes, /models)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py
‚îÇ   ‚îú‚îÄ‚îÄ db/             # Repositories SQLAlchemy Core
‚îÇ   ‚îú‚îÄ‚îÄ interfaces/     # Interfaces (protocoles)
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îú‚îÄ‚îÄ services/       # Services m√©tier (event_service.py, embedding_service.py, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event_service.py                        # Orchestration √©v√©nements + auto-embedding
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentence_transformer_embedding_service.py  # Embeddings locaux (nomic-embed-text-v1.5)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py                    # Mock embeddings (dev/test)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_search_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ templates/      # Templates Jinja2/HTMX
‚îú‚îÄ‚îÄ db/                 # Configuration et initialisation PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ init/           # Scripts SQL d'initialisation (01-extensions, 01-init, 02-partman-config)
‚îú‚îÄ‚îÄ workers/            # Workers asynchrones (ex: ingestion, PGMQ consumers)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ worker.py       # Potentiel point d'entr√©e
‚îÇ   ‚îú‚îÄ‚îÄ tasks/          # Logique des t√¢ches
‚îÇ   ‚îî‚îÄ‚îÄ config/         # Configuration sp√©cifique worker (si besoin, sinon via env)
‚îú‚îÄ‚îÄ docs/               # Documentation (PFD, PRD, ARCH...)
‚îú‚îÄ‚îÄ scripts/            # Utilitaires (seed data, bench)
‚îú‚îÄ‚îÄ tests/              # Tests automatis√©s (pytest)
‚îú‚îÄ‚îÄ certs/              # Certificats (si HTTPS local)
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îî‚îÄ‚îÄ README.md
```
*Note: Le worker de synchronisation PG->Chroma (`sync.py`) n'est plus n√©cessaire.* 
*Note: Structure bas√©e sur les listings et les conventions FastAPI/Docker. L'ancienne `ui/` est int√©gr√©e dans `api/templates/`. `api/db` contient les repositories.*

---

## 11. Int√©gration avec Expanse
*La biblioth√®que client Python (`mnemo_client.py`) reste valide car elle interagit avec l'API FastAPI, qui abstrait la base de donn√©es.* 
*L'exemple d'int√©gration `.mdc` reste valide.* 

---

## 12. R√©silience et reprise apr√®s incident (Local)
*   **Strat√©gie de Sauvegarde :** Focus sur **PostgreSQL**. Utilisation de `pg_dump` (logique) pour des sauvegardes r√©guli√®res et/ou `pg_basebackup` + archivage WAL (physique) pour Point-in-Time Recovery. Stockage des sauvegardes sur un disque diff√©rent ou externe.
*   **Reprise :** Restauration standard PostgreSQL depuis les sauvegardes.
*   **Monitoring :** Alertes bas√©es sur les logs ou des v√©rifications p√©riodiques (espace disque, √©tat des jobs `pg_cron`, erreurs PG).

---

## 13. Documentation associ√©e
*V√©rifier et mettre √† jour les documents dans `docs/` (ex: `Specification_API.md`, `bdd_schema.md`) pour refl√©ter l'architecture 100% PostgreSQL, PGMQ, etc.*

---

## 14. √âvolutions futures
*Reste inchang√© conceptuellement, mais l'impl√©mentation se ferait dans l'√©cosyst√®me PostgreSQL.* 

---

**Version**: v1.3.0
**Derni√®re mise √† jour**: 2025-10-13
**Changements** : Ajout EventService + auto-embedding (nomic-embed-text-v1.5), fix health check DSN, harmonisation versioning
**Auteur**: Giak

