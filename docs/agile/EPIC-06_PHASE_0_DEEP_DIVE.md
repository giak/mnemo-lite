# EPIC-06 Phase 0 - Deep Dive & Ultra-Thinking

**Date**: 2025-10-15
**Version**: 2.0.0 (Post-Research 2024-2025)
**Statut**: ðŸ“Š RECHERCHE APPROFONDIE COMPLÃ‰TÃ‰E
**Sources**: Web research 2024-2025 + analyse codebase MnemoLite

---

## ðŸŽ¯ Executive Summary

Phase 0 prÃ©pare l'infrastructure pour EPIC-06 Code Intelligence avec **DEUX approches validÃ©es**:

### Option A: Alembic + SQLAlchemy Core (RECOMMANDÃ‰)
- âœ… Migrations standard industry
- âœ… Template async disponible
- âš ï¸ NÃ©cessite SQLAlchemy Core (pas ORM complet)
- âš ï¸ Architecture diffÃ©rente de MnemoLite actuel (asyncpg pur)

### Option B: Pure asyncpg + SQL migrations (ALTERNATIF)
- âœ… CohÃ©rent avec architecture actuelle
- âœ… Pas de dÃ©pendance SQLAlchemy
- âš ï¸ Migrations manuelles SQL
- âš ï¸ Pas de autogenerate

**DÃ©cision**: **Option A (Alembic + SQLAlchemy Core)** pour Phase 0
**Justification**: Standard industry, autogenerate, rÃ©versible, meilleur pour Ã©volution future

---

## ðŸ“Š Story 0.1: Alembic Async Setup - Deep Dive

### Recherches 2024-2025

#### DÃ©couverte Critique #1: Alembic â‰  Sans SQLAlchemy

**Sources**:
- GitHub Discussion #1208 (sqlalchemy/alembic)
- Stack Overflow Q72794483, Q77710687
- DEV.to: "Alembic with Async SQLAlchemy" (2024)

**Conclusion**:
> Alembic est **fondamentalement designed pour SQLAlchemy**. Vous pouvez utiliser SQLAlchemy Core (sans ORM), mais Ã©viter complÃ¨tement SQLAlchemy n'est pas le cas d'usage prÃ©vu.

**Impact MnemoLite**:
- Architecture actuelle: asyncpg pur (pas de SQLAlchemy)
- Phase 0 nÃ©cessitera: **SQLAlchemy Core async** + asyncpg driver
- Pas de breaking changes API, mais ajout dÃ©pendance

---

#### DÃ©couverte Critique #2: Template Async Disponible (2023+)

**Source**: https://alembic.sqlalchemy.org/en/latest/cookbook.html#using-asyncio-with-alembic

**Commande**:
```bash
alembic init -t async alembic
```

**Patterns 2024** (berkkaraal.com, September 2024):
```python
# alembic/env.py (async template)
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import pool

async def run_async_migrations():
    """Run migrations in async mode using asyncpg driver."""
    connectable = create_async_engine(
        config.get_main_option("sqlalchemy.url"),
        poolclass=pool.NullPool,  # Alembic gÃ¨re les connexions
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()

def run_migrations_online():
    """Run migrations in 'online' mode."""
    if is_async_mode():
        import asyncio
        asyncio.run(run_async_migrations())
    else:
        # Fallback synchrone (psycopg2)
        run_sync_migrations()
```

**Avantages Template Async**:
- âœ… Full asyncpg support
- âœ… Pas de psycopg2 requis
- âœ… CohÃ©rent avec FastAPI async

---

#### DÃ©couverte Critique #3: Alternatives Modernes (2024-2025)

**Sources**:
- atlasgo.io: "Atlas vs Classic Migration Tools" (2025)
- slashdot.org: "Top Alembic Alternatives in 2025"
- pingcap.com: "Schema Migration Tool Comparative Guide"

**Atlas** (Modern, 2024):
- Schema-as-code HCL/SQL
- CLI Go-based
- CI/CD integration forte
- **PostgreSQL 18 support rapide**
- âš ï¸ Ã‰cosystÃ¨me moins mature que Alembic

**Flyway** (Enterprise, depuis 2010):
- Version-controlled migrations
- +23 databases supportÃ©s
- Java-based (CLI disponible)
- Production-proven
- âš ï¸ Overkill pour MnemoLite (petite Ã©quipe)

**Liquibase** (Enterprise, depuis 2006):
- XML/YAML/SQL changelogs
- Plus de DB supportÃ©s (30+)
- Enterprise features (rollback tags, contexts)
- âš ï¸ ComplexitÃ© Ã©levÃ©e pour notre use case

**pgroll** (PostgreSQL-specific, 2024):
- Xata (serverless Postgres)
- Zero-downtime migrations
- Go-based CLI
- âš ï¸ TrÃ¨s jeune (adoption limitÃ©e)

**graphile-migrate** (PostgreSQL-specific, TypeScript):
- Roll-forward only
- TypeScript-first
- Opinionated
- âš ï¸ JavaScript ecosystem (pas Python)

**Comparaison - Fit Score MnemoLite**:

| Tool | Python Native | Async Support | Autogenerate | Maturity | PostgreSQL 18 | **Score /10** |
|------|---------------|---------------|--------------|----------|---------------|---------------|
| **Alembic** | âœ… | âœ… | âœ… | â­â­â­â­â­ | âœ… | **9/10** |
| Atlas | âŒ (CLI) | N/A | âœ… | â­â­â­ | âœ… | 7/10 |
| Flyway | âŒ (CLI) | N/A | âŒ | â­â­â­â­â­ | âœ… | 6/10 |
| Liquibase | âŒ (CLI) | N/A | âŒ | â­â­â­â­â­ | âœ… | 6/10 |
| pgroll | âŒ (CLI) | N/A | âŒ | â­â­ | âœ… | 5/10 |
| graphile-migrate | âŒ (TS) | âœ… | âŒ | â­â­â­ | âœ… | 4/10 |
| **Pure asyncpg + SQL** | âœ… | âœ… | âŒ | â­â­ | âœ… | **6/10** |

**Recommandation**: **Alembic** (9/10) reste le meilleur choix pour MnemoLite.

---

### Architecture Alembic + MnemoLite

#### Challenge: Dual DB Access Pattern

**Actuel (asyncpg pur)**:
```python
# api/db/database.py
class Database:
    async def get_pool(self) -> asyncpg.Pool:
        self._pool = await asyncpg.create_pool(
            dsn=self.dsn,
            init=self._init_connection  # pgvector registration
        )
```

**Avec Alembic (SQLAlchemy Core async)**:
```python
# api/db/engine.py (NOUVEAU)
from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine

async def get_async_engine() -> AsyncEngine:
    """Engine SQLAlchemy pour repositories + Alembic."""
    engine = create_async_engine(
        "postgresql+asyncpg://mnemo:pass@localhost:5432/mnemolite",
        echo=False,
        pool_size=10,
        max_overflow=5
    )
    return engine
```

**Pattern Cohabitation**:
- **Repositories**: Migreront progressivement vers SQLAlchemy Core async
- **Connexions directes**: Garderont asyncpg pur (workers, scripts)
- **Migrations**: Alembic via SQLAlchemy async engine

---

#### Setup Alembic avec asyncpg - Steps DÃ©taillÃ©s

##### Step 1: Installer DÃ©pendances

```bash
# requirements.txt
sqlalchemy[asyncio]>=2.0.0  # SQLAlchemy 2.0 avec support async
alembic>=1.13.0             # Alembic rÃ©cent (template async)
asyncpg>=0.29.0              # Driver PostgreSQL async (dÃ©jÃ  installÃ©)
```

**Versions validÃ©es 2024**:
- SQLAlchemy 2.0.35 (DÃ©cembre 2024)
- Alembic 1.13.3 (Novembre 2024)
- asyncpg 0.29.0 (AoÃ»t 2024)

---

##### Step 2: Initialiser Alembic (Template Async)

```bash
cd /home/giak/Work/MnemoLite
alembic init -t async alembic
```

**Output attendu**:
```
Creating directory /home/giak/Work/MnemoLite/alembic...
  Generating /home/giak/Work/MnemoLite/alembic/env.py...
  Generating /home/giak/Work/MnemoLite/alembic/README...
  Generating /home/giak/Work/MnemoLite/alembic/script.py.mako...
  Generating /home/giak/Work/MnemoLite/alembic.ini...
```

---

##### Step 3: Configurer `alembic.ini`

```ini
# alembic.ini
[alembic]
script_location = alembic
prepend_sys_path = .
version_path_separator = os  # Pour Windows compatibility
sqlalchemy.url = postgresql+asyncpg://%(POSTGRES_USER)s:%(POSTGRES_PASSWORD)s@%(POSTGRES_HOST)s:%(POSTGRES_PORT)s/%(POSTGRES_DB)s

[post_write_hooks]
# hooks.black.type = console_scripts
# hooks.black.entrypoint = black
# hooks.black.options = -l 79 REVISION_SCRIPT_FILENAME

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

**Variables environnement** (Ã  dÃ©finir avant `alembic upgrade head`):
```bash
export POSTGRES_USER=mnemo
export POSTGRES_PASSWORD=mnemopass
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432
export POSTGRES_DB=mnemolite
```

**Alternative**: Hardcoder URL dans `alembic.ini` (non recommandÃ© prod):
```ini
sqlalchemy.url = postgresql+asyncpg://mnemo:mnemopass@localhost:5432/mnemolite
```

---

##### Step 4: Configurer `alembic/env.py` (Async Mode)

```python
# alembic/env.py
from logging.config import fileConfig
import asyncio
from sqlalchemy import pool
from sqlalchemy.ext.asyncio import create_async_engine
from alembic import context
import os

# Import vos modÃ¨les ici pour autogenerate
# from api.db.models import Base  # Si vous crÃ©ez un Base SQLAlchemy
# target_metadata = Base.metadata

# Pour MnemoLite Phase 0: migrations manuelles
target_metadata = None

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

def get_url():
    """Construire URL depuis environnement ou config."""
    # PrioritÃ©: variable environnement > alembic.ini
    return os.getenv(
        "DATABASE_URL",
        config.get_main_option("sqlalchemy.url")
    ).replace("postgresql://", "postgresql+asyncpg://")

def run_migrations_offline():
    """
    Run migrations in 'offline' mode.
    Configure context avec URL uniquement, pas de Engine.
    """
    url = get_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def do_run_migrations(connection):
    """Callback synchrone pour run_sync()."""
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        compare_type=True,  # DÃ©tecter changements types colonnes
        compare_server_default=True,  # DÃ©tecter changements defaults
    )

    with context.begin_transaction():
        context.run_migrations()

async def run_async_migrations():
    """
    Run migrations in async mode avec asyncpg.
    """
    url = get_url()

    connectable = create_async_engine(
        url,
        poolclass=pool.NullPool,  # Alembic ne nÃ©cessite pas de pool
        echo=False,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()

def run_migrations_online():
    """
    Run migrations in 'online' mode.
    DÃ©tecte async mode et appelle run_async_migrations.
    """
    if context.is_offline_mode():
        run_migrations_offline()
    else:
        asyncio.run(run_async_migrations())

run_migrations_online()
```

**Points ClÃ©s**:
- âœ… `create_async_engine` avec asyncpg driver
- âœ… `connection.run_sync(do_run_migrations)` pour compatibilitÃ© sync Alembic
- âœ… `asyncio.run()` pour exÃ©cuter migration async
- âœ… `compare_type=True` pour dÃ©tecter changements types (important PostgreSQL)

---

##### Step 5: CrÃ©er Migration Baseline

**Option A: Migration Manuelle (RECOMMANDÃ‰ Phase 0)**

```bash
alembic revision -m "baseline_existing_tables"
```

Ã‰diter `alembic/versions/XXXX_baseline_existing_tables.py`:

```python
"""baseline_existing_tables

Revision ID: abc123def456
Revises:
Create Date: 2025-10-15 16:00:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from pgvector.sqlalchemy import Vector

# revision identifiers
revision = 'abc123def456'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    """
    Baseline migration: marque l'Ã©tat actuel de la DB.
    Ne crÃ©e rien (tables existent dÃ©jÃ ), sert de point de rÃ©fÃ©rence.
    """
    # VÃ©rifier que les tables existent
    # Si exÃ©cutÃ© sur DB vide, crÃ©er les tables

    # Option: CrÃ©er tables si n'existent pas
    # op.execute("""
    # CREATE TABLE IF NOT EXISTS events (
    #     id UUID PRIMARY KEY,
    #     timestamp TIMESTAMPTZ NOT NULL,
    #     content JSONB NOT NULL,
    #     embedding VECTOR(768),
    #     metadata JSONB
    # );
    # """)

    # Pour baseline simple: ne rien faire (tables dÃ©jÃ  crÃ©Ã©es par init scripts)
    pass

def downgrade():
    """Baseline ne peut pas Ãªtre downgrade."""
    pass
```

**Marquer migration comme appliquÃ©e** (DB existante):
```bash
# Option 1: Stamp sans exÃ©cuter
alembic stamp head

# Option 2: ExÃ©cuter migration (no-op)
alembic upgrade head
```

---

**Option B: Autogenerate (NÃ©cessite Base SQLAlchemy)**

Si vous crÃ©ez un `Base` SQLAlchemy:

```python
# api/db/models.py (NOUVEAU)
from sqlalchemy.orm import declarative_base
from sqlalchemy import Column, DateTime, Text
from sqlalchemy.dialects.postgresql import UUID, JSONB
from pgvector.sqlalchemy import Vector
import uuid

Base = declarative_base()

class Event(Base):
    __tablename__ = "events"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    timestamp = Column(DateTime(timezone=True), nullable=False)
    content = Column(JSONB, nullable=False)
    embedding = Column(Vector(768))
    metadata = Column(JSONB)
```

Puis:
```bash
# Importer Base dans alembic/env.py
# from api.db.models import Base
# target_metadata = Base.metadata

alembic revision --autogenerate -m "baseline_existing_tables"
alembic upgrade head
```

**âš ï¸ ATTENTION**: Autogenerate peut gÃ©nÃ©rer DROP/CREATE si tables existent dÃ©jÃ ! Review manually.

---

##### Step 6: Tester Migrations

```bash
# VÃ©rifier Ã©tat actuel
alembic current

# Expected output:
# abc123def456 (head)

# Tester upgrade (no-op si baseline)
alembic upgrade head

# Tester downgrade
alembic downgrade -1

# Re-upgrade
alembic upgrade head

# VÃ©rifier historique
alembic history --verbose
```

---

### PiÃ¨ges & Mitigations

#### PiÃ¨ge #1: pgvector Types Non Reconnus

**SymptÃ´me**:
```
sqlalchemy.exc.ProgrammingError: (asyncpg.exceptions.UndefinedObjectError) type "vector" does not exist
```

**Cause**: Extension pgvector pas crÃ©Ã©e avant migration

**Solution**:
```python
# Dans alembic/env.py, avant do_run_migrations:
def do_run_migrations(connection):
    # Assurer que pgvector est chargÃ©
    connection.execute(sa.text("CREATE EXTENSION IF NOT EXISTS vector;"))

    context.configure(
        connection=connection,
        target_metadata=target_metadata,
    )
    with context.begin_transaction():
        context.run_migrations()
```

**Alternative**: CrÃ©er extension dans migration `001_add_pgvector.py`:
```python
def upgrade():
    op.execute("CREATE EXTENSION IF NOT EXISTS vector;")
```

---

#### PiÃ¨ge #2: Autogenerate DÃ©tecte Faux Changements

**SymptÃ´me**:
```bash
alembic revision --autogenerate -m "test"
# GÃ©nÃ¨re DROP COLUMN, ADD COLUMN alors qu'aucun changement
```

**Cause**: IncompatibilitÃ© types SQLAlchemy vs types PostgreSQL rÃ©els

**Solution**: Configurer `compare_type` prÃ©cisÃ©ment:
```python
# alembic/env.py
def run_migrations_online():
    context.configure(
        compare_type=True,
        compare_server_default=True,

        # Ignorer certains types connus pour faux positifs
        include_object=lambda object, name, type_, reflected, compare_to: True,
        render_as_batch=False,
    )
```

**Alternative**: Migrations manuelles Phase 0 (Ã©vite autogenerate)

---

#### PiÃ¨ge #3: Connexion Pool Conflicts

**SymptÃ´me**:
```
asyncpg.exceptions.TooManyConnectionsError: sorry, too many clients already
```

**Cause**: Alembic + Application partagent pool sans coordination

**Solution**: Alembic utilise `NullPool` (pas de pooling)
```python
connectable = create_async_engine(
    url,
    poolclass=pool.NullPool,  # â† Critique!
)
```

---

### Recommandation Finale Story 0.1

**Approche Phase 0**:
1. âœ… Installer SQLAlchemy 2.0 + Alembic 1.13+
2. âœ… Initialiser avec template async (`alembic init -t async`)
3. âœ… CrÃ©er migration baseline manuelle (marque Ã©tat actuel)
4. âœ… Tester upgrade/downgrade sur DB test
5. âŒ **PAS de autogenerate Phase 0** (Ã©vite complications)
6. âœ… Migrations manuelles pour `code_chunks` table (Phase 1)

**Timeline**: 1 jour (avec tests)

**Story Points**: 3 (validÃ©, pas de changement)

---

## ðŸ“Š Story 0.2: Dual Embeddings Service - Deep Dive

### Recherches 2024-2025

#### DÃ©couverte Critique #1: RAM Optimization Techniques

**Sources**:
- Milvus AI: "Reduce memory footprint Sentence Transformers" (2024)
- Medium: "Optimizing Sentence Embedding Model" (Aahana Khanal, 2024)
- HuggingFace Optimum: "Accelerate Sentence Transformers" (Philipp Schmid, 2024)

**Techniques ValidÃ©es**:

**1. FP16 Precision (Half-Precision)**:
```python
# RÃ©duit RAM de 50%
model = SentenceTransformer(
    "jinaai/jina-embeddings-v2-base-code",
    device="cpu"
).half()  # FP32 â†’ FP16
```

**Impact**:
- RAM: 400 MB â†’ 200 MB (50% rÃ©duction)
- Latence: +5-10% (minimal)
- Accuracy: -0.1% (nÃ©gligeable)

**Limitations**:
- âš ï¸ CPU support FP16 limitÃ© (PyTorch nÃ©cessite AVX2)
- âœ… Fonctionne bien GPU/MPS

---

**2. INT8 Quantization (8-bit)**:
```python
from optimum.onnxruntime import ORTModel

# Convertir modÃ¨le en ONNX + quantize INT8
model = ORTModel.from_pretrained(
    "jinaai/jina-embeddings-v2-base-code",
    export=True,
    quantization_config="int8"
)
```

**Impact**:
- RAM: 400 MB â†’ 100 MB (75% rÃ©duction)
- Latence: Similaire ou meilleur (ONNX optimized)
- Accuracy: -1-2% (acceptable pour code search)

**Limitations**:
- âš ï¸ NÃ©cessite optimum + onnxruntime
- âš ï¸ Conversion une-off (50-100 MB stockage)

---

**3. Lazy Loading Pattern**:
```python
_text_model = None
_code_model = None

async def get_text_model():
    global _text_model
    if _text_model is None:
        _text_model = await load_model_async("nomic-ai/nomic-embed-text-v1.5")
    return _text_model

async def get_code_model():
    global _code_model
    if _code_model is None:
        _code_model = await load_model_async("jinaai/jina-embeddings-v2-base-code")
    return _code_model
```

**Impact**:
- Startup: InstantanÃ© (pas de chargement upfront)
- RAM: Progressive (code model chargÃ© only si /v1/code/search appelÃ©)
- Latence premiÃ¨re requÃªte: +10-30s (acceptable)

---

**4. Model Caching & Unloading**:
```python
import weakref
import gc

class ModelCache:
    def __init__(self, ttl_seconds=3600):
        self._cache = {}
        self._last_access = {}
        self.ttl = ttl_seconds

    async def get_model(self, model_name):
        # Check TTL
        if model_name in self._cache:
            elapsed = time.time() - self._last_access[model_name]
            if elapsed > self.ttl:
                # Unload model
                del self._cache[model_name]
                gc.collect()

        # Load if needed
        if model_name not in self._cache:
            self._cache[model_name] = SentenceTransformer(model_name)

        self._last_access[model_name] = time.time()
        return self._cache[model_name]
```

**Impact**:
- RAM: ModÃ¨les unload aprÃ¨s inactivitÃ© (libÃ¨re ~400 MB)
- Trade-off: Cold start penalty aprÃ¨s TTL

---

**5. Batch Size Tuning**:
```python
# DÃ©faut sentence-transformers: batch_size=32
# Pour CPU avec RAM limitÃ©e: rÃ©duire batch

embeddings = model.encode(
    texts,
    batch_size=8,  # RÃ©duit peaks RAM temporaires
    show_progress_bar=False
)
```

**Impact**:
- RAM peaks: -30-40% (Ã©vite OOM sur gros batches)
- Latence: +10-20% (plus de batches)

---

#### DÃ©couverte Critique #2: jina-embeddings-v2-base-code Benchmarks

**Source**: jina.ai/news/elevate-your-code-search (FÃ©vrier 2024)

**Benchmarks CodeSearchNet**:
- **Leads 9/15 benchmarks**
- Top 3 sur tous les 15
- **Vs Microsoft CodeBERT**: +12% Recall@10 moyen
- **Vs Salesforce CodeT5**: +8% Recall@10 moyen

**SpÃ©cifications**:
- **Parameters**: 161M (vs nomic-text 137M)
- **Context Length**: 8192 tokens (vs 8192 nomic-text)
- **Dimensions**: 768 (identical to nomic-text âœ…)
- **Languages**: 30+ programming languages
  - Emphasis: Python, JavaScript, Java, PHP, Go, Ruby
- **Training Data**: 150M code Q&A pairs + docstrings
- **License**: Apache 2.0 (commercial-friendly)

**Latence Attendue** (CPU, 307MB model):
- Single text: 50-100ms
- Batch 32: 800-1200ms
- Batch 64: 1500-2000ms

**RAM Usage ValidÃ©**:
- FP32: ~400 MB (161M params * 4 bytes * 1.5 overhead)
- FP16: ~200 MB
- INT8: ~100 MB

---

#### DÃ©couverte Critique #3: Dual Model Loading Pattern

**Source**: Analyse codebase MnemoLite + best practices 2024

**Pattern Existant (nomic-text uniquement)**:
```python
# api/services/sentence_transformer_embedding_service.py
class SentenceTransformerEmbeddingService:
    def __init__(self, model_name, dimension):
        self.model_name = model_name
        self._model = None  # Lazy loading
        self._lock = asyncio.Lock()

    async def _ensure_model_loaded(self):
        if self._model is None:
            async with self._lock:
                self._model = await loop.run_in_executor(
                    None,
                    self._load_model_sync
                )
```

**Pattern Dual Models (RECOMMANDÃ‰)**:
```python
from enum import Enum

class EmbeddingDomain(str, Enum):
    TEXT = "text"
    CODE = "code"
    HYBRID = "hybrid"

class DualEmbeddingService:
    """
    Service d'embeddings dual-model avec lazy loading.

    - text_model: nomic-embed-text-v1.5 (conversations, docs)
    - code_model: jina-embeddings-v2-base-code (code, API)
    """

    def __init__(self):
        self.text_model_name = os.getenv(
            "EMBEDDING_MODEL",
            "nomic-ai/nomic-embed-text-v1.5"
        )
        self.code_model_name = os.getenv(
            "CODE_EMBEDDING_MODEL",
            "jinaai/jina-embeddings-v2-base-code"
        )
        self.dimension = int(os.getenv("EMBEDDING_DIMENSION", "768"))

        # Lazy loading
        self._text_model = None
        self._code_model = None
        self._text_lock = asyncio.Lock()
        self._code_lock = asyncio.Lock()

        logger.info(
            "DualEmbeddingService initialized",
            extra={
                "text_model": self.text_model_name,
                "code_model": self.code_model_name,
                "dimension": self.dimension
            }
        )

    async def _ensure_text_model(self):
        """Charge text model si nÃ©cessaire (thread-safe)."""
        if self._text_model is not None:
            return

        async with self._text_lock:
            if self._text_model is not None:
                return

            logger.info(f"Loading text model: {self.text_model_name}")
            loop = asyncio.get_event_loop()
            self._text_model = await loop.run_in_executor(
                None,
                lambda: SentenceTransformer(
                    self.text_model_name,
                    device="cpu",
                    trust_remote_code=True
                )
            )
            logger.info("âœ… Text model loaded")

    async def _ensure_code_model(self):
        """Charge code model si nÃ©cessaire (thread-safe)."""
        if self._code_model is not None:
            return

        async with self._code_lock:
            if self._code_model is not None:
                return

            logger.info(f"Loading code model: {self.code_model_name}")
            loop = asyncio.get_event_loop()
            self._code_model = await loop.run_in_executor(
                None,
                lambda: SentenceTransformer(
                    self.code_model_name,
                    device="cpu",
                    trust_remote_code=True
                )
            )
            logger.info("âœ… Code model loaded")

    async def generate_embedding(
        self,
        text: str,
        domain: EmbeddingDomain = EmbeddingDomain.TEXT
    ) -> dict[str, list[float]]:
        """
        GÃ©nÃ¨re embedding(s) selon domain.

        Args:
            text: Texte Ã  encoder
            domain: TEXT (nomic), CODE (jina), ou HYBRID (both)

        Returns:
            - TEXT: {'text': [768D]}
            - CODE: {'code': [768D]}
            - HYBRID: {'text': [768D], 'code': [768D]}
        """
        result = {}

        if domain in [EmbeddingDomain.TEXT, EmbeddingDomain.HYBRID]:
            await self._ensure_text_model()
            loop = asyncio.get_event_loop()
            emb_array = await loop.run_in_executor(
                None,
                self._text_model.encode,
                text
            )
            result['text'] = emb_array.tolist()

        if domain in [EmbeddingDomain.CODE, EmbeddingDomain.HYBRID]:
            await self._ensure_code_model()
            loop = asyncio.get_event_loop()
            emb_array = await loop.run_in_executor(
                None,
                self._code_model.encode,
                text
            )
            result['code'] = emb_array.tolist()

        return result

    def get_stats(self) -> dict:
        """Retourne stats service."""
        return {
            "text_model": self.text_model_name,
            "code_model": self.code_model_name,
            "dimension": self.dimension,
            "text_model_loaded": self._text_model is not None,
            "code_model_loaded": self._code_model is not None,
            "estimated_ram_mb": self._estimate_ram()
        }

    def _estimate_ram(self) -> int:
        """Estime RAM totale utilisÃ©e."""
        ram = 0
        if self._text_model is not None:
            ram += 260  # nomic-text ~260 MB
        if self._code_model is not None:
            ram += 400  # jina-code ~400 MB
        return ram
```

**Avantages Pattern**:
- âœ… Lazy loading (code model chargÃ© seulement si nÃ©cessaire)
- âœ… Thread-safe (double-checked locking)
- âœ… Async-first (run_in_executor pour Ã©viter blocking)
- âœ… Monitoring RAM (`get_stats()`)
- âœ… Backward compatible (TEXT domain = comportement actuel)

---

### Architecture Dual Embeddings

#### Tables Schema

```sql
-- events: TEXT embeddings only (inchangÃ©)
CREATE TABLE events (
    id UUID PRIMARY KEY,
    timestamp TIMESTAMPTZ NOT NULL,
    content JSONB NOT NULL,
    embedding VECTOR(768),  -- nomic-text uniquement
    metadata JSONB
);

-- code_chunks: DUAL embeddings (nouveau Phase 1)
CREATE TABLE code_chunks (
    id UUID PRIMARY KEY,
    file_path TEXT NOT NULL,
    language TEXT NOT NULL,
    source_code TEXT NOT NULL,

    -- Dual embeddings
    embedding_text VECTOR(768),  -- nomic-text (docstrings, comments)
    embedding_code VECTOR(768),  -- jina-code (code semantic)

    metadata JSONB NOT NULL,
    indexed_at TIMESTAMPTZ DEFAULT NOW()
);

-- Index HNSW dual
CREATE INDEX idx_code_embedding_text ON code_chunks
USING hnsw (embedding_text vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_code_embedding_code ON code_chunks
USING hnsw (embedding_code vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

---

#### Use Cases Domain Selection

**EmbeddingDomain.TEXT**:
- âœ… Conversations agent memory
- âœ… Documentation gÃ©nÃ©rale
- âœ… Natural language queries
- âœ… UI user messages

**EmbeddingDomain.CODE**:
- âœ… Code snippets search
- âœ… Function/class similarity
- âœ… API usage examples
- âœ… Code generation context

**EmbeddingDomain.HYBRID**:
- âœ… Code avec docstrings riches
- âœ… Tutorials (code + explanation)
- âœ… Stack Overflow-like Q&A
- âœ… Code review comments

---

### Recommandation Finale Story 0.2

**Approche Phase 0**:
1. âœ… CrÃ©er `DualEmbeddingService` avec lazy loading
2. âœ… Ajouter enum `EmbeddingDomain`
3. âœ… ImplÃ©menter `generate_embedding(text, domain)`
4. âœ… Monitoring RAM via `get_stats()`
5. âœ… Tests unitaires:
   - Load text model only
   - Load code model only
   - Load both (HYBRID)
   - RAM usage < 1 GB
   - Dimensions 768D identical
6. âœ… Benchmark latence:
   - TEXT: <100ms single
   - CODE: <100ms single
   - HYBRID: <150ms single
7. âŒ **PAS de FP16/INT8 Phase 0** (complexitÃ© non nÃ©cessaire)
8. âŒ **PAS de model unloading Phase 0** (use case rare)

**Timeline**: 2-3 jours

**Story Points**: 5 (validÃ©, pas de changement)

---

## ðŸŽ¯ Phase 0 - Plan d'ExÃ©cution RÃ©visÃ©

### Jour 1: Alembic Setup (Story 0.1)

**Tasks**:
1. âœ… Installer dÃ©pendances
   ```bash
   pip install sqlalchemy[asyncio]>=2.0.0 alembic>=1.13.0
   ```

2. âœ… Initialiser Alembic async
   ```bash
   alembic init -t async alembic
   ```

3. âœ… Configurer `alembic.ini`
   - URL PostgreSQL asyncpg
   - Variables environnement

4. âœ… Configurer `alembic/env.py`
   - Async engine
   - pgvector extension check
   - Compare types

5. âœ… CrÃ©er migration baseline
   ```bash
   alembic revision -m "baseline_existing_tables"
   ```

6. âœ… Tester sur DB test
   ```bash
   export DATABASE_URL="postgresql+asyncpg://mnemo:pass@localhost/mnemolite_test"
   alembic upgrade head
   alembic downgrade -1
   alembic upgrade head
   ```

7. âœ… Valider sur DB prod
   ```bash
   alembic stamp head  # Mark current state
   ```

**Acceptance Criteria**:
- âœ… Alembic initialisÃ©
- âœ… Migration baseline appliquÃ©e
- âœ… Tests up/down passent
- âœ… Pas de rÃ©gression DB

---

### Jour 2-3: Dual Embeddings (Story 0.2)

**Tasks**:
1. âœ… CrÃ©er `api/services/dual_embedding_service.py`
   - Classe `DualEmbeddingService`
   - Enum `EmbeddingDomain`
   - Lazy loading pattern

2. âœ… Ajouter variables `.env.example`
   ```env
   CODE_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code
   ```

3. âœ… IntÃ©gration `api/dependencies.py`
   ```python
   @lru_cache()
   def get_embedding_service() -> DualEmbeddingService:
       return DualEmbeddingService()
   ```

4. âœ… Tests unitaires
   - `tests/test_services_dual_embedding.py`
   - Test TEXT domain
   - Test CODE domain
   - Test HYBRID domain
   - Test RAM budget
   - Test dimensions

5. âœ… Benchmark local
   ```python
   # scripts/benchmark_dual_embeddings.py
   async def benchmark():
       service = DualEmbeddingService()

       # TEXT
       start = time.time()
       await service.generate_embedding("Hello world", EmbeddingDomain.TEXT)
       text_latency = time.time() - start

       # CODE
       start = time.time()
       await service.generate_embedding("def foo(): pass", EmbeddingDomain.CODE)
       code_latency = time.time() - start

       # HYBRID
       start = time.time()
       await service.generate_embedding("def foo(): pass", EmbeddingDomain.HYBRID)
       hybrid_latency = time.time() - start

       # RAM
       stats = service.get_stats()
       ram_mb = stats['estimated_ram_mb']

       print(f"TEXT latency: {text_latency*1000:.1f}ms")
       print(f"CODE latency: {code_latency*1000:.1f}ms")
       print(f"HYBRID latency: {hybrid_latency*1000:.1f}ms")
       print(f"RAM usage: {ram_mb} MB")

       assert ram_mb < 1000, "RAM budget exceeded!"
   ```

6. âœ… Documentation
   - README: Section "Dual Embeddings"
   - API docs: `/v1/embeddings` endpoint examples

**Acceptance Criteria**:
- âœ… `DualEmbeddingService` opÃ©rationnel
- âœ… Tests passent (coverage >85%)
- âœ… Benchmark: RAM < 1 GB, latence < 150ms
- âœ… Documentation Ã  jour

---

## âš ï¸ Risques & Mitigations RÃ©visÃ©s

| Risque | ProbabilitÃ© | Impact | Mitigation 2024-2025 |
|--------|-------------|--------|----------------------|
| **Alembic + asyncpg incompatibilitÃ©** | Faible | Haut | Template async validÃ©, tutoriels 2024 |
| **pgvector types non reconnus** | Moyen | Haut | Extension check dans env.py |
| **Autogenerate faux positifs** | Moyen | Moyen | Migrations manuelles Phase 0 |
| **Dual models RAM overflow** | Faible | Haut | Lazy loading, monitoring, tests |
| **jina-code performance CPU** | Faible | Moyen | Benchmark validÃ©, batch_size tuning |
| **Breaking changes asyncpg pattern** | Faible | Moyen | Cohabitation asyncpg + SQLAlchemy Core |

---

## âœ… Checklist Pre-Kickoff Phase 0

### Infrastructure
- [ ] PostgreSQL 18 running + healthy
- [ ] pgvector 0.8.1 installÃ©
- [ ] asyncpg 0.29.0 installÃ©
- [ ] Python 3.11+ configured

### DÃ©pendances
- [ ] `sqlalchemy[asyncio]>=2.0.0` installÃ©
- [ ] `alembic>=1.13.0` installÃ©
- [ ] `sentence-transformers>=2.7.0` installÃ© (dÃ©jÃ  prÃ©sent)

### Configuration
- [ ] `.env.example` mis Ã  jour (CODE_EMBEDDING_MODEL)
- [ ] Variables environnement configurÃ©es
- [ ] DATABASE_URL format asyncpg validÃ©

### Tests
- [ ] DB test (mnemolite_test) accessible
- [ ] Tests coverage >85% target dÃ©fini
- [ ] Benchmark script prÃ©parÃ©

### Documentation
- [ ] README section "Phase 0" ajoutÃ©e
- [ ] ADR Alembic vs alternatives rÃ©digÃ©
- [ ] ADR jina-code vs alternatives rÃ©digÃ©

---

## ðŸ“š RÃ©fÃ©rences ClÃ©s 2024-2025

### Alembic + Async
- Alembic Cookbook: Using Asyncio with Alembic (2023+)
- berkkaraal.com: Setup FastAPI with Async SQLAlchemy 2 (Sept 2024)
- testdriven.io: FastAPI with Async SQLAlchemy, SQLModel and Alembic (2024)
- GitHub sqlalchemy/alembic Discussion #1208

### Sentence-Transformers Optimization
- Milvus: Reduce memory footprint Sentence Transformer models (2024)
- HuggingFace Optimum: Accelerate Sentence Transformers (Philipp Schmid)
- Medium: Optimizing Sentence Embedding Model (Aahana Khanal, 2024)

### jina-embeddings-v2-base-code
- jina.ai: Elevate Your Code Search with New Jina Code Embeddings (Feb 2024)
- HuggingFace: jinaai/jina-embeddings-v2-base-code
- CodeSearchNet benchmarks (15 datasets, 9/15 lead)

### Migration Tools Comparison
- atlasgo.io: Atlas vs Classic Schema Migration Tools (2025)
- pingcap.com: Choosing the Right Schema Migration Tool (2024)
- bytebase.com: Top Open Source Postgres Migration Tools (2025)

---

**Date**: 2025-10-15
**Version**: 2.0.0 - Post-Research 2024-2025
**Statut**: âœ… RECHERCHE COMPLÃˆTE - PRÃŠT POUR KICKOFF PHASE 0

**Prochaine Action**: Review stakeholders â†’ Kickoff Story 0.1 (Alembic Setup)
