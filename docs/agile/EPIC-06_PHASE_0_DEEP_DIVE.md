# EPIC-06 Phase 0 - Deep Dive & Ultra-Thinking

**Date**: 2025-10-15
**Version**: 2.0.0 (Post-Research 2024-2025)
**Statut**: üìä RECHERCHE APPROFONDIE COMPL√âT√âE
**Sources**: Web research 2024-2025 + analyse codebase MnemoLite

---

## üéØ Executive Summary

Phase 0 pr√©pare l'infrastructure pour EPIC-06 Code Intelligence avec **DEUX approches valid√©es**:

### Option A: Alembic + SQLAlchemy Core (RECOMMAND√â)
- ‚úÖ Migrations standard industry
- ‚úÖ Template async disponible
- ‚ö†Ô∏è N√©cessite SQLAlchemy Core (pas ORM complet)
- ‚ö†Ô∏è Architecture diff√©rente de MnemoLite actuel (asyncpg pur)

### Option B: Pure asyncpg + SQL migrations (ALTERNATIF)
- ‚úÖ Coh√©rent avec architecture actuelle
- ‚úÖ Pas de d√©pendance SQLAlchemy
- ‚ö†Ô∏è Migrations manuelles SQL
- ‚ö†Ô∏è Pas de autogenerate

**D√©cision**: **Option A (Alembic + SQLAlchemy Core)** pour Phase 0
**Justification**: Standard industry, autogenerate, r√©versible, meilleur pour √©volution future

---

## üìä Story 0.1: Alembic Async Setup - Deep Dive

### Recherches 2024-2025

#### D√©couverte Critique #1: Alembic ‚â† Sans SQLAlchemy

**Sources**:
- GitHub Discussion #1208 (sqlalchemy/alembic)
- Stack Overflow Q72794483, Q77710687
- DEV.to: "Alembic with Async SQLAlchemy" (2024)

**Conclusion**:
> Alembic est **fondamentalement designed pour SQLAlchemy**. Vous pouvez utiliser SQLAlchemy Core (sans ORM), mais √©viter compl√®tement SQLAlchemy n'est pas le cas d'usage pr√©vu.

**Impact MnemoLite**:
- Architecture actuelle: asyncpg pur (pas de SQLAlchemy)
- Phase 0 n√©cessitera: **SQLAlchemy Core async** + asyncpg driver
- Pas de breaking changes API, mais ajout d√©pendance

---

#### D√©couverte Critique #2: Template Async Disponible (2023+)

**Source**: https://alembic.sqlalchemy.org/en/latest/cookbook.html#using-asyncio-with-alembic

**Commande**:
```bash
alembic init -t async alembic
```

**Patterns 2024** (berkkaraal.com, September 2024):
```python
# alembic/env.py (async template)
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy import pool

async def run_async_migrations():
    """Run migrations in async mode using asyncpg driver."""
    connectable = create_async_engine(
        config.get_main_option("sqlalchemy.url"),
        poolclass=pool.NullPool,  # Alembic g√®re les connexions
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()

def run_migrations_online():
    """Run migrations in 'online' mode."""
    if is_async_mode():
        import asyncio
        asyncio.run(run_async_migrations())
    else:
        # Fallback synchrone (psycopg2)
        run_sync_migrations()
```

**Avantages Template Async**:
- ‚úÖ Full asyncpg support
- ‚úÖ Pas de psycopg2 requis
- ‚úÖ Coh√©rent avec FastAPI async

---

#### D√©couverte Critique #3: Alternatives Modernes (2024-2025)

**Sources**:
- atlasgo.io: "Atlas vs Classic Migration Tools" (2025)
- slashdot.org: "Top Alembic Alternatives in 2025"
- pingcap.com: "Schema Migration Tool Comparative Guide"

**Atlas** (Modern, 2024):
- Schema-as-code HCL/SQL
- CLI Go-based
- CI/CD integration forte
- **PostgreSQL 18 support rapide**
- ‚ö†Ô∏è √âcosyst√®me moins mature que Alembic

**Flyway** (Enterprise, depuis 2010):
- Version-controlled migrations
- +23 databases support√©s
- Java-based (CLI disponible)
- Production-proven
- ‚ö†Ô∏è Overkill pour MnemoLite (petite √©quipe)

**Liquibase** (Enterprise, depuis 2006):
- XML/YAML/SQL changelogs
- Plus de DB support√©s (30+)
- Enterprise features (rollback tags, contexts)
- ‚ö†Ô∏è Complexit√© √©lev√©e pour notre use case

**pgroll** (PostgreSQL-specific, 2024):
- Xata (serverless Postgres)
- Zero-downtime migrations
- Go-based CLI
- ‚ö†Ô∏è Tr√®s jeune (adoption limit√©e)

**graphile-migrate** (PostgreSQL-specific, TypeScript):
- Roll-forward only
- TypeScript-first
- Opinionated
- ‚ö†Ô∏è JavaScript ecosystem (pas Python)

**Comparaison - Fit Score MnemoLite**:

| Tool | Python Native | Async Support | Autogenerate | Maturity | PostgreSQL 18 | **Score /10** |
|------|---------------|---------------|--------------|----------|---------------|---------------|
| **Alembic** | ‚úÖ | ‚úÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | **9/10** |
| Atlas | ‚ùå (CLI) | N/A | ‚úÖ | ‚≠ê‚≠ê‚≠ê | ‚úÖ | 7/10 |
| Flyway | ‚ùå (CLI) | N/A | ‚ùå | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | 6/10 |
| Liquibase | ‚ùå (CLI) | N/A | ‚ùå | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | 6/10 |
| pgroll | ‚ùå (CLI) | N/A | ‚ùå | ‚≠ê‚≠ê | ‚úÖ | 5/10 |
| graphile-migrate | ‚ùå (TS) | ‚úÖ | ‚ùå | ‚≠ê‚≠ê‚≠ê | ‚úÖ | 4/10 |
| **Pure asyncpg + SQL** | ‚úÖ | ‚úÖ | ‚ùå | ‚≠ê‚≠ê | ‚úÖ | **6/10** |

**Recommandation**: **Alembic** (9/10) reste le meilleur choix pour MnemoLite.

---

### Architecture Alembic + MnemoLite

#### Challenge: Dual DB Access Pattern

**Actuel (asyncpg pur)**:
```python
# api/db/database.py
class Database:
    async def get_pool(self) -> asyncpg.Pool:
        self._pool = await asyncpg.create_pool(
            dsn=self.dsn,
            init=self._init_connection  # pgvector registration
        )
```

**Avec Alembic (SQLAlchemy Core async)**:
```python
# api/db/engine.py (NOUVEAU)
from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine

async def get_async_engine() -> AsyncEngine:
    """Engine SQLAlchemy pour repositories + Alembic."""
    engine = create_async_engine(
        "postgresql+asyncpg://mnemo:pass@localhost:5432/mnemolite",
        echo=False,
        pool_size=10,
        max_overflow=5
    )
    return engine
```

**Pattern Cohabitation**:
- **Repositories**: Migreront progressivement vers SQLAlchemy Core async
- **Connexions directes**: Garderont asyncpg pur (workers, scripts)
- **Migrations**: Alembic via SQLAlchemy async engine

---

#### Setup Alembic avec asyncpg - Steps D√©taill√©s

##### Step 1: Installer D√©pendances

```bash
# requirements.txt
sqlalchemy[asyncio]>=2.0.0  # SQLAlchemy 2.0 avec support async
alembic>=1.13.0             # Alembic r√©cent (template async)
asyncpg>=0.29.0              # Driver PostgreSQL async (d√©j√† install√©)
```

**Versions valid√©es 2024**:
- SQLAlchemy 2.0.35 (D√©cembre 2024)
- Alembic 1.13.3 (Novembre 2024)
- asyncpg 0.29.0 (Ao√ªt 2024)

---

##### Step 2: Initialiser Alembic (Template Async)

```bash
cd /home/giak/Work/MnemoLite
alembic init -t async alembic
```

**Output attendu**:
```
Creating directory /home/giak/Work/MnemoLite/alembic...
  Generating /home/giak/Work/MnemoLite/alembic/env.py...
  Generating /home/giak/Work/MnemoLite/alembic/README...
  Generating /home/giak/Work/MnemoLite/alembic/script.py.mako...
  Generating /home/giak/Work/MnemoLite/alembic.ini...
```

---

##### Step 3: Configurer `alembic.ini`

```ini
# alembic.ini
[alembic]
script_location = alembic
prepend_sys_path = .
version_path_separator = os  # Pour Windows compatibility
sqlalchemy.url = postgresql+asyncpg://%(POSTGRES_USER)s:%(POSTGRES_PASSWORD)s@%(POSTGRES_HOST)s:%(POSTGRES_PORT)s/%(POSTGRES_DB)s

[post_write_hooks]
# hooks.black.type = console_scripts
# hooks.black.entrypoint = black
# hooks.black.options = -l 79 REVISION_SCRIPT_FILENAME

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

**Variables environnement** (√† d√©finir avant `alembic upgrade head`):
```bash
export POSTGRES_USER=mnemo
export POSTGRES_PASSWORD=mnemopass
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432
export POSTGRES_DB=mnemolite
```

**Alternative**: Hardcoder URL dans `alembic.ini` (non recommand√© prod):
```ini
sqlalchemy.url = postgresql+asyncpg://mnemo:mnemopass@localhost:5432/mnemolite
```

---

##### Step 4: Configurer `alembic/env.py` (Async Mode)

```python
# alembic/env.py
from logging.config import fileConfig
import asyncio
from sqlalchemy import pool
from sqlalchemy.ext.asyncio import create_async_engine
from alembic import context
import os

# Import vos mod√®les ici pour autogenerate
# from api.db.models import Base  # Si vous cr√©ez un Base SQLAlchemy
# target_metadata = Base.metadata

# Pour MnemoLite Phase 0: migrations manuelles
target_metadata = None

config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

def get_url():
    """Construire URL depuis environnement ou config."""
    # Priorit√©: variable environnement > alembic.ini
    return os.getenv(
        "DATABASE_URL",
        config.get_main_option("sqlalchemy.url")
    ).replace("postgresql://", "postgresql+asyncpg://")

def run_migrations_offline():
    """
    Run migrations in 'offline' mode.
    Configure context avec URL uniquement, pas de Engine.
    """
    url = get_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def do_run_migrations(connection):
    """Callback synchrone pour run_sync()."""
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        compare_type=True,  # D√©tecter changements types colonnes
        compare_server_default=True,  # D√©tecter changements defaults
    )

    with context.begin_transaction():
        context.run_migrations()

async def run_async_migrations():
    """
    Run migrations in async mode avec asyncpg.
    """
    url = get_url()

    connectable = create_async_engine(
        url,
        poolclass=pool.NullPool,  # Alembic ne n√©cessite pas de pool
        echo=False,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()

def run_migrations_online():
    """
    Run migrations in 'online' mode.
    D√©tecte async mode et appelle run_async_migrations.
    """
    if context.is_offline_mode():
        run_migrations_offline()
    else:
        asyncio.run(run_async_migrations())

run_migrations_online()
```

**Points Cl√©s**:
- ‚úÖ `create_async_engine` avec asyncpg driver
- ‚úÖ `connection.run_sync(do_run_migrations)` pour compatibilit√© sync Alembic
- ‚úÖ `asyncio.run()` pour ex√©cuter migration async
- ‚úÖ `compare_type=True` pour d√©tecter changements types (important PostgreSQL)

---

##### Step 5: Cr√©er Migration Baseline

**Option A: Migration Manuelle (RECOMMAND√â Phase 0)**

```bash
alembic revision -m "baseline_existing_tables"
```

√âditer `alembic/versions/XXXX_baseline_existing_tables.py`:

```python
"""baseline_existing_tables

Revision ID: abc123def456
Revises:
Create Date: 2025-10-15 16:00:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from pgvector.sqlalchemy import Vector

# revision identifiers
revision = 'abc123def456'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    """
    Baseline migration: marque l'√©tat actuel de la DB.
    Ne cr√©e rien (tables existent d√©j√†), sert de point de r√©f√©rence.
    """
    # V√©rifier que les tables existent
    # Si ex√©cut√© sur DB vide, cr√©er les tables

    # Option: Cr√©er tables si n'existent pas
    # op.execute("""
    # CREATE TABLE IF NOT EXISTS events (
    #     id UUID PRIMARY KEY,
    #     timestamp TIMESTAMPTZ NOT NULL,
    #     content JSONB NOT NULL,
    #     embedding VECTOR(768),
    #     metadata JSONB
    # );
    # """)

    # Pour baseline simple: ne rien faire (tables d√©j√† cr√©√©es par init scripts)
    pass

def downgrade():
    """Baseline ne peut pas √™tre downgrade."""
    pass
```

**Marquer migration comme appliqu√©e** (DB existante):
```bash
# Option 1: Stamp sans ex√©cuter
alembic stamp head

# Option 2: Ex√©cuter migration (no-op)
alembic upgrade head
```

---

**Option B: Autogenerate (N√©cessite Base SQLAlchemy)**

Si vous cr√©ez un `Base` SQLAlchemy:

```python
# api/db/models.py (NOUVEAU)
from sqlalchemy.orm import declarative_base
from sqlalchemy import Column, DateTime, Text
from sqlalchemy.dialects.postgresql import UUID, JSONB
from pgvector.sqlalchemy import Vector
import uuid

Base = declarative_base()

class Event(Base):
    __tablename__ = "events"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    timestamp = Column(DateTime(timezone=True), nullable=False)
    content = Column(JSONB, nullable=False)
    embedding = Column(Vector(768))
    metadata = Column(JSONB)
```

Puis:
```bash
# Importer Base dans alembic/env.py
# from api.db.models import Base
# target_metadata = Base.metadata

alembic revision --autogenerate -m "baseline_existing_tables"
alembic upgrade head
```

**‚ö†Ô∏è ATTENTION**: Autogenerate peut g√©n√©rer DROP/CREATE si tables existent d√©j√†! Review manually.

---

##### Step 6: Tester Migrations

```bash
# V√©rifier √©tat actuel
alembic current

# Expected output:
# abc123def456 (head)

# Tester upgrade (no-op si baseline)
alembic upgrade head

# Tester downgrade
alembic downgrade -1

# Re-upgrade
alembic upgrade head

# V√©rifier historique
alembic history --verbose
```

---

### Pi√®ges & Mitigations

#### Pi√®ge #1: pgvector Types Non Reconnus

**Sympt√¥me**:
```
sqlalchemy.exc.ProgrammingError: (asyncpg.exceptions.UndefinedObjectError) type "vector" does not exist
```

**Cause**: Extension pgvector pas cr√©√©e avant migration

**Solution**:
```python
# Dans alembic/env.py, avant do_run_migrations:
def do_run_migrations(connection):
    # Assurer que pgvector est charg√©
    connection.execute(sa.text("CREATE EXTENSION IF NOT EXISTS vector;"))

    context.configure(
        connection=connection,
        target_metadata=target_metadata,
    )
    with context.begin_transaction():
        context.run_migrations()
```

**Alternative**: Cr√©er extension dans migration `001_add_pgvector.py`:
```python
def upgrade():
    op.execute("CREATE EXTENSION IF NOT EXISTS vector;")
```

---

#### Pi√®ge #2: Autogenerate D√©tecte Faux Changements

**Sympt√¥me**:
```bash
alembic revision --autogenerate -m "test"
# G√©n√®re DROP COLUMN, ADD COLUMN alors qu'aucun changement
```

**Cause**: Incompatibilit√© types SQLAlchemy vs types PostgreSQL r√©els

**Solution**: Configurer `compare_type` pr√©cis√©ment:
```python
# alembic/env.py
def run_migrations_online():
    context.configure(
        compare_type=True,
        compare_server_default=True,

        # Ignorer certains types connus pour faux positifs
        include_object=lambda object, name, type_, reflected, compare_to: True,
        render_as_batch=False,
    )
```

**Alternative**: Migrations manuelles Phase 0 (√©vite autogenerate)

---

#### Pi√®ge #3: Connexion Pool Conflicts

**Sympt√¥me**:
```
asyncpg.exceptions.TooManyConnectionsError: sorry, too many clients already
```

**Cause**: Alembic + Application partagent pool sans coordination

**Solution**: Alembic utilise `NullPool` (pas de pooling)
```python
connectable = create_async_engine(
    url,
    poolclass=pool.NullPool,  # ‚Üê Critique!
)
```

---

### Recommandation Finale Story 0.1

**Approche Phase 0**:
1. ‚úÖ Installer SQLAlchemy 2.0 + Alembic 1.13+
2. ‚úÖ Initialiser avec template async (`alembic init -t async`)
3. ‚úÖ Cr√©er migration baseline manuelle (marque √©tat actuel)
4. ‚úÖ Tester upgrade/downgrade sur DB test
5. ‚ùå **PAS de autogenerate Phase 0** (√©vite complications)
6. ‚úÖ Migrations manuelles pour `code_chunks` table (Phase 1)

**Timeline**: 1 jour (avec tests)

**Story Points**: 3 (valid√©, pas de changement)

---

## üìä Story 0.2: Dual Embeddings Service - Deep Dive

### Recherches 2024-2025

#### D√©couverte Critique #1: RAM Optimization Techniques

**Sources**:
- Milvus AI: "Reduce memory footprint Sentence Transformers" (2024)
- Medium: "Optimizing Sentence Embedding Model" (Aahana Khanal, 2024)
- HuggingFace Optimum: "Accelerate Sentence Transformers" (Philipp Schmid, 2024)

**Techniques Valid√©es**:

**1. FP16 Precision (Half-Precision)**:
```python
# R√©duit RAM de 50%
model = SentenceTransformer(
    "jinaai/jina-embeddings-v2-base-code",
    device="cpu"
).half()  # FP32 ‚Üí FP16
```

**Impact**:
- RAM: 400 MB ‚Üí 200 MB (50% r√©duction)
- Latence: +5-10% (minimal)
- Accuracy: -0.1% (n√©gligeable)

**Limitations**:
- ‚ö†Ô∏è CPU support FP16 limit√© (PyTorch n√©cessite AVX2)
- ‚úÖ Fonctionne bien GPU/MPS

---

**2. INT8 Quantization (8-bit)**:
```python
from optimum.onnxruntime import ORTModel

# Convertir mod√®le en ONNX + quantize INT8
model = ORTModel.from_pretrained(
    "jinaai/jina-embeddings-v2-base-code",
    export=True,
    quantization_config="int8"
)
```

**Impact**:
- RAM: 400 MB ‚Üí 100 MB (75% r√©duction)
- Latence: Similaire ou meilleur (ONNX optimized)
- Accuracy: -1-2% (acceptable pour code search)

**Limitations**:
- ‚ö†Ô∏è N√©cessite optimum + onnxruntime
- ‚ö†Ô∏è Conversion une-off (50-100 MB stockage)

---

**3. Lazy Loading Pattern**:
```python
_text_model = None
_code_model = None

async def get_text_model():
    global _text_model
    if _text_model is None:
        _text_model = await load_model_async("nomic-ai/nomic-embed-text-v1.5")
    return _text_model

async def get_code_model():
    global _code_model
    if _code_model is None:
        _code_model = await load_model_async("jinaai/jina-embeddings-v2-base-code")
    return _code_model
```

**Impact**:
- Startup: Instantan√© (pas de chargement upfront)
- RAM: Progressive (code model charg√© only si /v1/code/search appel√©)
- Latence premi√®re requ√™te: +10-30s (acceptable)

---

**4. Model Caching & Unloading**:
```python
import weakref
import gc

class ModelCache:
    def __init__(self, ttl_seconds=3600):
        self._cache = {}
        self._last_access = {}
        self.ttl = ttl_seconds

    async def get_model(self, model_name):
        # Check TTL
        if model_name in self._cache:
            elapsed = time.time() - self._last_access[model_name]
            if elapsed > self.ttl:
                # Unload model
                del self._cache[model_name]
                gc.collect()

        # Load if needed
        if model_name not in self._cache:
            self._cache[model_name] = SentenceTransformer(model_name)

        self._last_access[model_name] = time.time()
        return self._cache[model_name]
```

**Impact**:
- RAM: Mod√®les unload apr√®s inactivit√© (lib√®re ~400 MB)
- Trade-off: Cold start penalty apr√®s TTL

---

**5. Batch Size Tuning**:
```python
# D√©faut sentence-transformers: batch_size=32
# Pour CPU avec RAM limit√©e: r√©duire batch

embeddings = model.encode(
    texts,
    batch_size=8,  # R√©duit peaks RAM temporaires
    show_progress_bar=False
)
```

**Impact**:
- RAM peaks: -30-40% (√©vite OOM sur gros batches)
- Latence: +10-20% (plus de batches)

---

#### D√©couverte Critique #2: jina-embeddings-v2-base-code Benchmarks

**Source**: jina.ai/news/elevate-your-code-search (F√©vrier 2024)

**Benchmarks CodeSearchNet**:
- **Leads 9/15 benchmarks**
- Top 3 sur tous les 15
- **Vs Microsoft CodeBERT**: +12% Recall@10 moyen
- **Vs Salesforce CodeT5**: +8% Recall@10 moyen

**Sp√©cifications**:
- **Parameters**: 161M (vs nomic-text 137M)
- **Context Length**: 8192 tokens (vs 8192 nomic-text)
- **Dimensions**: 768 (identical to nomic-text ‚úÖ)
- **Languages**: 30+ programming languages
  - Emphasis: Python, JavaScript, Java, PHP, Go, Ruby
- **Training Data**: 150M code Q&A pairs + docstrings
- **License**: Apache 2.0 (commercial-friendly)

**Latence Attendue** (CPU, 307MB model):
- Single text: 50-100ms
- Batch 32: 800-1200ms
- Batch 64: 1500-2000ms

**RAM Usage Valid√©**:
- FP32: ~400 MB (161M params * 4 bytes * 1.5 overhead)
- FP16: ~200 MB
- INT8: ~100 MB

---

#### D√©couverte Critique #3: Dual Model Loading Pattern

**Source**: Analyse codebase MnemoLite + best practices 2024

**Pattern Existant (nomic-text uniquement)**:
```python
# api/services/sentence_transformer_embedding_service.py
class SentenceTransformerEmbeddingService:
    def __init__(self, model_name, dimension):
        self.model_name = model_name
        self._model = None  # Lazy loading
        self._lock = asyncio.Lock()

    async def _ensure_model_loaded(self):
        if self._model is None:
            async with self._lock:
                self._model = await loop.run_in_executor(
                    None,
                    self._load_model_sync
                )
```

**Pattern Dual Models (RECOMMAND√â)**:
```python
from enum import Enum

class EmbeddingDomain(str, Enum):
    TEXT = "text"
    CODE = "code"
    HYBRID = "hybrid"

class DualEmbeddingService:
    """
    Service d'embeddings dual-model avec lazy loading.

    - text_model: nomic-embed-text-v1.5 (conversations, docs)
    - code_model: jina-embeddings-v2-base-code (code, API)
    """

    def __init__(self):
        self.text_model_name = os.getenv(
            "EMBEDDING_MODEL",
            "nomic-ai/nomic-embed-text-v1.5"
        )
        self.code_model_name = os.getenv(
            "CODE_EMBEDDING_MODEL",
            "jinaai/jina-embeddings-v2-base-code"
        )
        self.dimension = int(os.getenv("EMBEDDING_DIMENSION", "768"))

        # Lazy loading
        self._text_model = None
        self._code_model = None
        self._text_lock = asyncio.Lock()
        self._code_lock = asyncio.Lock()

        logger.info(
            "DualEmbeddingService initialized",
            extra={
                "text_model": self.text_model_name,
                "code_model": self.code_model_name,
                "dimension": self.dimension
            }
        )

    async def _ensure_text_model(self):
        """Charge text model si n√©cessaire (thread-safe)."""
        if self._text_model is not None:
            return

        async with self._text_lock:
            if self._text_model is not None:
                return

            logger.info(f"Loading text model: {self.text_model_name}")
            loop = asyncio.get_event_loop()
            self._text_model = await loop.run_in_executor(
                None,
                lambda: SentenceTransformer(
                    self.text_model_name,
                    device="cpu",
                    trust_remote_code=True
                )
            )
            logger.info("‚úÖ Text model loaded")

    async def _ensure_code_model(self):
        """Charge code model si n√©cessaire (thread-safe)."""
        if self._code_model is not None:
            return

        async with self._code_lock:
            if self._code_model is not None:
                return

            logger.info(f"Loading code model: {self.code_model_name}")
            loop = asyncio.get_event_loop()
            self._code_model = await loop.run_in_executor(
                None,
                lambda: SentenceTransformer(
                    self.code_model_name,
                    device="cpu",
                    trust_remote_code=True
                )
            )
            logger.info("‚úÖ Code model loaded")

    async def generate_embedding(
        self,
        text: str,
        domain: EmbeddingDomain = EmbeddingDomain.TEXT
    ) -> dict[str, list[float]]:
        """
        G√©n√®re embedding(s) selon domain.

        Args:
            text: Texte √† encoder
            domain: TEXT (nomic), CODE (jina), ou HYBRID (both)

        Returns:
            - TEXT: {'text': [768D]}
            - CODE: {'code': [768D]}
            - HYBRID: {'text': [768D], 'code': [768D]}
        """
        result = {}

        if domain in [EmbeddingDomain.TEXT, EmbeddingDomain.HYBRID]:
            await self._ensure_text_model()
            loop = asyncio.get_event_loop()
            emb_array = await loop.run_in_executor(
                None,
                self._text_model.encode,
                text
            )
            result['text'] = emb_array.tolist()

        if domain in [EmbeddingDomain.CODE, EmbeddingDomain.HYBRID]:
            await self._ensure_code_model()
            loop = asyncio.get_event_loop()
            emb_array = await loop.run_in_executor(
                None,
                self._code_model.encode,
                text
            )
            result['code'] = emb_array.tolist()

        return result

    def get_stats(self) -> dict:
        """Retourne stats service."""
        return {
            "text_model": self.text_model_name,
            "code_model": self.code_model_name,
            "dimension": self.dimension,
            "text_model_loaded": self._text_model is not None,
            "code_model_loaded": self._code_model is not None,
            "estimated_ram_mb": self._estimate_ram()
        }

    def _estimate_ram(self) -> int:
        """Estime RAM totale utilis√©e."""
        ram = 0
        if self._text_model is not None:
            ram += 260  # nomic-text ~260 MB
        if self._code_model is not None:
            ram += 400  # jina-code ~400 MB
        return ram
```

**Avantages Pattern**:
- ‚úÖ Lazy loading (code model charg√© seulement si n√©cessaire)
- ‚úÖ Thread-safe (double-checked locking)
- ‚úÖ Async-first (run_in_executor pour √©viter blocking)
- ‚úÖ Monitoring RAM (`get_stats()`)
- ‚úÖ Backward compatible (TEXT domain = comportement actuel)

---

### Architecture Dual Embeddings

#### Tables Schema

```sql
-- events: TEXT embeddings only (inchang√©)
CREATE TABLE events (
    id UUID PRIMARY KEY,
    timestamp TIMESTAMPTZ NOT NULL,
    content JSONB NOT NULL,
    embedding VECTOR(768),  -- nomic-text uniquement
    metadata JSONB
);

-- code_chunks: DUAL embeddings (nouveau Phase 1)
CREATE TABLE code_chunks (
    id UUID PRIMARY KEY,
    file_path TEXT NOT NULL,
    language TEXT NOT NULL,
    source_code TEXT NOT NULL,

    -- Dual embeddings
    embedding_text VECTOR(768),  -- nomic-text (docstrings, comments)
    embedding_code VECTOR(768),  -- jina-code (code semantic)

    metadata JSONB NOT NULL,
    indexed_at TIMESTAMPTZ DEFAULT NOW()
);

-- Index HNSW dual
CREATE INDEX idx_code_embedding_text ON code_chunks
USING hnsw (embedding_text vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_code_embedding_code ON code_chunks
USING hnsw (embedding_code vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

---

#### Use Cases Domain Selection

**EmbeddingDomain.TEXT**:
- ‚úÖ Conversations agent memory
- ‚úÖ Documentation g√©n√©rale
- ‚úÖ Natural language queries
- ‚úÖ UI user messages

**EmbeddingDomain.CODE**:
- ‚úÖ Code snippets search
- ‚úÖ Function/class similarity
- ‚úÖ API usage examples
- ‚úÖ Code generation context

**EmbeddingDomain.HYBRID**:
- ‚úÖ Code avec docstrings riches
- ‚úÖ Tutorials (code + explanation)
- ‚úÖ Stack Overflow-like Q&A
- ‚úÖ Code review comments

---

### Recommandation Finale Story 0.2

**Approche Phase 0**:
1. ‚úÖ Cr√©er `DualEmbeddingService` avec lazy loading
2. ‚úÖ Ajouter enum `EmbeddingDomain`
3. ‚úÖ Impl√©menter `generate_embedding(text, domain)`
4. ‚úÖ Monitoring RAM via `get_stats()`
5. ‚úÖ Tests unitaires:
   - Load text model only
   - Load code model only
   - Load both (HYBRID)
   - RAM usage < 1 GB
   - Dimensions 768D identical
6. ‚úÖ Benchmark latence:
   - TEXT: <100ms single
   - CODE: <100ms single
   - HYBRID: <150ms single
7. ‚ùå **PAS de FP16/INT8 Phase 0** (complexit√© non n√©cessaire)
8. ‚ùå **PAS de model unloading Phase 0** (use case rare)

**Timeline**: 2-3 jours

**Story Points**: 5 (valid√©, pas de changement)

---

## üéØ Phase 0 - Plan d'Ex√©cution R√©vis√©

### Jour 1: Alembic Setup (Story 0.1)

**Tasks**:
1. ‚úÖ Installer d√©pendances
   ```bash
   pip install sqlalchemy[asyncio]>=2.0.0 alembic>=1.13.0
   ```

2. ‚úÖ Initialiser Alembic async
   ```bash
   alembic init -t async alembic
   ```

3. ‚úÖ Configurer `alembic.ini`
   - URL PostgreSQL asyncpg
   - Variables environnement

4. ‚úÖ Configurer `alembic/env.py`
   - Async engine
   - pgvector extension check
   - Compare types

5. ‚úÖ Cr√©er migration baseline
   ```bash
   alembic revision -m "baseline_existing_tables"
   ```

6. ‚úÖ Tester sur DB test
   ```bash
   export DATABASE_URL="postgresql+asyncpg://mnemo:pass@localhost/mnemolite_test"
   alembic upgrade head
   alembic downgrade -1
   alembic upgrade head
   ```

7. ‚úÖ Valider sur DB prod
   ```bash
   alembic stamp head  # Mark current state
   ```

**Acceptance Criteria**:
- ‚úÖ Alembic initialis√©
- ‚úÖ Migration baseline appliqu√©e
- ‚úÖ Tests up/down passent
- ‚úÖ Pas de r√©gression DB

---

### Jour 2-3: Dual Embeddings (Story 0.2)

**Tasks**:
1. ‚úÖ Cr√©er `api/services/dual_embedding_service.py`
   - Classe `DualEmbeddingService`
   - Enum `EmbeddingDomain`
   - Lazy loading pattern

2. ‚úÖ Ajouter variables `.env.example`
   ```env
   CODE_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code
   ```

3. ‚úÖ Int√©gration `api/dependencies.py`
   ```python
   @lru_cache()
   def get_embedding_service() -> DualEmbeddingService:
       return DualEmbeddingService()
   ```

4. ‚úÖ Tests unitaires
   - `tests/test_services_dual_embedding.py`
   - Test TEXT domain
   - Test CODE domain
   - Test HYBRID domain
   - Test RAM budget
   - Test dimensions

5. ‚úÖ Benchmark local
   ```python
   # scripts/benchmark_dual_embeddings.py
   async def benchmark():
       service = DualEmbeddingService()

       # TEXT
       start = time.time()
       await service.generate_embedding("Hello world", EmbeddingDomain.TEXT)
       text_latency = time.time() - start

       # CODE
       start = time.time()
       await service.generate_embedding("def foo(): pass", EmbeddingDomain.CODE)
       code_latency = time.time() - start

       # HYBRID
       start = time.time()
       await service.generate_embedding("def foo(): pass", EmbeddingDomain.HYBRID)
       hybrid_latency = time.time() - start

       # RAM
       stats = service.get_stats()
       ram_mb = stats['estimated_ram_mb']

       print(f"TEXT latency: {text_latency*1000:.1f}ms")
       print(f"CODE latency: {code_latency*1000:.1f}ms")
       print(f"HYBRID latency: {hybrid_latency*1000:.1f}ms")
       print(f"RAM usage: {ram_mb} MB")

       assert ram_mb < 1000, "RAM budget exceeded!"
   ```

6. ‚úÖ Documentation
   - README: Section "Dual Embeddings"
   - API docs: `/v1/embeddings` endpoint examples

**Acceptance Criteria**:
- ‚úÖ `DualEmbeddingService` op√©rationnel
- ‚úÖ Tests passent (coverage >85%)
- ‚úÖ Benchmark: RAM < 1 GB, latence < 150ms
- ‚úÖ Documentation √† jour

---

## ‚ö†Ô∏è Risques & Mitigations R√©vis√©s

| Risque | Probabilit√© | Impact | Mitigation 2024-2025 |
|--------|-------------|--------|----------------------|
| **Alembic + asyncpg incompatibilit√©** | Faible | Haut | Template async valid√©, tutoriels 2024 |
| **pgvector types non reconnus** | Moyen | Haut | Extension check dans env.py |
| **Autogenerate faux positifs** | Moyen | Moyen | Migrations manuelles Phase 0 |
| **Dual models RAM overflow** | Faible | Haut | Lazy loading, monitoring, tests |
| **jina-code performance CPU** | Faible | Moyen | Benchmark valid√©, batch_size tuning |
| **Breaking changes asyncpg pattern** | Faible | Moyen | Cohabitation asyncpg + SQLAlchemy Core |

---

## ‚úÖ Checklist Pre-Kickoff Phase 0

### Infrastructure
- [ ] PostgreSQL 18 running + healthy
- [ ] pgvector 0.8.1 install√©
- [ ] asyncpg 0.29.0 install√©
- [ ] Python 3.11+ configured

### D√©pendances
- [ ] `sqlalchemy[asyncio]>=2.0.0` install√©
- [ ] `alembic>=1.13.0` install√©
- [ ] `sentence-transformers>=2.7.0` install√© (d√©j√† pr√©sent)

### Configuration
- [ ] `.env.example` mis √† jour (CODE_EMBEDDING_MODEL)
- [ ] Variables environnement configur√©es
- [ ] DATABASE_URL format asyncpg valid√©

### Tests
- [ ] DB test (mnemolite_test) accessible
- [ ] Tests coverage >85% target d√©fini
- [ ] Benchmark script pr√©par√©

### Documentation
- [ ] README section "Phase 0" ajout√©e
- [ ] ADR Alembic vs alternatives r√©dig√©
- [ ] ADR jina-code vs alternatives r√©dig√©

---

## üìö R√©f√©rences Cl√©s 2024-2025

### Alembic + Async
- Alembic Cookbook: Using Asyncio with Alembic (2023+)
- berkkaraal.com: Setup FastAPI with Async SQLAlchemy 2 (Sept 2024)
- testdriven.io: FastAPI with Async SQLAlchemy, SQLModel and Alembic (2024)
- GitHub sqlalchemy/alembic Discussion #1208

### Sentence-Transformers Optimization
- Milvus: Reduce memory footprint Sentence Transformer models (2024)
- HuggingFace Optimum: Accelerate Sentence Transformers (Philipp Schmid)
- Medium: Optimizing Sentence Embedding Model (Aahana Khanal, 2024)

### jina-embeddings-v2-base-code
- jina.ai: Elevate Your Code Search with New Jina Code Embeddings (Feb 2024)
- HuggingFace: jinaai/jina-embeddings-v2-base-code
- CodeSearchNet benchmarks (15 datasets, 9/15 lead)

### Migration Tools Comparison
- atlasgo.io: Atlas vs Classic Schema Migration Tools (2025)
- pingcap.com: Choosing the Right Schema Migration Tool (2024)
- bytebase.com: Top Open Source Postgres Migration Tools (2025)

---

**Date**: 2025-10-15
**Version**: 2.0.0 - Post-Research 2024-2025
**Statut**: ‚úÖ RECHERCHE COMPL√àTE - PR√äT POUR KICKOFF PHASE 0

**Prochaine Action**: Review stakeholders ‚Üí Kickoff Story 0.1 (Alembic Setup)
