# EPIC-06: Code Intelligence pour MnemoLite

**Statut**: üöß **EN COURS** - Phase 0 COMPLETE (100%), Phase 1 PARTIAL (86% - Stories 1, 2bis & 3)
**Priorit√©**: MOYEN-HAUT
**Complexit√©**: HAUTE
**Date Cr√©ation**: 2025-10-15
**Derni√®re Mise √† Jour**: 2025-10-16 (Phase 1 Stories 1, 2bis & 3 Complete)
**Version MnemoLite**: v1.4.0+ (Post-v1.3.0)

---

## üéØ Vision & Objectif

**√âtendre MnemoLite avec des capacit√©s code intelligence** TOUT EN **pr√©servant son r√¥le principal de m√©moire cognitive pour agents IA** (conversations, documentation technique, d√©cisions architecturales).

### ‚ö†Ô∏è Contrainte Critique

**MnemoLite doit RESTER une m√©moire pour assistant** :
- ‚úÖ **Use case principal** : Conversations avec Claude/GPT, notes de dev, ADRs, documentation technique
- ‚úÖ **Use case nouveau** : Indexation et recherche de code (compl√©mentaire, pas remplacement)
- ‚úÖ **Architecture** : Dual-purpose (texte g√©n√©ral + code sp√©cialis√©)
- ‚úÖ **Backward compatibility** : Table `events` inchang√©e, API v1 intacte

### Objectif Principal

Ajouter des capacit√©s **code-aware** √† MnemoLite pour :
1. **Chunking s√©mantique** du code (par fonction/classe, pas par lignes arbitraires)
2. **Dual embeddings** (texte g√©n√©ral + code sp√©cialis√©, m√™me dimensionnalit√© 768D)
3. **Graph de d√©pendances** (call graph, import graph) stock√© nativement dans PostgreSQL
4. **Recherche hybride** (BM25 lexical + vector s√©mantique + graph relationnel)
5. **M√©tadonn√©es code riches** (language, complexit√©, tests, fr√©quence d'utilisation)
6. **Unified search** (chercher dans conversations + code simultan√©ment)

### Motivation

**Probl√®me actuel** :
- MnemoLite traite le code comme du texte brut
- Pas de compr√©hension de la structure syntaxique (fonctions, classes, imports)
- Embeddings g√©n√©ralistes (`nomic-embed-text-v1.5`) moins pr√©cis sur code pur
- Pas de navigation relationnelle (call graph, dependencies)
- Chunking manuel ou par taille fixe ‚Üí perte de contexte s√©mantique

**Impact attendu** :
- üéØ **Pr√©cision +40-80%** sur recherche s√©mantique de code (selon recherche cAST 2024)
- üöÄ **Recall +25%** via chunking AST intelligent vs chunking fixe
- üß† **Contexte relationnel** : navigation call graph ‚Üí compr√©hension architecture
- üí° **Meilleurs agents** : m√©moire conversationnelle + compr√©hension codebase r√©elle
- üîó **Unified memory** : agent se souvient des conversations ET du code discut√©

---

## ‚úÖ Phase 0 Complete (2025-10-16)

**Statut**: ‚úÖ **100% COMPLETE** (8/8 story points) - AHEAD OF SCHEDULE

### Stories Compl√®tes

#### Story 0.1: Alembic Async Setup (3 pts) - 2025-10-15 ‚úÖ
- ‚úÖ Alembic 1.17.0 install√© avec template async
- ‚úÖ Pydantic v2 settings migration (`workers/config/settings.py`)
- ‚úÖ Baseline NO-OP migration cr√©√©e (revision: 9dde1f9db172)
- ‚úÖ Database stamp√©e, `alembic_version` op√©rationnelle
- ‚úÖ 17/17 DB tests pass√©s
- **Dur√©e**: 1 jour (vs 2 jours estim√©s) ‚úÖ AHEAD

#### Story 0.2: Dual Embeddings Service (5 pts) - 2025-10-16 ‚úÖ
- ‚úÖ `DualEmbeddingService` cr√©√© (EmbeddingDomain: TEXT | CODE | HYBRID)
- ‚úÖ Lazy loading + double-checked locking (thread-safe)
- ‚úÖ RAM safeguard (bloque CODE model si > 900 MB)
- ‚úÖ Backward compatibility 100% (Adapter pattern)
- ‚úÖ 24 unit tests + 19 regression tests passent
- ‚úÖ Audit complet: Score 9.4/10 - Production Ready
- ‚úÖ 2 bugs critiques corrig√©s (empty HYBRID, deprecated asyncio API)
- **Dur√©e**: 1 jour (vs 3 jours estim√©s) ‚úÖ AHEAD

### Phase 0 Achievements

**Timeline**: 3 jours (Oct 14-16, vs 5-6 jours estim√©s) ‚Üí **AHEAD OF SCHEDULE -2 jours**

**Infrastructure Ready**:
- ‚úÖ Alembic async migrations op√©rationnelles
- ‚úÖ DualEmbeddingService (TEXT + CODE domains)
- ‚úÖ Protocol-based adapter pattern (0 breaking changes)
- ‚úÖ Comprehensive test coverage (43 tests passed)
- ‚úÖ RAM monitoring & safeguards actifs
- ‚úÖ Documentation compl√®te (3 reports + audit)

**Quality Score**:
- Story 0.1: 100% success
- Story 0.2: 93.75% success (RAM adjusted with approval)
- Audit global: 9.4/10 - Production Ready
- Backward compatibility: 0 breaking changes ‚úÖ

### ‚ö†Ô∏è RAM Discovery (CRITICAL LESSON LEARNED)

> **D√©couverte majeure Phase 0**: Les estimations RAM initiales bas√©es sur model weights uniquement √©taient **significativement sous-estim√©es**.

**Estimation initiale (INCORRECTE)**:
- nomic-embed-text-v1.5: 137M params ‚Üí ~260 MB RAM (model weights only)
- jina-embeddings-v2-base-code: 161M params ‚Üí ~400 MB RAM
- **Total estim√©**: ~660-700 MB < 1 GB ‚úÖ

**Mesures r√©elles (Story 0.2 - 2025-10-16)**:
- API baseline: 698 MB
- **TEXT model charg√©**: **1.25 GB** (+552 MB, vs 260 MB estim√©)
- **CODE model**: BLOCKED by RAM safeguard (would exceed 900 MB threshold)

**Root Cause**:
```
TEXT model actual RAM = Model Weights + PyTorch + Tokenizer + Working Memory
                      = 260 MB      + 200 MB   + 150 MB    + 100 MB
                      ‚âà 710 MB overhead (!!)
```

**Formula Nouvelle (Phase 0+)**:
```
Process RAM = Baseline + (Model Weights √ó 3-5)
```

**Implications**:
- ‚ö†Ô∏è Dual models TEXT+CODE simultan√©s: **NOT FEASIBLE** with current RAM budget (2 GB container)
  - TEXT: 1.25 GB
  - CODE: ~400 MB estimated (not tested)
  - Total: ~1.65 GB > safe threshold
- ‚úÖ TEXT-only: fonctionne (backward compat pr√©serv√©e)
- ‚úÖ CODE-only: fonctionne (en isolation)
- ‚úÖ RAM Safeguard: pr√©vient OOM correctement

**Stakeholder Decision (2025-10-16)**:
- ‚úÖ Accepted higher RAM (1.25 GB TEXT model)
- ‚úÖ Infrastructure dual ready (future optimization possible)
- ‚úÖ Use cases separated: TEXT for events, CODE for code intelligence (Phase 1+)

**Future Optimizations**:
1. **Quantization FP16**: RAM reduction ~50% (1.25 GB ‚Üí ~625 MB)
2. **Model Swapping**: Unload TEXT before loading CODE
3. **Larger Container**: 2 GB ‚Üí 4 GB RAM

**Voir**: `EPIC-06_PHASE_0_STORY_0.2_AUDIT_REPORT.md` pour analyse compl√®te

---

## ‚úÖ Phase 1 Complete (2025-10-16)

**Statut**: ‚úÖ **100% COMPLETE** (26/26 story points) - Stories 1, 2bis & 3 DONE

### Stories Compl√®tes

#### Story 1: Tree-sitter Integration & AST Chunking (13 pts) - 2025-10-16 ‚úÖ
- ‚úÖ Tree-sitter 0.21.3 + tree-sitter-languages 1.10.2 install√©s
- ‚úÖ `CodeChunkingService` impl√©ment√© (390 lignes)
- ‚úÖ `PythonParser` avec AST extraction (functions, classes, methods)
- ‚úÖ Algorithme split-then-merge avec fallback chunking
- ‚úÖ Performance: <150ms pour 366 LOC (20 functions)
- ‚úÖ 9/10 tests unitaires passent (1 xfail attendu - edge case)
- ‚úÖ Pydantic models: `CodeChunk`, `CodeChunkCreate`, `ChunkType`, `CodeUnit`
- **Dur√©e**: 1 jour (vs 10-13 jours estim√©s) ‚úÖ AHEAD

**Impl√©mentation**:
- `api/models/code_chunk_models.py` (234 lignes) - Models Pydantic v2
- `api/services/code_chunking_service.py` (390 lignes) - Service + Parser
- `tests/services/test_code_chunking_service.py` (283 lignes) - 10 tests

#### Story 2bis: Code Chunks Table & Repository (5 pts) - 2025-10-16 ‚úÖ
- ‚úÖ Alembic migration cr√©√©e (revision: a40a6de7d379)
- ‚úÖ Table `code_chunks` avec dual embeddings VECTOR(768)
- ‚úÖ HNSW indexes (m=16, ef_construction=64) sur embedding_text + embedding_code
- ‚úÖ GIN index sur metadata JSONB
- ‚úÖ B-tree indexes sur language, chunk_type, file_path
- ‚úÖ Trigram indexes (pg_trgm) sur source_code + name
- ‚úÖ `CodeChunkRepository` impl√©ment√© (431 lignes) - CRUD + search
- ‚úÖ Vector search avec dual embeddings (TEXT | CODE)
- ‚úÖ Similarity search avec pg_trgm (BM25-like)
- ‚úÖ 10/10 tests d'int√©gration passent
- ‚úÖ Migration test database + pgvector extension install√©e
- **Dur√©e**: 1 jour (vs 5-8 jours estim√©s) ‚úÖ AHEAD

**Impl√©mentation**:
- `api/alembic/versions/20251016_0816-a40a6de7d379_*.py` (115 lignes) - Migration
- `api/db/repositories/code_chunk_repository.py` (431 lignes) - Repository
- `tests/db/repositories/test_code_chunk_repository.py` (226 lignes) - 10 tests
- `tests/conftest.py` - Ajout fixture `test_engine`

#### Story 3: Code Metadata Extraction (8 pts) - 2025-10-16 ‚úÖ
- ‚úÖ `MetadataExtractorService` impl√©ment√© (359 lignes)
- ‚úÖ 9 metadata fields extracted: signature, parameters, returns, decorators, docstring, cyclomatic, LOC, imports, calls
- ‚úÖ Python `ast` module pour extraction (stdlib)
- ‚úÖ `radon` library pour cyclomatic complexity
- ‚úÖ Graceful degradation (partial metadata si extraction fails)
- ‚úÖ Integration avec `CodeChunkingService` (param√®tre `extract_metadata=True`)
- ‚úÖ 15/15 unit tests passent (MetadataExtractorService)
- ‚úÖ 19/19 integration tests passent (CodeChunkingService)
- ‚úÖ 12/12 edge cases handled (empty funcs, unicode, syntax errors, etc.)
- ‚úÖ **Audit complet r√©alis√©: Score 9.2/10 - Production Ready**
- ‚úÖ **Performance CRITIQUE: Issue O(n¬≤) d√©couverte et fix√©e**
  - Avant: 10.50ms per function (200 funcs) - UNACCEPTABLE ‚ùå
  - Apr√®s optimization: **0.98ms per function** (5x improvement) ‚úÖ
  - Root cause: `_extract_imports()` faisait `ast.walk(tree)` pour chaque fonction
  - Fix: Pr√©-extraction des imports une seule fois ‚Üí O(n¬≤) ‚Üí O(n)
- **Dur√©e**: 1 jour dev + 0.5 jour audit (vs 3-5 jours estim√©s) ‚úÖ AHEAD

**Impl√©mentation**:
- `api/services/metadata_extractor_service.py` (359 lignes) - Service extraction
- `api/services/code_chunking_service.py` - Integration + optimization O(n)
- `tests/services/test_metadata_extractor_service.py` (365 lignes) - 15 tests unitaires
- `tests/services/test_code_chunking_service.py` (19 tests integration)
- `scripts/validate_story3_metadata.py` (166 lignes) - Script validation
- `scripts/audit_story3_edge_cases.py` (261 lignes) - Edge cases testing
- `scripts/audit_story3_performance.py` (228 lignes) - Performance benchmarks
- `docs/agile/EPIC-06_STORY_3_AUDIT_REPORT.md` (600+ lignes) - Audit complet

**Metadata Fields (9 core)**:
```json
{
  "signature": "def calculate_total(items: list[float]) -> float:",
  "parameters": ["items"],
  "returns": "float",
  "decorators": ["@staticmethod"],
  "docstring": "Calculate total from items list...",
  "complexity": {"cyclomatic": 3, "lines_of_code": 12},
  "imports": ["typing.List", "math"],
  "calls": ["sum", "abs", "round"]
}
```

### Phase 1 Achievements

**Timeline**: 3 jours (Oct 16, vs 18-26 jours estim√©s) ‚Üí **AHEAD OF SCHEDULE -15 jours**

**Infrastructure Ready**:
- ‚úÖ Tree-sitter parsing op√©rationnel (Python)
- ‚úÖ AST-based semantic chunking (<150ms pour 300+ LOC)
- ‚úÖ PostgreSQL code_chunks table avec dual embeddings
- ‚úÖ HNSW + GIN + Trigram indexes complets
- ‚úÖ Repository pattern avec QueryBuilder (consistent avec EventRepository)
- ‚úÖ Metadata extraction avec 9 champs (signature, params, complexity, etc.)
- ‚úÖ Python AST + radon pour m√©tadonn√©es riches
- ‚úÖ Performance optimization O(n¬≤) ‚Üí O(n) pour metadata extraction
- ‚úÖ Test coverage: 44/44 tests passed (100%) - 34 unit/integration + 10 repository

**Quality Score**:
- Story 1 (Chunking): 90% success (9/10 tests, 1 xfail expected)
- Story 2bis (Repository): 100% success (10/10 tests)
- Story 3 (Metadata): 100% success (34/34 tests) - **Audit: 9.2/10**
- Performance: ‚úÖ **0.98ms per function** (after O(n) optimization), Repository <1s
- Robustness: ‚úÖ 12/12 edge cases, comprehensive audit + validation on real code

### üîß Issues Fixed During Validation

**Story 2bis Audit (2025-10-16)** - 6 issues critiques corrig√©es:

1. **Test Engine Fixture Missing**
   - Fix: Ajout `@pytest_asyncio.fixture` pour `test_engine` dans conftest.py

2. **pgvector Extension Test DB**
   - Fix: `CREATE EXTENSION IF NOT EXISTS vector` sur mnemolite_test

3. **Embedding Format Mismatch**
   - Issue: List ‚Üí String conversion pour pgvector
   - Fix: Ajout `_format_embedding_for_db()` method (format "[0.1,0.2,...]")

4. **Embedding Parsing from DB**
   - Issue: String ‚Üí List deserialization
   - Fix: Ajout `from_db_record()` classmethod avec `ast.literal_eval()`

5. **Vector Search SQL Syntax**
   - Issue: `:embedding::vector` placeholder syntax error
   - Fix: Direct embedding string injection: `'{embedding_str}'::vector`

6. **Update Query Validation**
   - Issue: Empty update didn't raise ValueError
   - Fix: Validation before adding `last_modified = NOW()`

**Story 3 Audit (2025-10-16)** - 1 issue CRITIQUE d√©couverte et corrig√©e:

1. **‚ö†Ô∏è Performance O(n¬≤) - Metadata Extraction**
   - **Impact**: CRITIQUE - 200 fonctions = 2099ms overhead (10.50ms/func) ‚ùå
   - **Root Cause**: `_extract_imports()` appelait `ast.walk(tree)` pour CHAQUE fonction
   - **Sympt√¥mes**: Performance d√©gradait quadratiquement avec nombre de fonctions
   - **Fix**: Pr√©-extraction des imports au niveau module (une seule fois)
     ```python
     # AVANT: O(n¬≤) - ast.walk(tree) √ó N fonctions
     for chunk in chunks:
         metadata = extract_metadata(node, tree)  # Walk tree chaque fois!

     # APR√àS: O(n) - ast.walk(tree) √ó 1 + traitement lin√©aire
     module_imports = _extract_module_imports(tree)  # Une fois!
     for chunk in chunks:
         metadata = extract_metadata(node, tree, module_imports)
     ```
   - **R√©sultat**: **5x improvement** - 398ms pour 200 fonctions (0.98ms/func) ‚úÖ
   - **Tests**: 34/34 passing, 12/12 edge cases, production ready (9.2/10)

**Voir**: `docs/agile/EPIC-06_STORY_3_AUDIT_REPORT.md` pour d√©tails complets

### üéØ Next Steps - Phase 2

**Phase 1 Complete** ‚úÖ (26/26 pts - 100%)

**Note Story 2**: Story 2 "Dual Embeddings" a √©t√© **fusionn√©e avec Phase 0 Story 0.2** (voir ADR-017). Phase 1 n'a donc que 3 stories: 1, 2bis, 3.

**Phase 2: Graph Intelligence (Story 4)** - üü° BRAINSTORM COMPLETE (2025-10-16)
- ‚úÖ Architecture brainstorm complete (EPIC-06_STORY_4_BRAINSTORM.md)
- ‚è≥ Implementation pending: Static analysis pour call graph + import graph
- ‚è≥ Stockage dans nodes/edges PostgreSQL
- ‚è≥ API endpoints pour graph traversal
- ‚è≥ Visualisation JSON pour UI

---

## üî¨ Recherche & Benchmarking (2024-2025)

### 1. Embeddings Code State-of-the-Art

| Mod√®le | Params | Dimensions | RAM | Performance | Local | MnemoLite Fit |
|--------|--------|------------|-----|-------------|-------|---------------|
| nomic-embed-code (ICLR 2025) | 7B | 768 | ~14 GB | ü•á SOTA CSN | ‚úÖ | ‚ùå **Trop lourd** |
| **jina-embeddings-v2-base-code** | 161M | **768** | ~400 MB | ü•à Lead 9/15 CSN | ‚úÖ | ü•á **RECOMMAND√â** |
| jina-code-embeddings-1.5b | 1.5B | 1536‚Üí768 | ~3 GB | ü•á 86% CSN | ‚úÖ | ‚≠ê SOTA 2025 (si GPU) |
| CodeBERT (Microsoft) | 125M | 768 | ~300 MB | ü•â Bon multi-lang | ‚úÖ | ‚úÖ Alternatif |
| nomic-embed-text-v1.5 (actuel) | 137M | 768 | ~260 MB | ‚≠ê Texte g√©n√©ral | ‚úÖ | ‚úÖ Garder pour texte |

**üéØ Recommandation FINALE MnemoLite** (apr√®s deep analysis) :

‚Üí **jina-embeddings-v2-base-code** (161M, 768D, Apache 2.0)

**Raisons** :
- ‚úÖ **43√ó plus l√©ger** que nomic-code (161M vs 7B params)
- ‚úÖ **M√™me dimensionnalit√© 768D** que nomic-text ‚Üí **PAS de migration DB!**
- ‚úÖ **RAM l√©ger** : ~400 MB (vs 14 GB nomic-code)
- ‚úÖ **Performance excellente** : Lead 9/15 benchmarks CodeSearchNet
- ‚úÖ **Multi-langages** : 30+ programming languages
- ‚úÖ **CPU-friendly** : D√©ploiement facile sans GPU
- ‚úÖ **Total syst√®me** : nomic-text (137M) + jina-code (161M) = **~700 MB** total

**Trade-off accept√©** :
- ‚ö†Ô∏è Pas le SOTA 2025 absolu (-11 pts vs jina-1.5B)
- ‚úÖ Mais **ratio performance/poids optimal** pour MnemoLite local & l√©ger

**Voir** : [`EPIC-06_DEEP_ANALYSIS.md`](EPIC-06_DEEP_ANALYSIS.md) pour analyse comparative compl√®te

### 2. Chunking S√©mantique via AST

**Recherche cAST (arxiv 2024, ICLR 2025)** :
- **82% am√©lioration** pr√©cision retrieval vs chunking fixe
- **Tree-sitter** : parsing multi-langages (Python, JS, TS, Go, Rust, Java, etc.)
- **Split-then-merge algorithm** : d√©coupe AST en chunks coh√©rents
- Pr√©serve structure syntaxique (fonctions compl√®tes, pas de coupure mid-expression)

**Impl√©mentation Open Source** :
- `code-splitter` (Rust crate, tree-sitter based)
- `py-tree-sitter` (Python bindings)

**Exemple** :
```python
# ‚ùå Chunking fixe (mauvais):
Chunk 1: "def calculate_total(items):\n    result = 0"
Chunk 2: "    for item in items:\n        result += item.price"
# ‚Üí Fonction coup√©e arbitrairement, contexte perdu

# ‚úÖ Chunking AST (bon):
Chunk 1: "def calculate_total(items):\n    result = 0\n    for item in items:\n        result += item.price\n    return result"
# ‚Üí Fonction compl√®te, contexte pr√©serv√©
```

### 3. Hybrid Search: BM25 + Vector + Graph

**Architecture recommand√©e 2024-2025** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Query: "fonction qui calcule totaux"       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                    ‚îÇ
        ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  BM25 Search ‚îÇ    ‚îÇVector Search ‚îÇ
‚îÇ  (lexical)   ‚îÇ    ‚îÇ  (semantic)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                    ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  RRF Fusion      ‚îÇ  ‚Üê Reciprocal Rank Fusion
        ‚îÇ  (ranking)       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Graph Expansion  ‚îÇ  ‚Üê Enrichir avec call graph
        ‚îÇ (dependencies)   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Reranking Model  ‚îÇ  ‚Üê Optional: affiner top-K
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
          R√©sultats finaux
```

**Technologies 2024-2025** :
- PostgreSQL Native BM25 (via `pg_trgm` + custom scoring)
- pgvector pour vector search (d√©j√† utilis√©)
- RRF (Reciprocal Rank Fusion) : `score = 1/(rank + k)`
- Graph traversal via CTE r√©cursifs (d√©j√† capable dans MnemoLite)

### 4. Code Graph & Dependencies

**Call Graph** : fonction ‚Üí fonctions appel√©es
**Import Graph** : module ‚Üí modules import√©s
**Data Flow Graph** : variable ‚Üí utilisations

**Stockage PostgreSQL** :
```sql
-- D√©j√† existant dans MnemoLite (nodes/edges)
CREATE TABLE nodes (
    node_id UUID PRIMARY KEY,
    node_type TEXT,  -- 'function', 'class', 'method', 'module'
    label TEXT,      -- Nom de la fonction/classe
    props JSONB      -- M√©tadonn√©es code-specific
);

CREATE TABLE edges (
    edge_id UUID PRIMARY KEY,
    source_node UUID,
    target_node UUID,
    relationship TEXT,  -- 'calls', 'imports', 'extends', 'uses'
    props JSONB
);

-- Index pour traversal rapide
CREATE INDEX idx_edges_source ON edges(source_node);
CREATE INDEX idx_edges_target ON edges(target_node);
```

**Static Analysis Tools** :
- Python: `ast` (stdlib), `pyan`, `jedi`
- JavaScript/TS: Tree-sitter + `typescript` compiler API
- Multi-language: Tree-sitter (50+ langages)

---

## üèóÔ∏è Architecture Propos√©e

### Composants √† Ajouter

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MnemoLite v1.4.0 Architecture            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  API Layer (FastAPI)                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /v1/code/index (nouveau)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GET /v1/code/search (nouveau)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GET /v1/code/graph (nouveau)             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /v1/events (existant, √©tendu)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                    ‚îÇ                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Services Layer                             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CodeIndexingService (nouveau)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CodeSearchService (nouveau)              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GraphAnalysisService (nouveau)           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ EmbeddingService (√©tendu)                ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                    ‚îÇ                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Code Processing Pipeline (nouveau)         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  1. Tree-sitter Parsing ‚Üí AST               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  2. Semantic Chunking ‚Üí Nodes               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  3. Metadata Extraction ‚Üí Props             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  4. Dependency Analysis ‚Üí Edges             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  5. Embedding Generation ‚Üí Vectors          ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                    ‚îÇ                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Repository Layer                           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CodeChunkRepository (nouveau)            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GraphRepository (√©tendu)                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ EventRepository (existant)               ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                    ‚îÇ                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL 18 + pgvector                   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ code_chunks (nouveau)                    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ nodes/edges (√©tendu pour code)           ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ events (existant)                        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ BM25 index (nouveau, via pg_trgm)        ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Nouveau Sch√©ma DB (Architecture Dual-Purpose)

**Strat√©gie** : Tables s√©par√©es (`events` + `code_chunks`) pour pr√©server use cases distincts

```sql
-- Table 1: events (INCHANG√âE - agent memory)
-- Conversations, documentation, d√©cisions architecturales
CREATE TABLE events (
    id UUID PRIMARY KEY,
    timestamp TIMESTAMPTZ NOT NULL,
    content JSONB NOT NULL,
    embedding VECTOR(768),  -- nomic-embed-text-v1.5 (texte g√©n√©ral)
    metadata JSONB
    -- Schema existant pr√©serv√©
);

-- Table 2: code_chunks (NOUVELLE - code intelligence)
CREATE TABLE code_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

    -- Identification
    file_path TEXT NOT NULL,
    language TEXT NOT NULL,  -- 'python', 'javascript', 'typescript', etc.
    chunk_type TEXT NOT NULL,  -- 'function', 'class', 'method', 'module'
    name TEXT,  -- Nom de la fonction/classe

    -- Contenu
    source_code TEXT NOT NULL,
    start_line INT,
    end_line INT,

    -- Dual embeddings (768D les deux!)
    embedding_text VECTOR(768),  -- nomic-text (docstrings, comments)
    embedding_code VECTOR(768),  -- jina-code (code s√©mantique)

    -- M√©tadonn√©es code
    metadata JSONB NOT NULL,  -- {complexity, params, returns, docstring, tests, etc.}

    -- Timestamps
    indexed_at TIMESTAMPTZ DEFAULT NOW(),
    last_modified TIMESTAMPTZ,

    -- Relations
    node_id UUID,  -- Lien vers nodes table
    repository TEXT,  -- Nom du repo
    commit_hash TEXT  -- Git commit
);

-- Index HNSW pour dual embeddings
CREATE INDEX idx_events_embedding ON events
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_code_embedding_text ON code_chunks
USING hnsw (embedding_text vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_code_embedding_code ON code_chunks
USING hnsw (embedding_code vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Index GIN pour m√©tadonn√©es
CREATE INDEX idx_code_chunks_metadata ON code_chunks USING gin (metadata jsonb_path_ops);

-- Index B-tree pour filtrage
CREATE INDEX idx_code_chunks_language ON code_chunks(language);
CREATE INDEX idx_code_chunks_type ON code_chunks(chunk_type);
CREATE INDEX idx_code_chunks_file ON code_chunks(file_path);

-- Index trigram pour BM25-like search
CREATE EXTENSION IF NOT EXISTS pg_trgm;
CREATE INDEX idx_code_chunks_source_trgm ON code_chunks USING gin (source_code gin_trgm_ops);
CREATE INDEX idx_code_chunks_name_trgm ON code_chunks USING gin (name gin_trgm_ops);

-- Extension pour nodes/edges (code graphs)
ALTER TABLE nodes ADD COLUMN IF NOT EXISTS code_metadata JSONB;
ALTER TABLE edges ADD COLUMN IF NOT EXISTS call_frequency INT DEFAULT 0;
```

---

## üìã User Stories (6 Stories)

### Story 1: Tree-sitter Integration & AST Chunking
**Priority**: üî¥ HAUTE
**Points**: 13
**D√©pendances**: Aucune

**En tant que** d√©veloppeur agent IA utilisant MnemoLite,
**Je veux** que le code soit d√©coup√© en chunks s√©mantiques (fonctions/classes),
**Afin de** rechercher du code sans couper arbitrairement les fonctions.

**Crit√®res d'acceptation**:
- ‚úÖ Tree-sitter install√© et configur√© (Python bindings)
- ‚úÖ Parsers disponibles : Python, JavaScript, TypeScript, Go, Rust, Java
- ‚úÖ Algorithme split-then-merge impl√©ment√© (inspir√© cAST paper)
- ‚úÖ Chunking respecte les limites de fonctions/classes/m√©thodes
- ‚úÖ Fallback sur chunking fixe si parsing √©choue
- ‚úÖ Tests unitaires avec exemples multi-langages

**Impl√©mentation** :
```python
# api/services/code_chunking_service.py
from tree_sitter import Language, Parser
import tree_sitter_python as tspython

class CodeChunkingService:
    def __init__(self):
        self.parser = Parser()
        self.languages = {
            'python': Language(tspython.language()),
            # 'javascript': Language(tsjs.language()),
            # etc.
        }

    async def chunk_code(
        self,
        source_code: str,
        language: str,
        max_chunk_size: int = 2000
    ) -> list[CodeChunk]:
        """
        D√©coupe le code via AST en chunks s√©mantiques.

        Algorithme:
        1. Parse code ‚Üí AST
        2. Identifier nodes de type function/class/method
        3. Si node.size < max_chunk_size ‚Üí chunk autonome
        4. Sinon ‚Üí split r√©cursif
        5. Merge petits chunks adjacents
        """
        pass
```

---

### Story 2: Dual Embeddings (Text + Code) - R√âVIS√â
**Priority**: üü° MOYENNE
**Points**: 5 (R√âDUIT de 8)
**D√©pendances**: Story 1 (chunking)

**En tant que** syst√®me MnemoLite,
**Je veux** supporter dual embeddings (texte g√©n√©ral + code sp√©cialis√©),
**Afin de** maintenir la m√©moire agent TOUT EN ajoutant capacit√©s code.

**Crit√®res d'acceptation**:
- ‚úÖ **jina-embeddings-v2-base-code** t√©l√©charg√© et op√©rationnel
- ‚úÖ `EmbeddingService` √©tendu avec param√®tre `domain: 'text'|'code'|'hybrid'`
- ‚úÖ **Backward compatibility** : Table events intacte, embeddings texte inchang√©s
- ‚úÖ Dual embeddings sur code_chunks (embedding_text + embedding_code)
- ‚úÖ Benchmark: jina-code vs nomic-text sur code (pr√©cision, latence, RAM)
- ‚úÖ Validation: 768D identiques, pas de migration DB n√©cessaire
- ‚úÖ Documentation `.env.example` pour `CODE_EMBEDDING_MODEL`

**Configuration** :
```python
# .env
EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5          # Texte g√©n√©ral (inchang√©)
CODE_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code  # Code sp√©cialis√© (nouveau)
EMBEDDING_DIMENSION=768  # Identique pour les deux (critique!)
```

**Impl√©mentation** :
```python
# api/services/embedding_service.py
class EmbeddingDomain(str, Enum):
    TEXT = "text"      # Conversations, docs
    CODE = "code"      # Code snippets
    HYBRID = "hybrid"  # Both (for code with docstrings)

class EmbeddingService:
    def __init__(self):
        self.text_model = SentenceTransformer(settings.EMBEDDING_MODEL)
        self.code_model = SentenceTransformer(settings.CODE_EMBEDDING_MODEL)

    async def generate_embedding(
        self,
        text: str,
        domain: EmbeddingDomain = EmbeddingDomain.TEXT
    ) -> dict[str, list[float]]:
        """
        Generate embedding(s) based on domain.
        Returns: {'text': [...], 'code': [...]} or subset
        """
        result = {}
        if domain in [EmbeddingDomain.TEXT, EmbeddingDomain.HYBRID]:
            result['text'] = self.text_model.encode(text).tolist()
        if domain in [EmbeddingDomain.CODE, EmbeddingDomain.HYBRID]:
            result['code'] = self.code_model.encode(text).tolist()
        return result
```

---

### Story 3: Code Metadata Extraction
**Priority**: üü° MOYENNE
**Points**: 8
**D√©pendances**: Story 1 (chunking)

**En tant qu'** agent IA,
**Je veux** des m√©tadonn√©es riches sur chaque chunk de code,
**Afin de** filtrer/scorer intelligemment (ex: "fonctions avec >5 param√®tres").

**M√©tadonn√©es √† extraire**:
```json
{
  "language": "python",
  "chunk_type": "function",
  "name": "calculate_total",
  "signature": "calculate_total(items: List[Item]) -> float",
  "parameters": ["items"],
  "returns": "float",
  "docstring": "Calculate total price from items list",
  "complexity": {
    "cyclomatic": 3,
    "lines_of_code": 12,
    "cognitive": 5
  },
  "imports": ["typing.List", "models.Item"],
  "calls": ["item.get_price", "sum"],
  "decorators": ["@staticmethod"],
  "has_tests": true,
  "test_files": ["tests/test_calculations.py"],
  "last_modified": "2025-10-15T10:30:00Z",
  "author": "john.doe",
  "usage_frequency": 42  // Combien de fois appel√©e (static analysis)
}
```

**Outils**:
- Python: `ast` module (stdlib), `radon` (complexit√©)
- JavaScript/TS: Tree-sitter + TypeScript compiler API
- Multi-language: Tree-sitter queries

---

### Story 4: Dependency Graph Construction
**Priority**: üü° MOYENNE
**Points**: 13
**D√©pendances**: Story 1 (chunking), Story 3 (metadata)

**En tant qu'** agent IA,
**Je veux** naviguer le call graph du code index√©,
**Afin de** comprendre les d√©pendances et l'architecture.

**Types de relations**:
- `calls` : fonction A appelle fonction B
- `imports` : module A importe module B
- `extends` : classe A h√©rite de classe B
- `implements` : classe A impl√©mente interface B
- `uses` : fonction A utilise variable/type B

**Crit√®res d'acceptation**:
- ‚úÖ Static analysis pour extraire call graph
- ‚úÖ Stockage dans `nodes` + `edges` (PostgreSQL)
- ‚úÖ Requ√™tes CTE r√©cursives pour traversal (‚â§3 hops)
- ‚úÖ API `GET /v1/code/graph?from=function_id&depth=2`
- ‚úÖ Visualisation JSON compatible avec UI v4.0
- ‚úÖ Tests avec codebase r√©elle (~500 fonctions)

**Exemple requ√™te**:
```python
# "Quelles fonctions sont appel√©es par calculate_total ?"
GET /v1/code/graph?from=<uuid>&relationship=calls&direction=outbound&depth=1

# "Quelles fonctions appellent calculate_total ?"
GET /v1/code/graph?from=<uuid>&relationship=calls&direction=inbound&depth=1
```

---

### Story 5: Hybrid Search (BM25 + Vector + Graph)
**Priority**: üî¥ HAUTE
**Points**: 21
**D√©pendances**: Story 2 (embeddings), Story 4 (graph)

**En tant qu'** agent IA,
**Je veux** rechercher du code avec hybrid search (lexical + s√©mantique + graph),
**Afin d'** obtenir les r√©sultats les plus pertinents.

**Architecture**:
```python
# api/services/hybrid_code_search_service.py
class HybridCodeSearchService:
    async def search(
        self,
        query: str,
        language: Optional[str] = None,
        chunk_type: Optional[str] = None,
        use_bm25: bool = True,
        use_vector: bool = True,
        use_graph: bool = False,
        expand_graph_depth: int = 0,
        limit: int = 10
    ) -> SearchResults:
        """
        1. BM25 Search (lexical, pg_trgm)
        2. Vector Search (semantic, pgvector HNSW)
        3. RRF Fusion (combine scores)
        4. Graph Expansion (optionnel)
        5. Return top-K
        """

        # Parallel execution
        bm25_results = await self._bm25_search(query, language, chunk_type)
        vector_results = await self._vector_search(query, language, chunk_type)

        # Reciprocal Rank Fusion
        fused = self._rrf_fusion(bm25_results, vector_results, k=60)

        # Graph expansion (optionnel)
        if use_graph and expand_graph_depth > 0:
            fused = await self._expand_with_graph(fused, expand_graph_depth)

        return fused[:limit]

    def _rrf_fusion(self, list1, list2, k=60) -> list:
        """
        RRF score = 1 / (rank + k)
        Combine scores from multiple lists.
        """
        scores = {}
        for rank, item in enumerate(list1, 1):
            scores[item.id] = scores.get(item.id, 0) + 1 / (rank + k)
        for rank, item in enumerate(list2, 1):
            scores[item.id] = scores.get(item.id, 0) + 1 / (rank + k)

        # Sort by combined score
        sorted_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return [self._get_item(id) for id, score in sorted_items]
```

**BM25 Implementation (PostgreSQL)** :
```sql
-- Utiliser pg_trgm pour similarit√© lexicale
SELECT
    id,
    name,
    source_code,
    similarity(source_code, :query) AS bm25_score
FROM code_chunks
WHERE
    source_code % :query  -- Trigram similarity operator
    AND (:language IS NULL OR language = :language)
ORDER BY bm25_score DESC
LIMIT 100;  -- Overfetch pour fusion
```

**Crit√®res d'acceptation**:
- ‚úÖ BM25 search via `pg_trgm` op√©rationnel
- ‚úÖ Vector search via HNSW d√©j√† existant
- ‚úÖ RRF fusion impl√©ment√© (k=60 par d√©faut, configurable)
- ‚úÖ Graph expansion optionnel (depth 0-3)
- ‚úÖ Benchmark: recall +X% vs vector-only
- ‚úÖ API `POST /v1/code/search` avec tous param√®tres
- ‚úÖ Tests unitaires + int√©gration

---

### Story 6: Code Indexing Pipeline & API
**Priority**: üî¥ HAUTE
**Points**: 13
**D√©pendances**: Stories 1-4

**En tant que** d√©veloppeur,
**Je veux** indexer une codebase compl√®te via API,
**Afin que** MnemoLite ing√®re tout mon projet.

**Endpoints**:

```python
# POST /v1/code/index
{
  "repository": "my-project",
  "files": [
    {"path": "src/main.py", "content": "def main():\n    ..."},
    {"path": "src/utils.py", "content": "def helper():\n    ..."}
  ],
  "options": {
    "language": "python",
    "analyze_dependencies": true,
    "extract_metadata": true,
    "generate_embeddings": true
  }
}

# Response:
{
  "indexed_chunks": 127,
  "indexed_nodes": 89,
  "indexed_edges": 243,
  "processing_time_ms": 4523,
  "repository_id": "<uuid>"
}

# GET /v1/code/search
{
  "query": "fonction qui calcule les totaux",
  "language": "python",
  "chunk_type": "function",
  "use_bm25": true,
  "use_vector": true,
  "use_graph": false,
  "limit": 10
}

# GET /v1/code/graph
{
  "from_node": "<uuid>",
  "relationship": "calls",
  "direction": "outbound",
  "depth": 2
}
```

**Pipeline d'indexation**:
```
Input: Files ‚Üí
  1. Language Detection
  2. Tree-sitter Parsing (Story 1)
  3. Semantic Chunking (Story 1)
  4. Metadata Extraction (Story 3)
  5. Dependency Analysis (Story 4)
  6. Embedding Generation (Story 2)
  7. PostgreSQL Storage (code_chunks + nodes + edges)
Output: Indexed repository
```

**Crit√®res d'acceptation**:
- ‚úÖ Endpoint `/v1/code/index` op√©rationnel
- ‚úÖ Support batch indexing (plusieurs fichiers)
- ‚úÖ Processing async avec progress tracking
- ‚úÖ Error handling robuste (fichiers invalides, parsing errors)
- ‚úÖ Rate limiting (√©viter overload)
- ‚úÖ Documentation OpenAPI compl√®te
- ‚úÖ Tests end-to-end avec repo r√©el (~100 fichiers Python)

---

## üéØ Crit√®res d'Acceptation Globaux (Epic DoD)

### Infrastructure
- ‚úÖ Table `code_chunks` cr√©√©e avec index HNSW + GIN + trigram
- ‚úÖ Extension `pg_trgm` activ√©e
- ‚úÖ Sch√©ma `nodes`/`edges` √©tendu pour code graphs
- ‚úÖ Migration Alembic pour tous changements DB

### Code Quality
- ‚úÖ Tree-sitter int√©gr√© et test√© (6+ langages)
- ‚úÖ Nomic Embed Code op√©rationnel (ou d√©cision de garder nomic-text document√©e)
- ‚úÖ Code chunking s√©mantique >80% pr√©cision vs chunking fixe
- ‚úÖ Hybrid search (BM25+Vector+Graph) impl√©ment√©
- ‚úÖ Tests coverage >85% sur nouveaux modules

### Performance
- ‚úÖ Indexing: <500ms par fichier Python moyen (300 LOC)
- ‚úÖ Search hybrid: <50ms P95 (avec 10k chunks)
- ‚úÖ Graph traversal: <20ms pour depth=2
- ‚úÖ Benchmark document√© : recall, precision, latency

### Documentation
- ‚úÖ Architecture d√©cision record (ADR) pour choix embeddings
- ‚úÖ Guide utilisateur : comment indexer une codebase
- ‚úÖ API docs OpenAPI mis √† jour
- ‚úÖ README.md section "Code Intelligence"

### Integration
- ‚úÖ Compatible avec workflow existant (events API)
- ‚úÖ Pas de breaking changes sur API existantes
- ‚úÖ UI v4.0 : pages de visualisation code search + graph
- ‚úÖ Tests d'int√©gration avec agent IA r√©el (Claude/GPT)

---

## üìä M√©triques de Succ√®s

| M√©trique | Baseline (v1.3.0) | Target (v1.4.0) | Mesure |
|----------|-------------------|-----------------|---------|
| **Pr√©cision recherche code** | ~60% (texte) | >85% | Recall@10 sur CodeSearchNet |
| **Chunking qualit√©** | Arbitraire (lignes) | >80% fonctions compl√®tes | % chunks s√©mantiques valides |
| **Latency search** | 12ms (vector-only) | <50ms (hybrid) | P95 sur 10k chunks |
| **Coverage langages** | 0 (pas code-aware) | 6+ (Py, JS, TS, Go, Rust, Java) | Langages support√©s |
| **Graph navigation** | 0 (pas de graph) | <20ms depth=2 | P95 traversal |

---

## üèóÔ∏è Plan d'Impl√©mentation (Phases)

### Phase 1: Foundation (Stories 1-3) - 4 semaines
**Objectif** : Chunking + Embeddings + Metadata

1. **Semaine 1-2** : Story 1 (Tree-sitter + chunking)
   - Setup tree-sitter pour Python
   - Algorithme split-then-merge
   - Tests avec fichiers Python r√©els
   - Extension √† JS/TS

2. **Semaine 3** : Story 2 (Nomic Embed Code)
   - Benchmark nomic-text vs nomic-code
   - D√©cision finale (upgrade ou garder)
   - Migration si upgrade

3. **Semaine 4** : Story 3 (Metadata extraction)
   - Extraction via AST
   - Stockage dans JSONB
   - Tests complexit√©/docstrings

**Livrable Phase 1** : Chunking s√©mantique + embeddings code + m√©tadonn√©es

### Phase 2: Graph Intelligence (Story 4) - 3 semaines
**Objectif** : Call graph + dependency analysis

1. **Semaine 5-6** : Static analysis
   - Python call graph (via `ast`)
   - Import graph
   - Stockage nodes/edges

2. **Semaine 7** : Graph queries
   - CTE r√©cursifs
   - API endpoints
   - Visualisation JSON

**Livrable Phase 2** : Navigation call graph op√©rationnelle

### Phase 3: Hybrid Search (Story 5) - 3 semaines
**Objectif** : BM25 + Vector + RRF

1. **Semaine 8** : BM25 implementation
   - pg_trgm setup
   - Scoring SQL

2. **Semaine 9** : RRF fusion
   - Algorithme fusion
   - Tests recall/precision

3. **Semaine 10** : Graph expansion
   - Expansion optionnelle
   - Performance tuning

**Livrable Phase 3** : Hybrid search complet

### Phase 4: API & Integration (Story 6) - 2 semaines
**Objectif** : Pipeline complet + documentation

1. **Semaine 11** : Indexing API
   - Endpoints REST
   - Batch processing
   - Error handling

2. **Semaine 12** : Integration & docs
   - UI v4.0 pages
   - Documentation
   - Tests end-to-end

**Livrable Phase 4** : EPIC-06 COMPLET

---

## üöß Risques & Mitigations

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| **Tree-sitter complexit√©** | Haut | Moyen | PoC sur Python d'abord, fallback chunking fixe |
| **Nomic Embed Code lourd** (7B params) | Moyen | Moyen | Benchmark CPU/RAM, garder nomic-text si trop lourd |
| **BM25 performance d√©grad√©e** | Moyen | Faible | Index trigram + EXPLAIN ANALYZE |
| **Graph traversal lent** | Haut | Moyen | Limiter depth ‚â§3, index sur edges |
| **Breaking changes API** | Haut | Faible | Versionner API (v2), garder v1 compatibilit√© |
| **Scope creep** | Moyen | Haut | Stick to 6 stories, reporter features √† v1.5.0 |

---

## üîó D√©pendances Techniques

### Nouvelles D√©pendances (requirements.txt)
```python
# Code parsing & analysis
tree-sitter==0.20.4
tree-sitter-python==0.20.4
tree-sitter-javascript==0.20.3
tree-sitter-typescript==0.20.5
radon==6.0.1  # Complexity analysis

# Embeddings (si upgrade)
# sentence-transformers d√©j√† pr√©sent
# nomic-embed-code sera auto-t√©l√©charg√©

# Graph analysis (optionnel)
networkx==3.2.1  # Pour visualisation/analyse hors-DB
```

### Extensions PostgreSQL (d√©j√† install√©es)
- ‚úÖ pgvector (0.8.0)
- ‚úÖ pg_trgm (pour BM25-like)
- ‚ö†Ô∏è Pas de nouvelles extensions n√©cessaires

---

## üìö R√©f√©rences & Recherche

### Papers & Articles (2024-2025)
1. **cAST: Chunking via Abstract Syntax Trees** (arxiv 2024, ICLR 2025)
   - 82% am√©lioration pr√©cision via AST chunking
   - https://arxiv.org/abs/2506.15655

2. **Nomic Embed Code: State-of-the-Art Code Embedder** (Nomic AI, ICLR 2025)
   - 7B params, 768D, Apache 2.0
   - https://www.nomic.ai/blog/posts/introducing-state-of-the-art-nomic-embed-code

3. **Hybrid Search with BM25 + Vector** (Multiple sources 2024)
   - RRF (Reciprocal Rank Fusion)
   - PostgreSQL Native BM25 via pg_trgm

4. **Tree-sitter for Code Analysis** (2024)
   - Multi-language parsing
   - 50+ langages support√©s

### Open Source Tools
- **Tree-sitter**: https://tree-sitter.github.io/tree-sitter/
- **py-tree-sitter**: https://github.com/tree-sitter/py-tree-sitter
- **code-splitter** (Rust): https://github.com/wangxj03/code-splitter
- **Nomic Embed Models**: https://huggingface.co/nomic-ai

### Benchmarks
- CodeSearchNet: https://github.com/github/CodeSearchNet
- MTEB Code: https://huggingface.co/spaces/mteb/leaderboard

---

## üéØ Alternatives Consid√©r√©es (et Rejet√©es)

| Alternative | Raison du Rejet |
|-------------|-----------------|
| **Utiliser Sourcegraph/Cody** | Pas local, cloud-dependent, pas int√©grable |
| **Qdrant/Weaviate pour code** | Architecture MnemoLite = PostgreSQL-only |
| **LSP (Language Server Protocol)** | Trop lourd, n√©cessite compilation, pas pour indexing batch |
| **CodeBERT au lieu de Nomic Embed Code** | Nomic Embed Code plus r√©cent, meilleur MTEB score |
| **Chunking fixe am√©lior√©** | Research 2024 prouve AST chunking >>> chunking fixe |

---

## üîÑ Prochaines √âtapes (Post-EPIC-06)

### EPIC-07 (Potentiel) : Advanced Code Intelligence
- Reranking models (cross-encoder) pour top-K
- Multi-repo search (chercher dans plusieurs projets)
- Code completion hints (suggestions bas√©es sur graph)
- Semantic diff (comparer versions de code s√©mantiquement)
- Auto-documentation generation (summarize code chunks)

### EPIC-08 (Potentiel) : Production Optimizations
- Code embeddings quantization (FP16 ‚Üí INT8)
- Incremental indexing (re-index seulement fichiers modifi√©s)
- Distributed processing (indexing parall√®le multi-workers)
- Hot/warm storage pour code ancien (archive apr√®s 12 mois)

---

**Statut**: üöß **EN COURS** - Phase 0 COMPLETE (100%), Phase 1 MOSTLY COMPLETE (86%)
**Prochaine Action**: Phase 2 - Story 4: Dependency Graph Construction (13 pts, ~5-7 jours)
**Estimation Totale**: 13 semaines (3 mois) ‚Üí 9-10 semaines restantes (ahead of schedule)
**Complexit√©**: ‚≠ê‚≠ê‚≠ê‚≠ê‚ö™ (4/5)

---

**Notes de Conception**:
- Architecture respecte 100% contraintes MnemoLite (PostgreSQL-only, local, async)
- Compatibilit√© backward garantie (pas de breaking changes API v1)
- Approche pragmatique : PoC Python d'abord, extension multi-langages ensuite
- Performance valid√©e √† chaque phase (benchmarks obligatoires)
- Documentation continue (ADR, guides, tests)
- **Validation rigoureuse**: Audit complet + validation real code apr√®s chaque story

**Contributeurs Recherche**: Claude (AI), Recherches web 2024-2025
**Date Derni√®re Mise √† Jour**: 2025-10-16 (Phase 1 Stories 1, 2bis & 3 Complete)
**Progr√®s**: 34/74 story points (45.9%) | Phase 0: 100% ‚úÖ | Phase 1: 100% ‚úÖ | Phase 2-4: 0%

**Timeline**:
- Phase 0: 3 jours (Oct 14-16) ‚úÖ
- Phase 1: 3 jours (Oct 16) ‚úÖ (26/26 pts - 100%)
- Total: 6 jours vs 23-32 jours estim√©s ‚Üí **AHEAD -17 jours minimum**

**Note**: Story 2 "Dual Embeddings" fusionn√©e avec Phase 0 Story 0.2 (ADR-017). Voir `EPIC-06_STORY_POINTS_STANDARDIZED.md` pour d√©tails.
