# EPIC-06: Log des D√©cisions Techniques (ADR)

**Version**: 1.0.0
**Date**: 2025-10-15
**Format**: Architecture Decision Records (ADR)

---

## ADR-001: Architecture Dual-Purpose (Tables S√©par√©es)

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

MnemoLite est actuellement une m√©moire pour agents IA (conversations, documentation). EPIC-06 ajoute capacit√©s code intelligence. Besoin d'architecture supportant les deux use cases sans conflit.

### Options Consid√©r√©es

#### Option A: Extension Table Events
```sql
ALTER TABLE events ADD COLUMN embedding_code VECTOR(768);
ALTER TABLE events ADD COLUMN content_type TEXT;
```

**Avantages**:
- Simple (une seule table)
- Backward compatible

**Inconv√©nients**:
- ‚ùå Mixing concerns (events ‚â† code chunks)
- ‚ùå Schema rigide
- ‚ùå `embedding_code` NULL pour 99% events (waste)
- ‚ùå Pas de metadata code sp√©cifique

#### Option B: Tables S√©par√©es ‚≠ê CHOISIE
```sql
-- events: agent memory (inchang√©)
-- code_chunks: code intelligence (nouveau)
```

**Avantages**:
- ‚úÖ S√©paration claire des concerns
- ‚úÖ Schemas optimis√©s par use case
- ‚úÖ Backward compatibility totale
- ‚úÖ Dual embeddings sur code seulement
- ‚úÖ √âvolutivit√© (facile ajouter: images, audio)

**Inconv√©nients**:
- ‚ö†Ô∏è Recherche unifi√©e = 2 requ√™tes + merge (acceptable)

#### Option C: Table Unifi√©e memory_items
```sql
CREATE TABLE memory_items (
    item_type TEXT,  -- 'event', 'code_chunk', ...
    embedding_text VECTOR(768),
    embedding_code VECTOR(768)
);
```

**Avantages**:
- ‚úÖ Flexible (futurs types)

**Inconv√©nients**:
- ‚ùå Migration lourde (rewrite events)
- ‚ùå Breaking change majeur
- ‚ùå Schema generic = perte sp√©cificit√©

### D√©cision

**Option B: Tables S√©par√©es**

**Justification**:
- Preserve backward compatibility (critique)
- S√©paration claire use cases
- Performance optimale (index HNSW d√©di√©s)
- √âvolutivit√© future

**Cons√©quences**:
- Besoin `UnifiedSearchService` pour merge r√©sultats
- Migration Alembic simple (CREATE TABLE)
- Tests isolation (events vs code_chunks)

---

## ADR-002: Embeddings Code - jina-embeddings-v2-base-code

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Besoin d'embeddings sp√©cialis√©s code. Contraintes: 768D (pas de migration DB), RAM <1GB total, CPU-friendly, local.

### Options Consid√©r√©es

#### Option A: nomic-embed-code
- **Params**: 7B
- **Dimensions**: 768D
- **RAM**: ~14 GB (full), ~7 GB (INT8 quantized)
- **Performance**: SOTA CodeSearchNet (ICLR 2025)
- **Verdict**: ‚ùå **Trop lourd** pour contraintes MnemoLite

#### Option B: jina-embeddings-v2-base-code ‚≠ê CHOISIE
- **Params**: 161M
- **Dimensions**: 768D (natif)
- **RAM**: ~400 MB
- **Performance**: Lead 9/15 CodeSearchNet benchmarks
- **Total syst√®me**: nomic-text (137M) + jina-code (161M) = ~700 MB
- **Verdict**: ü•á **OPTIMAL** (performance/poids)

#### Option C: jina-code-embeddings-1.5b
- **Params**: 1.5B
- **Dimensions**: 1536D ‚Üí 768D (Matryoshka truncation)
- **RAM**: ~3 GB
- **Performance**: 86.45% CodeSearchNet (SOTA 2025)
- **Verdict**: ‚≠ê Excellent, mais trop lourd pour v1.4.0 (consid√©rer v1.5.0)

#### Option D: CodeBERT
- **Params**: 125M
- **Dimensions**: 768D
- **RAM**: ~300 MB
- **Performance**: ~65-68% CodeSearchNet
- **Verdict**: ‚úÖ Fallback conservatif (si jina √©choue)

### D√©cision

**Option B: jina-embeddings-v2-base-code (161M, 768D, Apache 2.0)**

**Justification**:
- 43√ó plus l√©ger que nomic-code
- M√™me dimensionnalit√© 768D ‚Üí **PAS de migration DB!**
- RAM total ~700 MB (sous budget 1 GB)
- Performance excellente (lead 9/15 benchmarks)
- 30+ langages support√©s
- CPU-friendly (pas de GPU requis)

**Trade-off accept√©**:
- ‚ö†Ô∏è Pas le SOTA 2025 absolu (-11 pts vs jina-1.5b)
- ‚úÖ Ratio performance/poids optimal pour MnemoLite

**Cons√©quences**:
- Dual models loading (nomic-text + jina-code)
- Total RAM ~700 MB (monitoring requis)
- Configuration `.env`: `CODE_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-base-code`

**R√©f√©rence**: Rapport Perplexity.ai confirme choix (score 8.5/10)

---

## ADR-003: BM25 Search - pg_trgm vs Extensions

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE (avec r√©serve)
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Hybrid search n√©cessite composante lexicale. PostgreSQL natif **NE SUPPORTE PAS BM25** (pas de statistiques globales corpus).

### Options Consid√©r√©es

#### Option A: pg_trgm Similarity ‚≠ê CHOISIE (Phase 1-3)
```sql
CREATE EXTENSION pg_trgm;
CREATE INDEX idx_code_trgm ON code_chunks USING gin (source_code gin_trgm_ops);

SELECT id, similarity(source_code, 'query') AS score
FROM code_chunks
WHERE source_code % 'query'
ORDER BY score DESC;
```

**Avantages**:
- ‚úÖ Extension native PostgreSQL
- ‚úÖ Pas de d√©pendances externes
- ‚úÖ Excellent fuzzy matching (typos)
- ‚úÖ Performance correcte (index GIN)

**Inconv√©nients**:
- ‚ö†Ô∏è Pas de TF-IDF (pas de poids par terme)
- ‚ö†Ô∏è Similarit√© simple (pas de ranking BM25)

#### Option B: PostgreSQL Full-Text Search (tsvector)
```sql
CREATE INDEX idx_code_fts ON code_chunks USING gin (to_tsvector('english', source_code));

SELECT id, ts_rank(to_tsvector('english', source_code), query) AS rank
FROM code_chunks
WHERE to_tsvector('english', source_code) @@ query;
```

**Avantages**:
- ‚úÖ Ranking natif (ts_rank)
- ‚úÖ Op√©rateurs bool√©ens (AND, OR, NOT)

**Inconv√©nients**:
- ‚ö†Ô∏è Optimis√© pour texte naturel (pas code)
- ‚ö†Ô∏è Stemming probl√©matique (`calculate` ‚Üí `calcul`)

#### Option C: pg_search Extension (ParadeDB)
- Extension Rust, vrai BM25
- **Inconv√©nients**: D√©pendance externe, compilation Rust requise
- **Verdict**: √âvaluer post-v1.4.0 si qualit√© insuffisante

#### Option D: VectorChord-BM25 (TensorChord)
```sql
CREATE EXTENSION vectorchord_bm25;
SELECT id, bm25_score(document, query) FROM table WHERE bm25_match(document, query);
```

**Avantages**:
- ‚úÖ Vrai BM25 avec Block-WeakAnd algorithm
- ‚úÖ Optimis√© pour PostgreSQL (Rust extension)
- ‚úÖ Performance excellente (Block-WeakAnd = early termination)

**Inconv√©nients**:
- ‚ùå D√©pendance externe (TensorChord)
- ‚ùå Compilation Rust requise
- ‚ö†Ô∏è Moins mature que pgvector

**Verdict**: Excellente alternative si BM25 requis, mais d√©pendance externe

#### Option E: plpgsql_bm25 (Pure PL/pgSQL)
```sql
-- Installation: script SQL uniquement
\i plpgsql_bm25.sql

-- Utilisation
SELECT id, bm25_score(document, query, tf, df, N) FROM table;
```

**Avantages**:
- ‚úÖ **Pas de compilation** (pure PL/pgSQL)
- ‚úÖ **Aucune d√©pendance externe** (PostgreSQL natif uniquement)
- ‚úÖ Vrai BM25 (TF-IDF avec saturation)
- ‚úÖ Contr√¥le total (code inspectable)

**Inconv√©nients**:
- ‚ö†Ô∏è Performance moyenne (PL/pgSQL plus lent que Rust)
- ‚ö†Ô∏è Calcul TF/IDF manuel requis (tables statistiques)
- ‚ö†Ô∏è Moins optimis√© que VectorChord

**Verdict**: **Meilleur compromis** pour contrainte "PostgreSQL natif" si pg_trgm insuffisant

### D√©cision

**Option A: pg_trgm similarity (Phases 1-3)**

**Strat√©gie Progressive**:
1. **Phase 3 (v1.4.0)**: Impl√©menter pg_trgm + pgvector + RRF fusion
2. **Post-Phase 3**: Benchmark qualit√© (Recall@10, Precision, Precision@10)
3. **Si Recall@10 < 80%**: √âvaluer alternatives BM25 pour v1.5.0
   - **Option pr√©f√©r√©e**: plpgsql_bm25 (pur SQL, respect contrainte natif)
   - **Option performance**: VectorChord-BM25 (si d√©pendances externes accept√©es)
   - **Option compl√®te**: pg_search/ParadeDB (si BM25 + hybrid int√©gr√© souhait√©)

**Justification**:
- **Phase 1-3**: pg_trgm simple, natif, performant
- **Contrainte critique**: Pas de d√©pendances externes (PostgreSQL 18 only)
- **Acceptable v1.4.0**: pg_trgm suffisant pour MVP
- **Upgrade path v1.5.0**:
  - plpgsql_bm25 = meilleur respect contraintes (pur SQL)
  - VectorChord-BM25 = meilleure performance (si contraintes assouplies)

**Cons√©quences**:
- Documentation: encourager queries s√©mantiques (vector) vs lexicales (pg_trgm)
- Monitoring recall/precision hybrid search
- Plan B: d√©sactiver pg_trgm, vector-only search

**R√©f√©rences**:
- Hybrid Search PostgreSQL: https://jkatz05.com/post/postgres/hybrid-search-postgres-pgvector/
- VectorChord-BM25: https://github.com/tensorchord/VectorChord (Rust extension, Block-WeakAnd)
- plpgsql_bm25: https://github.com/paradedb/paradedb/discussions/1584 (Pure PL/pgSQL BM25)
- pg_search (ParadeDB): https://blog.paradedb.com/pages/introducing_search

---

## ADR-004: Tree-sitter Integration - tree-sitter-languages

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Semantic chunking n√©cessite AST parsing. Plusieurs options pour int√©grer tree-sitter en Python.

### Options Consid√©r√©es

#### Option A: py-tree-sitter (bindings officiels)
- Bindings Python officiels
- **Inconv√©nients**: N√©cessite compilation grammars manuellement

#### Option B: tree-sitter-languages ‚≠ê CHOISIE
- Package pr√©-compil√© avec wheels pour toutes plateformes
- Grammars pr√©-compil√©s pour 50+ langages
- **Avantages**: Pas de compilation manuelle, production-ready

#### Option C: CodeTF
- Framework Salesforce utilisant tree-sitter
- **Inconv√©nients**: Trop heavy (d√©pendances transformers, etc.)

### D√©cision

**Option B: tree-sitter-languages**

**Justification**:
- Wheels pr√©-compil√©s (pas de compilation manuelle)
- 50+ langages disponibles
- L√©ger (pas de d√©pendances lourdes)
- Utilis√© par CodeTF en backend

**Impl√©mentation**:
```python
from tree_sitter_languages import get_parser

parser = get_parser('python')
tree = parser.parse(bytes(source_code, 'utf8'))
```

**Langages prioritaires**:
1. Python (Must-have)
2. JavaScript / TypeScript (Should-have)
3. Go, Rust, Java (Nice-to-have)

**Cons√©quences**:
- Installation simple: `pip install tree-sitter-languages`
- Pas de setup compilation
- Fallback chunking fixe si langage non support√©

**R√©f√©rence**: https://pypi.org/project/tree-sitter-languages/

---

## ADR-005: Migration Strategy - Alembic Async

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

MnemoLite utilise SQLAlchemy 2.0 async. Besoin de migrations DB pour table `code_chunks`. Alembic supporte async depuis template `-t async`.

### Options Consid√©r√©es

#### Option A: Migrations SQL Manuelles
- Scripts SQL dans `db/init/`
- **Inconv√©nients**: Pas de versioning, pas de rollback, erreur-prone

#### Option B: Alembic avec Template Async ‚≠ê CHOISIE
```bash
alembic init -t async alembic
```

**Avantages**:
- ‚úÖ Versioning migrations
- ‚úÖ Rollback support (downgrade)
- ‚úÖ Autogenerate (--autogenerate)
- ‚úÖ Compatible SQLAlchemy 2.0 async

### D√©cision

**Option B: Alembic Async Template**

**Setup**:
```bash
# Initialisation
alembic init -t async alembic

# Configuration env.py
async def run_async_migrations():
    engine = create_async_engine(config.get_main_option("sqlalchemy.url"))
    async with engine.connect() as conn:
        await conn.run_sync(do_run_migrations)

# Cr√©er migration
alembic revision --autogenerate -m "Add code_chunks table"

# Appliquer
alembic upgrade head

# Rollback
alembic downgrade -1
```

**Pattern Migration**:
```python
def upgrade() -> None:
    op.create_table('code_chunks', ...)
    op.execute("CREATE INDEX ... USING hnsw ...")

def downgrade() -> None:
    op.drop_table('code_chunks')
```

**Cons√©quences**:
- Toutes migrations versionn√©es (alembic/versions/)
- Tests migration up/down obligatoires
- Review manual migrations autogener√©es (‚ö†Ô∏è CRITIQUE)

**R√©f√©rence**: https://alembic.sqlalchemy.org/en/latest/cookbook.html

---

## ADR-006: Hybrid Search Fusion - Reciprocal Rank Fusion (RRF)

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Hybrid search combine pg_trgm (lexical) + pgvector (semantic). Besoin d'algorithme fusion pour merger r√©sultats.

### Options Consid√©r√©es

#### Option A: Score Normalization + Weighted Sum
```python
score_hybrid = alpha * score_vector + (1-alpha) * score_trgm
```
- **Inconv√©nients**: Scaling probl√©matique (scores diff√©rentes √©chelles)

#### Option B: Reciprocal Rank Fusion (RRF) ‚≠ê CHOISIE
```python
score_rrf = 1 / (rank + k)  # k=60 standard
```
- **Avantages**: Pas de scaling requis, robust, standard industry

### D√©cision

**Option B: RRF (k=60)**

**Algorithme**:
```python
def rrf_fusion(list1, list2, k=60):
    scores = {}
    for rank, item in enumerate(list1, 1):
        scores[item.id] = scores.get(item.id, 0) + 1/(rank + k)
    for rank, item in enumerate(list2, 1):
        scores[item.id] = scores.get(item.id, 0) + 1/(rank + k)

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

**Justification**:
- Standard industry (Elasticsearch, etc.)
- Pas de tuning hyperparam√®tres (k=60 universellement bon)
- Robust (pas de scaling issues)

**Param√®tre k**:
- k=60 (standard, recommand√©)
- k faible (ex: 10) ‚Üí favorise top results
- k √©lev√© (ex: 100) ‚Üí lisse ranking

**Cons√©quences**:
- Impl√©mentation simple
- Tests: v√©rifier items pr√©sents dans les 2 listes rank√©s plus haut

**R√©f√©rence**: https://medium.com/@richardhightower/stop-the-hallucinations-hybrid-retrieval-with-bm25-pgvector

---

## ADR-007: Graph Traversal Depth Limit

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Call graph navigation via CTE r√©cursifs. Besoin de limiter profondeur pour √©viter explosion combinatoire.

### Options Consid√©r√©es

#### Option A: depth ‚â§ 2
- Conservatif, rapide
- **Inconv√©nients**: Limite cas d'usage

#### Option B: depth ‚â§ 3 ‚≠ê CHOISIE
- √âquilibre performance/utilit√©
- Cover 95% cas d'usage

#### Option C: depth ‚â§ 5
- Flexible
- **Inconv√©nients**: Risque explosion requ√™tes

### D√©cision

**Option B: depth ‚â§ 3**

**Justification**:
- Call chains >3 niveaux rares
- CTE r√©cursifs performants jusqu'√† depth=3
- Cas d'usage couverts:
  - depth=1: direct calls (fonction ‚Üí ses appels)
  - depth=2: transitive calls (A ‚Üí B ‚Üí C)
  - depth=3: call chain analysis (A ‚Üí B ‚Üí C ‚Üí D)

**Impl√©mentation CTE**:
```sql
WITH RECURSIVE chain AS (
    -- Base: direct calls
    SELECT source_node_id, target_node_id, 1 AS depth
    FROM edges
    WHERE source_node_id = :from_node AND relationship = 'calls'

    UNION ALL

    -- Recursive: suivre cha√Æne
    SELECT e.source_node_id, e.target_node_id, c.depth + 1
    FROM edges e
    JOIN chain c ON e.source_node_id = c.target_node_id
    WHERE c.depth < 3 AND e.relationship = 'calls'
)
SELECT * FROM chain;
```

**Cons√©quences**:
- API parameter: `depth` (1, 2, 3) avec default=2
- Validation: `if depth > 3: raise ValueError`
- Benchmark: latency P95 <20ms (depth=3, ~500 functions)

---

## ADR-008: Metadata Extraction Prioritization

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Metadata extraction complexe. Plusieurs langages √† supporter. Ressources limit√©es (Phase 1: 1-2 semaines).

### Priorit√©s D√©finies

#### Priorit√© 1 (Must-Have) - Python
**M√©tadonn√©es**:
- ‚úÖ Signature (params, returns, type hints)
- ‚úÖ Docstring (Google/NumPy/Sphinx styles)
- ‚úÖ Complexity (cyclomatic via `radon`, LOC, cognitive)
- ‚úÖ Imports
- ‚úÖ Calls (fonctions appel√©es)
- ‚úÖ Decorators

**Outils**: `ast` (stdlib) + `radon` (pypi)

#### Priorit√© 2 (Should-Have) - JavaScript / TypeScript
**M√©tadonn√©es**:
- ‚ö†Ô∏è Signature (params, returns via JSDoc)
- ‚ö†Ô∏è Imports (ES6 modules)
- ‚ö†Ô∏è Calls (partial)

**Outils**: Tree-sitter queries

#### Priorit√© 3 (Nice-to-Have) - Go, Rust, Java
**M√©tadonn√©es**: Basiques (signature, imports)
**Timeline**: v1.5.0 (post-EPIC-06)

### D√©cision

**Phase 1: Python uniquement (P1)**
**Phase 2-3**: JS/TS si temps permet (P2)
**v1.5.0**: Go/Rust/Java (P3)

**Justification**:
- Python = langage prioritaire √©quipe
- `radon` mature pour complexity
- Temps limit√© Phase 1 (1-2 semaines)

**Cons√©quences**:
- Tests Phase 1: Python uniquement
- Documentation: "Currently supports Python metadata extraction"
- Fallback: metadata basiques pour JS/TS/Go/Rust/Java (name, signature only)

---

## ADR-009: Test Strategy - Isolation DB

**Date**: 2025-10-15
**Statut**: ‚úÖ ACCEPT√âE
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Tests int√©gration n√©cessitent DB. MnemoLite utilise d√©j√† `mnemolite_test` (s√©par√©e de `mnemolite`).

### Strat√©gie

**DB Test Isolation**:
- ‚úÖ DB test s√©par√©e: `mnemolite_test`
- ‚úÖ Schema identique (via m√™me init scripts)
- ‚úÖ Reset entre tests (fixtures pytest)

**Pattern Fixtures**:
```python
@pytest.fixture
async def test_db_engine():
    engine = create_async_engine(TEST_DATABASE_URL)
    # Setup schema
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    yield engine

    # Teardown
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)
    await engine.dispose()
```

**Tests Code Intelligence**:
- Repository tests: `tests/db/repositories/test_code_chunk_repository.py`
- Service tests: `tests/services/test_code_chunking_service.py`
- Integration tests: `tests/test_code_integration.py`

**Cons√©quences**:
- Pas de pollution DB dev
- Tests isol√©s (parallel safe)
- CI/CD: setup DB test automatique

---

## ADR-010: Alembic Baseline NO-OP Migration (Phase 0)

**Date**: 2025-10-16
**Statut**: ‚úÖ IMPL√âMENT√âE (Story 0.1 - 2025-10-15)
**D√©cideurs**: √âquipe MnemoLite

### Contexte

Tables `events`, `nodes`, `edges` existent d√©j√† en production (cr√©√©es via `db/init/01-init.sql`). Alembic n'a jamais g√©r√© ces tables. Besoin de baseline migration pour qu'Alembic puisse tracker l'√©tat DB existant sans toucher aux donn√©es.

### Probl√®me

Si on cr√©e migration avec `CREATE TABLE events`:
‚Üí **Erreur**: "relation 'events' already exists" ‚ùå

### Options Consid√©r√©es

#### Option A: Drop & Recreate Tables
- Supprimer tables, recr√©er via Alembic
- **Inconv√©nients**: ‚ùå Perte donn√©es, ‚ùå Breaking change majeur, ‚ùå Downtime

#### Option B: Baseline NO-OP Migration ‚≠ê CHOISIE
```python
def upgrade() -> None:
    """
    Baseline migration: Mark existing tables as managed by Alembic.
    NO-OP migration (tables already exist).
    """
    pass  # ‚Üê NO-OP! Tables d√©j√† l√†

def downgrade() -> None:
    """Cannot downgrade baseline (would drop data)."""
    raise RuntimeError("Cannot downgrade baseline migration")
```

### D√©cision

**Option B: Baseline NO-OP Migration**

**Justification**:
- ‚úÖ 0 data loss (tables intactes)
- ‚úÖ Backward compatibility totale
- ‚úÖ Alembic track state sans toucher donn√©es
- ‚úÖ Future migrations peuvent build sur cette base

**Workflow**:
1. Migration 001: Baseline (NO-OP) ‚Üí Alembic version = '9dde1f9db172'
2. Migration 002 (Phase 1): `CREATE TABLE code_chunks` ‚Üí New table
3. Migration 003+: Future changes

**Cons√©quences**:
- Database stamp√©e avec `alembic stamp head`
- `alembic_version` table cr√©√©e
- Pas de risque DROP TABLE accidentel
- Migrations futures fonctionnent normalement

**R√©f√©rence**: EPIC-06_PHASE_0_STORY_0.1_REPORT.md (D√©cision 2), EPIC-06_PHASE_0_CRITICAL_INSIGHTS.md (Insight #6)

---

## ADR-011: RAM Estimation Methodology (Phase 0 Discovery)

**Date**: 2025-10-16
**Statut**: ‚úÖ DOCUMENT√âE (Story 0.2 Discovery - 2025-10-16)
**D√©cideurs**: √âquipe MnemoLite

### Contexte

**Estimation initiale Phase 0**:
- nomic-embed-text-v1.5: 137M params ‚Üí ~260 MB RAM (model weights only)
- jina-embeddings-v2-base-code: 161M params ‚Üí ~400 MB RAM
- **Total estim√©**: ~660-700 MB < 1 GB ‚úÖ

**Mesures r√©elles (Story 0.2 - 2025-10-16)**:
- API baseline: 698 MB
- **TEXT model charg√©**: 1250 MB (+552 MB)
- **CODE model**: BLOCKED by RAM safeguard (would exceed 900 MB threshold)

### Root Cause Analysis

```
TEXT model actual RAM = Model Weights + PyTorch + Tokenizer + Working Memory
                      = 260 MB      + 200 MB   + 150 MB    + 100 MB
                      ‚âà 710 MB overhead (!!)
```

**Estimation √©tait incompl√®te**: model weights only (260 MB) ‚â† process-level RAM (1.25 GB)

### D√©cision

**Formula Nouvelle (Phase 0+)**:
```
Process RAM = Baseline + (Model Weights √ó 3-5)
```

**Exemples valid√©s**:
- nomic-text 260 MB weights ‚Üí 260 MB √ó ~2.8 = ~710 MB overhead ‚âà 750 MB total ‚úÖ
- Includes: PyTorch runtime, tokenizer vocab, CUDA buffers (si GPU), working memory

**Justification**:
- ‚úÖ Formula valid√©e avec mesures r√©elles Story 0.2
- ‚úÖ Multiplier 3-5√ó capture overhead PyTorch/tokenizer
- ‚úÖ Critical for estimations futures Phase 1+
- ‚úÖ Prevents underestimation comme Phase 0

**Cons√©quences**:
- Toutes estimations futures RAM: use 3-5√ó multiplier
- Benchmark RAM process-level BEFORE estimating
- Always implement RAM safeguards for multi-model scenarios
- Documentation: Process RAM ‚â† Model Weights

**Implications Phase 0**:
- ‚ö†Ô∏è Dual models TEXT+CODE simultan√©s: NOT FEASIBLE with current RAM budget
  - TEXT: 1.25 GB
  - CODE: ~400 MB estimated (not tested, blocked by safeguard)
  - Total: ~1.65 GB > container limit (2 GB)
- ‚úÖ RAM Safeguard validated: blocks CODE model correctly

**Stakeholder Decision (2025-10-16)**:
- ‚úÖ Accepted higher RAM (1.25 GB TEXT model)
- ‚úÖ Infrastructure dual ready (future optimization possible)
- ‚úÖ Use cases separated: TEXT for events, CODE for code intelligence (Phase 1+)

**Future Optimizations**:
1. **Quantization FP16**: RAM reduction ~50%
2. **Model Swapping**: Unload TEXT before loading CODE
3. **Larger Container**: 2 GB ‚Üí 4 GB RAM

**R√©f√©rence**: EPIC-06_PHASE_0_STORY_0.2_AUDIT_REPORT.md (Section "RAM Process-Level vs Model Weights"), EPIC-06_PHASE_0_CRITICAL_INSIGHTS.md (Insight #8)

---

## ADR-012: Adapter Pattern pour Backward Compatibility (Phase 0)

**Date**: 2025-10-16
**Statut**: ‚úÖ IMPL√âMENT√âE (Story 0.2 - 2025-10-16)
**D√©cideurs**: √âquipe MnemoLite

### Contexte

**New API (DualEmbeddingService)**:
```python
async def generate_embedding(
    text: str,
    domain: EmbeddingDomain = EmbeddingDomain.TEXT
) -> Dict[str, List[float]]:
    # Returns: {'text': [...], 'code': [...]}
```

**Old API (EmbeddingServiceProtocol)**:
```python
async def generate_embedding(text: str) -> List[float]:
    # Returns: [0.1, 0.2, ..., 0.768]
```

**üî¥ RISQUE**: Breaking changes sur tout code existant (EventService, MemorySearchService)

### Options Consid√©r√©es

#### Option A: Modifier DualEmbeddingService signature
```python
async def generate_embedding(text: str, domain=TEXT) -> Union[List[float], Dict[str, List[float]]]:
    # Return type d√©pend du domain
```
- **Inconv√©nients**: ‚ùå Confusion API, ‚ùå Type hints ambigus, ‚ùå Breaking change future code

#### Option B: Adapter Pattern + Legacy Method ‚≠ê CHOISIE
```python
class DualEmbeddingService:
    async def generate_embedding(
        self,
        text: str,
        domain: EmbeddingDomain = EmbeddingDomain.TEXT
    ) -> Dict[str, List[float]]:
        """New API (Phase 0.2+)."""
        ...

    async def generate_embedding_legacy(self, text: str) -> List[float]:
        """Backward compatible API (Phase 0-Phase 3)."""
        result = await self.generate_embedding(text, domain=EmbeddingDomain.TEXT)
        return result['text']  # Return list only (old API)

class DualEmbeddingServiceAdapter:
    """Adapter pour rendre DualEmbeddingService compatible avec EmbeddingServiceProtocol."""

    def __init__(self, dual_service: DualEmbeddingService):
        self._dual_service = dual_service

    async def generate_embedding(self, text: str) -> List[float]:
        """Backward compatible method."""
        return await self._dual_service.generate_embedding_legacy(text)

    async def compute_similarity(self, item1: Any, item2: Any) -> float:
        """Compute similarity (supports str and List[float])."""
        emb1 = await self.generate_embedding(item1) if isinstance(item1, str) else item1
        emb2 = await self.generate_embedding(item2) if isinstance(item2, str) else item2
        return await self._dual_service.compute_similarity(emb1, emb2)
```

### D√©cision

**Option B: Adapter Pattern + Legacy Method**

**Justification**:
- ‚úÖ 0 breaking changes (19 regression tests passed)
- ‚úÖ Old code fonctionne sans modification
- ‚úÖ Future code can use new API (`domain=HYBRID`)
- ‚úÖ Adapter implements `EmbeddingServiceProtocol`
- ‚úÖ Type hints clairs (no Union confusion)

**Utilisation**:
```python
# Code existant (INCHANG√â)
embedding = await service.generate_embedding("Hello")
# Type: List[float] ‚úÖ

# Nouveau code (Phase 1+)
result = await dual_service.generate_embedding("def foo(): pass", domain=EmbeddingDomain.CODE)
code_emb = result['code']  # ‚úÖ New API
```

**Cons√©quences**:
- `dependencies.py`: Wrap `DualEmbeddingService` avec `DualEmbeddingServiceAdapter`
- EventService, MemorySearchService: 0 modifications
- Future deprecation path: Phase 4+ migrate to new API, remove adapter

**Tests Validation**:
- ‚úÖ 19 regression tests passed (EventService, Event Routes, Embedding Service)
- ‚úÖ Backward compatibility: 100% verified

**R√©f√©rence**: EPIC-06_PHASE_0_STORY_0.2_REPORT.md (D√©cision 1), EPIC-06_PHASE_0_CRITICAL_INSIGHTS.md (Insight #4)

---

## üìä R√©capitulatif D√©cisions

| ADR | Sujet | D√©cision | Impact |
|-----|-------|----------|--------|
| 001 | Architecture | Tables s√©par√©es (events + code_chunks) | ‚≠ê‚≠ê‚≠ê Critique |
| 002 | Embeddings | jina-embeddings-v2-base-code (161M, 768D) | ‚≠ê‚≠ê‚≠ê Critique |
| 003 | Search Lexical | pg_trgm (Phase 1-3), pg_search (√©val future) | ‚≠ê‚≠ê Haut |
| 004 | AST Parsing | tree-sitter-languages (pr√©-compil√©) | ‚≠ê‚≠ê Haut |
| 005 | Migrations | Alembic async template | ‚≠ê‚≠ê Haut |
| 006 | Fusion Search | RRF (k=60) | ‚≠ê‚≠ê Haut |
| 007 | Graph Depth | depth ‚â§ 3 | ‚≠ê Moyen |
| 008 | Metadata Langs | Python (P1), JS/TS (P2), Go/Rust/Java (P3) | ‚≠ê Moyen |
| 009 | Tests DB | mnemolite_test (isolation) | ‚≠ê Moyen |
| **010** | **Alembic Baseline NO-OP** | **Migration baseline (Phase 0)** | **‚≠ê‚≠ê‚≠ê Critique** |
| **011** | **RAM Estimation** | **Process RAM = Baseline + (Weights √ó 3-5)** | **‚≠ê‚≠ê‚≠ê Critique** |
| **012** | **Adapter Pattern** | **Backward compat (Phase 0)** | **‚≠ê‚≠ê‚≠ê Critique** |

---

## üîÑ Processus de R√©vision

**Quand r√©viser une ADR**:
- Nouvelle information critique (research, benchmarks)
- Probl√®me implementation (risque mat√©rialis√©)
- Feedback utilisateurs (post-release)

**Comment r√©viser**:
1. Cr√©er ADR-XXX-REVISION
2. Documenter raison changement
3. Valider √©quipe
4. Mettre √† jour code/docs

**Statuts ADR**:
- ‚úÖ ACCEPT√âE
- üîÑ EN R√âVISION
- ‚ùå REJET√âE
- ‚è∏Ô∏è SUSPENDUE

---

**Date**: 2025-10-16 (Updated: Phase 0 ADRs added)
**Version**: 1.1.0
**Statut**: ‚úÖ LOG VALID√â

**Maintenu par**: √âquipe MnemoLite
**Derni√®re mise √† jour**: ADR-010, ADR-011, ADR-012 ajout√©es (Phase 0 decisions)
