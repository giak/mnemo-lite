# EPIC-20: ObservabilitÃ© & Monitoring IntÃ©grÃ© - ULTRATHINK

**Date**: 2025-10-23
**Status**: ğŸ§  Brainstorming
**PrioritÃ©**: Haute (Production-Critical)

---

## ğŸ¯ Vision

**CrÃ©er un systÃ¨me d'observabilitÃ© intÃ©grÃ© dans l'UI MnemoLite** permettant de voir en temps rÃ©el :
- ğŸ“Š Performance des API endpoints
- ğŸ”´ Ã‰tat du cache Redis (hits/misses, memory)
- ğŸ˜ Performance PostgreSQL (queries, connections)
- ğŸ“ Logs structurÃ©s en temps rÃ©el
- ğŸ“ˆ MÃ©triques systÃ¨me (CPU, RAM, I/O)

**Principe** : L'admin doit pouvoir **diagnostiquer un problÃ¨me en production en 30 secondes** depuis l'UI.

---

## ğŸ§  Brainstorming: Que Monitorer ?

### 1. ğŸ“Š API & Workflow

#### MÃ©triques Essentielles

**Par Endpoint** :
```
GET  /v1/code/search/hybrid
â”œâ”€ Throughput: 12.5 req/s
â”œâ”€ Latency P50: 45ms
â”œâ”€ Latency P95: 120ms
â”œâ”€ Latency P99: 250ms
â”œâ”€ Success Rate: 99.2%
â”œâ”€ Error Rate: 0.8%
â””â”€ Top Errors:
   â””â”€ TimeoutError: 5 (last 1h)
```

**Endpoints Ã  Monitorer** :
- `/v1/code/search/hybrid` (critique)
- `/v1/code/search/lexical`
- `/v1/code/search/vector`
- `/v1/code/index` (POST)
- `/v1/code/graph/build`
- `/v1/code/graph/traverse`
- `/ui/*` (pages)

**Visualisation** :
- Timeline (derniÃ¨res 24h)
- Heatmap par heure/endpoint
- Table triable par latence/erreurs

---

### 2. ğŸ”´ Redis Cache

#### MÃ©triques Essentielles

**Global** :
```
Redis Status: âœ… Connected
â”œâ”€ Memory Used: 245 MB / 2 GB (12%)
â”œâ”€ Hit Rate: 87.3% (last 1h)
â”œâ”€ Keys Total: 1,247
â”œâ”€ Evictions: 23 (last 1h)
â””â”€ Connections: 5 / 20
```

**Par Cache Type** :
```
search_results
â”œâ”€ Keys: 342
â”œâ”€ Hit Rate: 92%
â”œâ”€ Avg TTL: 28s / 30s
â””â”€ Top Keys: [...]

embeddings
â”œâ”€ Keys: 105
â”œâ”€ Hit Rate: 78%
â”œâ”€ Avg TTL: 45s / 60s
â””â”€ Top Keys: [...]

graph_traversal
â”œâ”€ Keys: 89
â”œâ”€ Hit Rate: 95%
â””â”€ Avg TTL: 98s / 120s
```

**Alertes** :
- Hit rate < 70% â†’ "Cache inefficace"
- Memory > 80% â†’ "Risque d'Ã©viction"
- Evictions > 100/h â†’ "TTL trop Ã©levÃ©?"

**Visualisation** :
- Gauge pour memory usage
- Line chart pour hit rate (temps rÃ©el)
- Bar chart par cache type

---

### 3. ğŸ˜ PostgreSQL

#### MÃ©triques Essentielles

**Connexions** :
```
PostgreSQL Status: âœ… Healthy
â”œâ”€ Active Connections: 8 / 20
â”œâ”€ Idle Connections: 2
â”œâ”€ Max Connections: 100
â””â”€ Connection Pool: OK
```

**Performance** :
```
Query Performance
â”œâ”€ Slow Queries (>100ms): 3 (last 1h)
â”œâ”€ Total Queries: 2,847
â”œâ”€ Avg Query Time: 12ms
â””â”€ Cache Hit Ratio: 98.5%
```

**Top Slow Queries** :
```sql
1. SELECT * FROM code_chunks WHERE ... (245ms, 5 calls)
2. INSERT INTO events ... (180ms, 12 calls)
3. SELECT COUNT(*) FROM nodes ... (120ms, 3 calls)
```

**Tables** :
```
code_chunks
â”œâ”€ Rows: 14,523
â”œâ”€ Size: 45 MB
â”œâ”€ Index Size: 12 MB
â””â”€ Last Vacuum: 2h ago

events
â”œâ”€ Rows: 8,941
â”œâ”€ Size: 28 MB
â””â”€ Partitioned: No
```

**Alertes** :
- Slow queries > 10/h â†’ "Optimisation requise"
- Cache hit ratio < 95% â†’ "Index manquants?"
- Active connections > 80% â†’ "Risque de saturation"

**Visualisation** :
- Timeline slow queries
- Table queries avec EXPLAIN
- Gauge connections/memory

---

### 4. ğŸ“ Logs en Temps RÃ©el

#### Interface de Logs

**Filtres** :
```
[Level: ALL â–¾] [Service: ALL â–¾] [Time: Last 1h â–¾] [Search: ___________]
```

**Stream de Logs** :
```
2025-10-23 21:50:12 [INFO ] search_completed query="validate email" latency=45ms
2025-10-23 21:50:11 [DEBUG] cache_hit key="search:validate..." ttl=28s
2025-10-23 21:50:10 [WARN ] slow_query duration=120ms table="code_chunks"
2025-10-23 21:50:05 [ERROR] timeout endpoint="/v1/code/search/hybrid" duration=5002ms
```

**Features** :
- âœ… Streaming temps rÃ©el (SSE ou WebSocket)
- âœ… Filtrage multi-critÃ¨res
- âœ… Recherche full-text
- âœ… Colorisation par level
- âœ… Expand pour voir JSON complet
- âœ… Export (JSON, CSV)

**Niveaux** :
- ERROR (rouge)
- WARN (orange)
- INFO (bleu)
- DEBUG (gris)

---

### 5. ğŸ“ˆ SystÃ¨me (Host Metrics)

#### MÃ©triques Essentielles

**CPU** :
```
CPU Usage
â”œâ”€ Current: 34%
â”œâ”€ Avg (1h): 28%
â”œâ”€ Processes:
â”‚  â”œâ”€ uvicorn: 18%
â”‚  â”œâ”€ postgres: 12%
â”‚  â””â”€ redis: 4%
```

**MÃ©moire** :
```
Memory Usage
â”œâ”€ Used: 1.2 GB / 4 GB (30%)
â”œâ”€ Processes:
â”‚  â”œâ”€ postgres: 580 MB
â”‚  â”œâ”€ uvicorn: 450 MB
â”‚  â””â”€ redis: 245 MB
```

**Disk I/O** :
```
Disk I/O
â”œâ”€ Read: 2.5 MB/s
â”œâ”€ Write: 1.2 MB/s
â””â”€ IOPS: 450
```

**RÃ©seau** :
```
Network
â”œâ”€ In: 5.2 Mbps
â”œâ”€ Out: 3.1 Mbps
â””â”€ Connections: 47
```

**Visualisation** :
- Sparklines pour CPU/RAM
- Real-time updates (5s interval)
- Alertes si > 80%

---

## ğŸ—ï¸ Architecture ProposÃ©e

### Approche 1ï¸âƒ£: KISS (MVP - RecommandÃ©)

**Stack** :
- Logs â†’ `structlog` (dÃ©jÃ  fait) + endpoint `/api/logs/stream`
- MÃ©triques â†’ PostgreSQL table `metrics` + agregation
- UI â†’ HTMX + Chart.js (dÃ©jÃ  utilisÃ©s)
- Temps rÃ©el â†’ Server-Sent Events (SSE) ou polling

**Avantages** :
- âœ… Pas de nouvelle dÃ©pendance
- âœ… Utilise stack existante
- âœ… Simple Ã  maintenir
- âœ… 2-3 jours de dev

**Architecture** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI Dashboard (/ui/monitoring/advanced)                      â”‚
â”‚ â”œâ”€ Chart.js (graphs)                                       â”‚
â”‚ â”œâ”€ HTMX (updates partiels)                                 â”‚
â”‚ â””â”€ SSE (logs temps rÃ©el)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI Backend                                             â”‚
â”‚ â”œâ”€ /api/monitoring/metrics (JSON)                          â”‚
â”‚ â”œâ”€ /api/monitoring/logs/stream (SSE)                       â”‚
â”‚ â”œâ”€ /api/monitoring/redis (status)                          â”‚
â”‚ â””â”€ /api/monitoring/postgres (stats)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL               â”‚  â”‚ Redis                       â”‚
â”‚ â”œâ”€ pg_stat_statements    â”‚  â”‚ â”œâ”€ INFO (memory, keys)     â”‚
â”‚ â”œâ”€ pg_stat_activity      â”‚  â”‚ â””â”€ SLOWLOG                 â”‚
â”‚ â””â”€ Table: metrics        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Stockage MÃ©triques** :
```sql
CREATE TABLE metrics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    metric_type VARCHAR(50) NOT NULL,  -- 'api', 'redis', 'postgres'
    metric_name VARCHAR(100) NOT NULL, -- 'latency', 'hit_rate', etc.
    value FLOAT NOT NULL,
    metadata JSONB,

    INDEX idx_metrics_type_time (metric_type, timestamp DESC)
);

-- Partition par jour (optionnel si gros volume)
```

**Exemple d'insertion** :
```python
# Dans search_metrics.py (dÃ©jÃ  existant)
async def record_metric(db, metric_type: str, metric_name: str, value: float, metadata: dict):
    await db.execute(
        "INSERT INTO metrics (metric_type, metric_name, value, metadata) VALUES ($1, $2, $3, $4)",
        metric_type, metric_name, value, metadata
    )
```

---

### Approche 2ï¸âƒ£: Standard (Prometheus-Like)

**Stack** :
- MÃ©triques â†’ Prometheus + Grafana
- Logs â†’ Loki
- Traces â†’ Tempo (optionnel)

**Avantages** :
- âœ… Industry standard
- âœ… Nombreux dashboards prÃ©-faits
- âœ… Alerting puissant

**InconvÃ©nients** :
- âŒ ComplexitÃ© accrue (3+ services)
- âŒ Maintenance overhead
- âŒ Pas intÃ©grÃ© Ã  l'UI MnemoLite

**Verdict** : â¸ï¸ **YAGNI** pour l'instant (sauf si besoin multi-instance)

---

### Approche 3ï¸âƒ£: Hybrid

**Stack** :
- MÃ©triques â†’ Table PostgreSQL + export Prometheus (optionnel)
- Logs â†’ structlog + UI intÃ©grÃ©e
- UI â†’ MnemoLite (natif) + Grafana (externe, optionnel)

**Avantages** :
- âœ… FlexibilitÃ©
- âœ… Peut Ã©voluer vers Prometheus plus tard
- âœ… Pas de lock-in

---

## ğŸ¨ UI/UX ProposÃ©e

### Dashboard Principal (`/ui/monitoring/advanced`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ›ï¸  MnemoLite Monitoring                                  [Last 1h â–¾]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚ â”‚ ğŸ“Š API         â”‚ â”‚ ğŸ”´ Redis       â”‚ â”‚ ğŸ˜ PostgreSQL  â”‚             â”‚
â”‚ â”‚ 15 req/s       â”‚ â”‚ 87% hit rate   â”‚ â”‚ 8/20 conn      â”‚             â”‚
â”‚ â”‚ 45ms P50       â”‚ â”‚ 245 MB / 2 GB  â”‚ â”‚ 98.5% cache    â”‚             â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ ğŸ“ˆ Latency by Endpoint (Last 1h)                                â”‚   â”‚
â”‚ â”‚                                                                 â”‚   â”‚
â”‚ â”‚    [Line chart: P50/P95/P99 pour chaque endpoint]              â”‚   â”‚
â”‚ â”‚                                                                 â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ ğŸ”´ Redis Hit Rate            â”‚ â”‚ ğŸ˜ Top Slow Queries          â”‚    â”‚
â”‚ â”‚ [Gauge chart: 87%]           â”‚ â”‚ 1. SELECT ... (245ms)        â”‚    â”‚
â”‚ â”‚                              â”‚ â”‚ 2. INSERT ... (180ms)        â”‚    â”‚
â”‚ â”‚ search: 92%                  â”‚ â”‚ 3. SELECT ... (120ms)        â”‚    â”‚
â”‚ â”‚ embed: 78%                   â”‚ â”‚ [View Details â†’]             â”‚    â”‚
â”‚ â”‚ graph: 95%                   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚                                                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ ğŸ“ Live Logs                                            [Pause] â”‚   â”‚
â”‚ â”‚ [Level â–¾] [Service â–¾] [Search: ____________]                   â”‚   â”‚
â”‚ â”‚                                                                 â”‚   â”‚
â”‚ â”‚ 21:50:12 [INFO ] search_completed latency=45ms                 â”‚   â”‚
â”‚ â”‚ 21:50:11 [DEBUG] cache_hit key="search:..."                    â”‚   â”‚
â”‚ â”‚ 21:50:10 [WARN ] slow_query duration=120ms                     â”‚   â”‚
â”‚ â”‚ 21:50:05 [ERROR] timeout duration=5002ms                       â”‚   â”‚
â”‚ â”‚                                                                 â”‚   â”‚
â”‚ â”‚ [Auto-scroll âœ“] [Export CSV]                                   â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pages DÃ©taillÃ©es

**`/ui/monitoring/redis`** :
- Hit rate par cache type (timeline)
- Memory usage (gauge)
- Top keys (table)
- Evictions (timeline)
- Commandes Redis (SLOWLOG)

**`/ui/monitoring/postgres`** :
- Slow queries (table avec EXPLAIN)
- Connexions actives (gauge)
- Cache hit ratio (timeline)
- Tables sizes (bar chart)
- Index usage (table)

**`/ui/monitoring/api`** :
- Latency par endpoint (heatmap)
- Error rate (timeline)
- Top erreurs (table)
- Request rate (sparkline)

**`/ui/monitoring/logs`** :
- Stream temps rÃ©el
- Filtres avancÃ©s
- Full-text search
- Export

---

## ğŸš€ Features ProposÃ©es (PrioritÃ©es)

### ğŸŸ¢ MVP (Must-Have - 5 pts)

**Story 20.1: Infrastructure de MÃ©triques (2 pts)**
- Table `metrics` PostgreSQL
- Service `MetricsCollector`
- Endpoints API `/api/monitoring/*`

**Story 20.2: Dashboard Monitoring UI (2 pts)**
- Page `/ui/monitoring/advanced`
- Cartes rÃ©sumÃ© (API, Redis, PostgreSQL)
- Charts basiques (Chart.js)

**Story 20.3: Logs en Temps RÃ©el (1 pt)**
- SSE endpoint `/api/logs/stream`
- UI logs avec filtres
- Auto-scroll + colorisation

---

### ğŸŸ¡ Standard (Should-Have - 8 pts)

**Story 20.4: Redis Monitoring DÃ©taillÃ© (2 pts)**
- Hit rate par cache type
- Memory usage + alertes
- Top keys analysis

**Story 20.5: PostgreSQL Monitoring DÃ©taillÃ© (3 pts)**
- Slow queries avec EXPLAIN
- Connexions actives
- Cache hit ratio
- Index usage

**Story 20.6: API Performance Analysis (2 pts)**
- Latency breakdown par endpoint
- Error tracking avec stack traces
- Request rate timeline

**Story 20.7: Alerting Simple (1 pt)**
- Alertes configurables (seuils)
- Notifications dans l'UI (badge rouge)
- Log des alertes

---

### ğŸ”µ Nice-to-Have (8 pts)

**Story 20.8: Export Prometheus (2 pts)**
- Endpoint `/metrics` format Prometheus
- Export metrics vers TSDB externe

**Story 20.9: Distributed Tracing (3 pts)**
- Trace ID per request
- Span tracking (DB, Redis, API)
- UI flame graph

**Story 20.10: Predictive Alerting (2 pts)**
- ML simple (trend analysis)
- "Cache hit rate baisse depuis 1h"
- "Latency augmente depuis 30min"

**Story 20.11: Historical Reports (1 pt)**
- Daily/Weekly reports PDF
- Email digest
- Trends analysis

---

## ğŸ¯ API Design

### Endpoints ProposÃ©s

```python
# MÃ©triques
GET  /api/monitoring/metrics?type=api&period=1h       â†’ JSON metrics
GET  /api/monitoring/metrics/summary                  â†’ JSON summary (cards)

# Redis
GET  /api/monitoring/redis/status                     â†’ JSON status
GET  /api/monitoring/redis/keys                       â†’ JSON top keys
GET  /api/monitoring/redis/stats                      â†’ JSON hit rate, etc.

# PostgreSQL
GET  /api/monitoring/postgres/status                  â†’ JSON status
GET  /api/monitoring/postgres/slow_queries            â†’ JSON slow queries
GET  /api/monitoring/postgres/connections             â†’ JSON connections
GET  /api/monitoring/postgres/tables                  â†’ JSON tables stats

# Logs
GET  /api/monitoring/logs/stream                      â†’ SSE stream
GET  /api/monitoring/logs?level=error&since=1h        â†’ JSON logs

# SystÃ¨me
GET  /api/monitoring/system/cpu                       â†’ JSON CPU usage
GET  /api/monitoring/system/memory                    â†’ JSON memory usage
GET  /api/monitoring/system/disk                      â†’ JSON disk I/O
```

---

## ğŸ”§ ImplÃ©mentation Technique

### 1. Service de Collection

```python
# api/services/metrics_collector.py

import asyncio
import psutil
from typing import Dict, Any
from sqlalchemy.ext.asyncio import AsyncEngine

class MetricsCollector:
    """Collecte mÃ©triques systÃ¨me, Redis, PostgreSQL."""

    def __init__(self, engine: AsyncEngine, redis_client):
        self.engine = engine
        self.redis = redis_client

    async def collect_api_metrics(self) -> Dict[str, Any]:
        """Collecte mÃ©triques API depuis table metrics."""
        async with self.engine.begin() as conn:
            # AgrÃ©gation derniÃ¨re heure
            result = await conn.execute("""
                SELECT
                    metric_name,
                    AVG(value) as avg_value,
                    MAX(value) as max_value,
                    COUNT(*) as count
                FROM metrics
                WHERE metric_type = 'api'
                  AND timestamp > NOW() - INTERVAL '1 hour'
                GROUP BY metric_name
            """)
            return {row['metric_name']: row for row in result}

    async def collect_redis_metrics(self) -> Dict[str, Any]:
        """Collecte mÃ©triques Redis."""
        info = await self.redis.info()

        return {
            "memory_used_mb": info['used_memory'] / (1024 * 1024),
            "memory_max_mb": 2048,  # from config
            "keys_total": await self.redis.dbsize(),
            "hit_rate": self._calculate_hit_rate(info),
            "connected_clients": info['connected_clients'],
            "evicted_keys": info.get('evicted_keys', 0)
        }

    async def collect_postgres_metrics(self) -> Dict[str, Any]:
        """Collecte mÃ©triques PostgreSQL."""
        async with self.engine.begin() as conn:
            # Connexions actives
            result = await conn.execute("""
                SELECT
                    COUNT(*) FILTER (WHERE state = 'active') as active,
                    COUNT(*) FILTER (WHERE state = 'idle') as idle,
                    COUNT(*) as total
                FROM pg_stat_activity
            """)
            connections = result.fetchone()

            # Cache hit ratio
            result = await conn.execute("""
                SELECT
                    sum(heap_blks_hit) / nullif(sum(heap_blks_hit) + sum(heap_blks_read), 0) * 100 as cache_hit_ratio
                FROM pg_statio_user_tables
            """)
            cache_hit = result.scalar()

            return {
                "connections_active": connections['active'],
                "connections_idle": connections['idle'],
                "connections_total": connections['total'],
                "cache_hit_ratio": cache_hit or 0
            }

    async def collect_system_metrics(self) -> Dict[str, Any]:
        """Collecte mÃ©triques systÃ¨me (CPU, RAM)."""
        return {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_used_mb": psutil.virtual_memory().used / (1024 * 1024),
            "memory_total_mb": psutil.virtual_memory().total / (1024 * 1024),
            "memory_percent": psutil.virtual_memory().percent
        }
```

---

### 2. Endpoint API

```python
# api/routes/monitoring_routes.py

from fastapi import APIRouter, Depends
from fastapi.responses import StreamingResponse
from services.metrics_collector import MetricsCollector

router = APIRouter(prefix="/api/monitoring", tags=["monitoring"])

@router.get("/metrics/summary")
async def get_metrics_summary(collector: MetricsCollector = Depends()):
    """RÃ©sumÃ© des mÃ©triques pour dashboard."""
    return {
        "api": await collector.collect_api_metrics(),
        "redis": await collector.collect_redis_metrics(),
        "postgres": await collector.collect_postgres_metrics(),
        "system": await collector.collect_system_metrics()
    }

@router.get("/logs/stream")
async def stream_logs():
    """Stream logs en temps rÃ©el via SSE."""
    async def event_generator():
        # Lire logs depuis file ou database
        while True:
            # Simulate log stream
            log = await get_latest_log()
            yield f"data: {json.dumps(log)}\n\n"
            await asyncio.sleep(1)

    return StreamingResponse(event_generator(), media_type="text/event-stream")
```

---

### 3. UI Component (HTMX + Chart.js)

```html
<!-- templates/monitoring_advanced.html -->

<div id="monitoring-dashboard" hx-get="/api/monitoring/metrics/summary"
     hx-trigger="every 5s" hx-swap="innerHTML">

    <!-- Cards Summary -->
    <div class="metrics-cards">
        <div class="card">
            <h3>ğŸ“Š API</h3>
            <div class="metric-value">{{ api.request_rate }} req/s</div>
            <div class="metric-detail">P50: {{ api.latency_p50 }}ms</div>
        </div>

        <div class="card">
            <h3>ğŸ”´ Redis</h3>
            <div class="metric-value">{{ redis.hit_rate }}%</div>
            <div class="metric-detail">{{ redis.memory_used_mb }} MB</div>
        </div>

        <div class="card">
            <h3>ğŸ˜ PostgreSQL</h3>
            <div class="metric-value">{{ postgres.connections_active }}/20</div>
            <div class="metric-detail">Cache: {{ postgres.cache_hit_ratio }}%</div>
        </div>
    </div>

    <!-- Charts -->
    <canvas id="latencyChart"></canvas>

    <script>
        // Update Chart.js avec nouvelles donnÃ©es
        updateLatencyChart({{ chart_data | tojson }});
    </script>
</div>

<!-- Live Logs (SSE) -->
<div id="live-logs">
    <script>
        const evtSource = new EventSource('/api/monitoring/logs/stream');
        evtSource.onmessage = (event) => {
            const log = JSON.parse(event.data);
            appendLog(log);  // Ajoute log Ã  la liste
        };
    </script>
</div>
```

---

## ğŸ’¡ IdÃ©es SupplÃ©mentaires

### 1. Health Checks Auto

**Endpoint** : `/health/detailed`

```json
{
    "status": "healthy",
    "checks": {
        "postgres": {"status": "ok", "latency_ms": 2},
        "redis": {"status": "ok", "latency_ms": 1},
        "disk": {"status": "ok", "usage_percent": 45},
        "memory": {"status": "warning", "usage_percent": 85}
    }
}
```

**UI** : Badge vert/orange/rouge dans navbar

---

### 2. Request Tracing

**Ajouter Trace ID** :
```python
import uuid
from fastapi import Request

@app.middleware("http")
async def add_trace_id(request: Request, call_next):
    trace_id = str(uuid.uuid4())
    request.state.trace_id = trace_id

    # Log avec trace_id
    logger.bind(trace_id=trace_id).info("request_started")

    response = await call_next(request)
    response.headers["X-Trace-ID"] = trace_id
    return response
```

**Affichage** : Dans logs UI, cliquer sur trace_id affiche tous les logs liÃ©s

---

### 3. Comparaison Temporelle

**Feature** : Comparer metrics "maintenant" vs "hier" vs "semaine derniÃ¨re"

```
Latency P95
â”œâ”€ Now:       120ms
â”œâ”€ Yesterday: 115ms (+4.3%)
â””â”€ Last Week: 105ms (+14.3%)  âš ï¸ Trending up
```

---

### 4. Query Explain Automatique

**Feature** : Slow query dÃ©tectÃ©e â†’ EXPLAIN ANALYZE automatique â†’ stockÃ©

**UI** : Afficher plan d'exÃ©cution avec suggestions d'index

```sql
-- Query dÃ©tectÃ©e lente
SELECT * FROM code_chunks WHERE name LIKE '%validate%'

-- EXPLAIN montre: Seq Scan (slow)
-- Suggestion: CREATE INDEX idx_code_chunks_name_trgm
--             USING gin (name gin_trgm_ops)
```

---

### 5. Anomaly Detection Simple

**Feature** : DÃ©tection de patterns anormaux

```
ğŸš¨ Anomaly Detected!
â”œâ”€ Metric: api_latency_p95
â”œâ”€ Current: 450ms
â”œâ”€ Expected: 120ms (based on last 7 days)
â”œâ”€ Deviation: +275%
â””â”€ Suggestion: Check slow queries or cache hit rate
```

**Algorithme** : Simple moving average + 3Ïƒ (Ã©cart-type)

---

### 6. Export & Reporting

**Features** :
- Export CSV/JSON pour analyses externes
- PDF report quotidien/hebdomadaire
- Email digest (optionnel)

```python
@router.get("/monitoring/export")
async def export_metrics(format: str = "csv", period: str = "24h"):
    """Export mÃ©triques en CSV ou JSON."""
    metrics = await collector.collect_historical(period)

    if format == "csv":
        return generate_csv(metrics)
    else:
        return metrics
```

---

## âš ï¸ ConsidÃ©rations Importantes

### Performance

**Impact sur API** :
- Collection mÃ©triques : ~1-2ms overhead par request
- Insertion DB : async (non-bloquant)
- Agregation : faite en background (cron 1min)

**Optimisations** :
- Batch inserts (toutes les 10s)
- Indexes sur table `metrics`
- Retention policy (garder 30 jours max)

---

### SÃ©curitÃ©

**AccÃ¨s** :
- Dashboard monitoring = Admin only
- Authentication requise
- RBAC (role-based access control)

**Logs** :
- Ne jamais logger passwords/tokens
- Anonymiser donnÃ©es sensibles
- Filtrer PII (personally identifiable information)

---

### ScalabilitÃ©

**Single Instance** :
- Table `metrics` PostgreSQL OK
- Agregation en mÃ©moire OK

**Multi-Instance** :
- Besoin Prometheus/Grafana
- Shared Redis pour mÃ©triques
- Distributed tracing (Tempo)

---

## ğŸ“Š Estimation Points

| Story | Description | Points | PrioritÃ© |
|-------|-------------|--------|----------|
| 20.1 | Infrastructure mÃ©triques | 2 | ğŸŸ¢ MVP |
| 20.2 | Dashboard UI | 2 | ğŸŸ¢ MVP |
| 20.3 | Logs temps rÃ©el | 1 | ğŸŸ¢ MVP |
| 20.4 | Redis monitoring | 2 | ğŸŸ¡ Standard |
| 20.5 | PostgreSQL monitoring | 3 | ğŸŸ¡ Standard |
| 20.6 | API performance | 2 | ğŸŸ¡ Standard |
| 20.7 | Alerting | 1 | ğŸŸ¡ Standard |
| 20.8 | Export Prometheus | 2 | ğŸ”µ Nice |
| 20.9 | Distributed tracing | 3 | ğŸ”µ Nice |
| 20.10 | Predictive alerting | 2 | ğŸ”µ Nice |
| 20.11 | Reports | 1 | ğŸ”µ Nice |
| **TOTAL** | | **21 pts** | **~4 sprints** |

**MVP** : 5 pts (1 semaine)
**Standard** : +8 pts (2 semaines)
**Nice-to-Have** : +8 pts (2 semaines)

---

## ğŸ¯ Recommandation

### Phase 1: MVP (5 pts) - Ã€ FAIRE

**Objectif** : Avoir monitoring basique en production

**Features** :
1. Table metrics + API endpoints
2. Dashboard `/ui/monitoring/advanced`
3. Logs streaming temps rÃ©el

**Valeur** :
- âœ… VisibilitÃ© immÃ©diate sur production
- âœ… DÃ©tection rapide des problÃ¨mes
- âœ… Pas de dÃ©pendance externe
- âœ… KISS

**Timeline** : 1 semaine (5 jours)

---

### Phase 2: Standard (8 pts) - RECOMMANDÃ‰

**Objectif** : Monitoring production-grade

**Features** :
1. Redis monitoring dÃ©taillÃ©
2. PostgreSQL slow queries
3. API performance breakdown
4. Alerting simple

**Valeur** :
- âœ… Diagnostic approfondi
- âœ… Optimisations guidÃ©es par data
- âœ… Alertes proactives

**Timeline** : 2 semaines

---

### Phase 3: Nice-to-Have (8 pts) - YAGNI

**Uniquement si** :
- Multi-instance deployment
- Ã‰quipe DevOps dÃ©diÃ©e
- Besoin traces distribuÃ©es

**Sinon** : â¸ï¸ Reporter

---

## ğŸ”— RÃ©fÃ©rences

- **PostgreSQL stats** : https://www.postgresql.org/docs/current/monitoring-stats.html
- **Redis INFO** : https://redis.io/commands/info/
- **Chart.js** : https://www.chartjs.org/
- **SSE** : https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events
- **Prometheus** : https://prometheus.io/

---

**CrÃ©Ã©** : 2025-10-23
**Auteur** : Brainstorming session
**Status** : ğŸ§  Ã€ valider par Ã©quipe
**Next** : CrÃ©er EPIC-20_README.md avec plan d'action
