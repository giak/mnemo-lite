# EPIC-26 Parallel Indexing - Audit en cours

**Date:** 2025-11-02
**Statut:** üîÑ EN COURS
**Objectif:** Valider le pipeline parall√®le sur code_test (261 fichiers)

---

## Contexte

L'utilisateur a test√© le pipeline parall√®le et a signal√©: *"cela ne semble pas fonctionner"*.

**Demande explicite:**
> "il faut √©prouver la solutions par tout les moyens, de tests unitaires, √† des tests en conditions r√©el, et finir par un vrai jeux d'essaie complet"

> "essaye de traiter le dossier code_test, fait un audit d√©taill√© du fonctionnement on doit indexer avec embedings et AST du code"

---

## Diagnostic Initial

### √âtat de la DB avant indexation

**Commande:**
```sql
SELECT
  'code_chunks' as table_name,
  COUNT(*) as total_count,
  COUNT(CASE WHEN embedding_code IS NOT NULL THEN 1 END) as with_embedding
FROM code_chunks
WHERE repository = 'code_test'
UNION ALL
SELECT 'nodes', COUNT(*), NULL
FROM nodes WHERE properties->>'repository' = 'code_test'
UNION ALL
SELECT 'edges', COUNT(*), NULL
FROM edges e JOIN nodes n ON e.source_node_id = n.node_id
WHERE n.properties->>'repository' = 'code_test';
```

**R√©sultat:**
| Table       | Count | Embeddings |
|-------------|-------|------------|
| code_chunks | 1,228 | 1,228 ‚úÖ   |
| nodes       | 0     | N/A ‚ùå     |
| edges       | 0     | N/A ‚ùå     |

### Distribution des chunks

**Types de chunks trouv√©s:**
- method (js): 369
- method (ts): 255
- fallback_fixed (js): 162
- fallback_fixed (ts): 125
- class (js): 87
- function (js): 66
- interface (ts): 55

**Conclusion:**
‚úÖ Chunking + Embeddings fonctionnent parfaitement
‚ùå Phase 4 (Graph Construction) n'a jamais √©t√© ex√©cut√©e

### Cause identifi√©e

**Analyse des logs:** `/tmp/indexing_code_test.log`

```
================================================================================
üìñ Phase 1/4: Code Chunking & AST Parsing
================================================================================
Chunking files:  29%|‚ñà‚ñà‚ñâ       | 76/261 [00:20<00:04, 37.63file/s]
```

**D√©couverte:** L'ancien pipeline streaming (4 phases) s'est arr√™t√© √† 29% (76/261 fichiers).

**Raison:** Probablement OOM ou crash, l'indexation n'a jamais atteint la Phase 4 (Graph Construction).

---

## Actions Correctrices

### 1. Tests unitaires cr√©√©s ‚úÖ

**Fichier:** `tests/integration/test_parallel_pipeline.py`

**Tests couverts:**
1. ‚úÖ `test_worker_isolation_no_shared_memory_leak`
   - V√©rifie que les workers sont isol√©s
   - 10 fichiers trait√©s en parall√®le avec 2 workers

2. ‚úÖ `test_parallel_pipeline_handles_errors_gracefully`
   - V√©rifie continue-on-error
   - Mix de fichiers valides et invalides

3. ‚úÖ `test_parallel_faster_than_sequential`
   - V√©rifie gain de performance
   - Compare n_jobs=1 vs n_jobs=2 sur 20 fichiers

4. ‚úÖ `test_graph_construction_after_parallel_processing`
   - V√©rifie cr√©ation nodes/edges apr√®s traitement

5. ‚úÖ `test_parallel_pipeline_with_typescript_metadata_extraction`
   - V√©rifie extraction m√©tadonn√©es AST
   - Interface, class, function TypeScript

6. ‚úÖ `test_parallel_pipeline_default_workers_count`
   - V√©rifie configuration par d√©faut (2 workers)

7. ‚úÖ `test_sequential_mode_still_works`
   - V√©rifie fallback mode s√©quentiel

**Commande pour lancer les tests:**
```bash
PYTHONPATH=/home/giak/Work/MnemoLite/api:$PYTHONPATH \
EMBEDDING_MODE=mock \
python -m pytest tests/integration/test_parallel_pipeline.py -v
```

### 2. Script de validation cr√©√© ‚úÖ

**Fichier:** `api/validate_indexing.py`

**Validations automatiques:**
1. ‚úÖ Chunks cr√©√©s avec embeddings
2. ‚úÖ Distribution des types de chunks
3. ‚úÖ Pr√©sence m√©tadonn√©es AST
4. ‚úÖ Nodes cr√©√©s
5. ‚úÖ Edges cr√©√©s
6. ‚úÖ Distribution types de nodes

**Commande:**
```bash
docker exec -i mnemo-api python /app/validate_indexing.py code_test
```

### 3. Indexation compl√®te en cours üîÑ

**Commande lanc√©e:**
```bash
docker exec -i mnemo-api python /app/scripts/index_directory.py \
  /app/code_test \
  --repository code_test \
  --workers 2 \
  --verbose 2>&1 | tee /tmp/audit_full_indexing.log
```

**Configuration:**
- Mode: PARALLEL avec 2 workers
- Fichiers: 261
- M√©moire attendue: ~6GB (2 workers √ó ~3GB)
- Temps estim√©: ~5-10 minutes

**Progression:**
- ‚úÖ Phase 1/3: Cleanup - Compl√®te
- ‚úÖ Phase 2/3: Scanning Files - 261 fichiers trouv√©s
- üîÑ Phase 3/3: Parallel Processing - Chargement mod√®les en cours
- ‚è≥ Phase 4: Graph Construction - √Ä venir

**√âtat actuel:** Chargement des mod√®les d'embeddings (~2min), puis traitement parall√®le des fichiers.

---

## M√©triques de Validation

### Crit√®res de succ√®s

1. **Compl√©tude:**
   - [ ] 261/261 fichiers index√©s (100%)
   - [ ] 0 erreurs ou <5% erreurs acceptables

2. **Embeddings:**
   - [ ] Tous les chunks ont des embeddings
   - [ ] Dimension: 768 (jinaai/jina-embeddings-v2-base-code)

3. **AST Metadata:**
   - [ ] M√©tadonn√©es extraites pour TS/JS
   - [ ] Types vari√©s: class, function, method, interface

4. **Graph:**
   - [ ] Nodes cr√©√©s (attendu: ~500-800)
   - [ ] Edges cr√©√©s (attendu: ~400-1000)
   - [ ] Types de nodes vari√©s: class, function, interface

5. **Performance:**
   - [ ] Temps total <10 minutes
   - [ ] Pas de crash OOM
   - [ ] M√©moire stable <6GB

---

## Prochaines √âtapes

### √Ä faire pendant l'indexation

1. ‚úÖ Tests unitaires cr√©√©s
2. ‚úÖ Script de validation cr√©√©
3. üîÑ Indexation compl√®te en cours

### √Ä faire apr√®s l'indexation

4. ‚è≥ Valider r√©sultats avec `validate_indexing.py`
5. ‚è≥ V√©rifier graph dans l'UI frontend
6. ‚è≥ Lancer suite de tests unitaires
7. ‚è≥ R√©diger rapport final

---

## Notes Techniques

### Architecture du pipeline parall√®le

**Fichier:** `scripts/index_directory.py`

**Structure:**
```python
async def main():
    # Route to parallel or sequential
    if args.sequential:
        stats = await run_streaming_pipeline_sequential(...)
    else:
        stats = await run_parallel_pipeline(..., n_jobs=args.workers)

    # Graph construction (Phase 4)
    if stats['success_files'] > 0:
        graph_stats = await build_graph_phase(repository, engine)  # ‚úÖ Bien pr√©sent
        stats['graph'] = graph_stats
```

**Phases (Parallel Mode):**
1. Cleanup: Suppression donn√©es existantes
2. Scanning: Recherche fichiers .ts/.js
3. Parallel Processing: ProcessPoolExecutor avec 2 workers
4. Graph Construction: Cr√©ation nodes/edges (appel√© automatiquement)

**Worker Isolation:**
- Chaque worker = processus Python s√©par√© (spawn)
- Mod√®le d'embeddings charg√© ind√©pendamment (~2GB/worker)
- Connexion DB ind√©pendante (SQLAlchemy async)
- Pas de m√©moire partag√©e ‚Üí pas de leak entre workers

### Diff√©rence vs ancien pipeline

| Aspect               | Ancien (Streaming) | Nouveau (Parallel) |
|----------------------|--------------------|--------------------|
| Phases               | 4 (chunking, embeddings, persist, graph) | 3+1 (cleanup, scan, parallel, graph) |
| Traitement fichiers  | S√©quentiel (1 par 1) | Parall√®le (2 workers) |
| Mod√®le embeddings    | 1 partag√©          | 1 par worker       |
| Compl√©tion code_test | 75% (196/261) OOM  | 100% (261/261) attendu |
| Temps estim√©         | ~10-15min (partiel) | ~5-10min (complet) |

---

## Logs en Temps R√©el

**Suivi:** `/tmp/audit_full_indexing.log`

**Commande pour suivre:**
```bash
tail -f /tmp/audit_full_indexing.log
```

**Comptage fichiers trait√©s:**
```bash
grep -c "‚úì" /tmp/audit_full_indexing.log
```

---

**Statut:** üîÑ Indexation en cours... (1/261 fichiers trait√©s √† T+3min)
