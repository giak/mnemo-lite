# EPIC-22: Advanced Observability & Real-Time Monitoring

**Date de cr√©ation**: 2025-10-24
**Status**: üü° **PHASE 2 IN PROGRESS** (Story 22.5 ‚úÖ | 22.6 ‚úÖ | 22.7 ‚è≥)
**Priorit√©**: P1 (Production-Critical)
**Points totaux**: 19 pts (Phase 1: 5 pts ‚úÖ | Phase 2: 6 pts üü° | Phase 3: 8 pts ‚è∏Ô∏è)
**Progress**: 10/19 pts = **53% Complete**

---

## üìä Vision

**"En 30 secondes, l'admin peut diagnostiquer n'importe quel probl√®me production depuis l'UI"**

Production-ready observability int√©gr√©e nativement dans MnemoLite, **sans d√©pendances externes** (pas de Prometheus/Grafana/ELK).

---

## üéØ Objectifs

### Probl√®mes R√©solus
1. ‚ùå **Avant**: Monitoring dispers√© entre `/ui/monitoring` (events), `/performance/*` (API), `/v1/cache/*` (cache)
2. ‚ùå **Avant**: Pas de visibilit√© Redis d√©taill√©e (memory, hit rate par type, evictions)
3. ‚ùå **Avant**: Pas de latency par endpoint (impossible de trouver les endpoints lents)
4. ‚ùå **Avant**: Pas de logs streaming temps r√©el (besoin SSH + docker logs)
5. ‚ùå **Avant**: R√©actif au lieu de proactif (pas d'alerting)

### Solutions Apport√©es (Phase 1 ‚úÖ)
1. ‚úÖ **Dashboard unifi√©** `/ui/monitoring/advanced` ‚Üí Tout sur 1 page
2. ‚úÖ **M√©triques persist√©es** ‚Üí Table PostgreSQL `metrics` avec historique
3. ‚úÖ **Logs streaming** ‚Üí SSE temps r√©el avec filtres
4. ‚úÖ **KPIs temps r√©el** ‚Üí API latency, Redis hit rate, PostgreSQL connections, System resources
5. ‚úÖ **Request tracing** ‚Üí trace_id (UUID) dans headers et logs

---

## üèóÔ∏è Architecture

### Stack (Zero Nouvelle D√©pendance)
```
‚úÖ Backend: FastAPI (already present)
‚úÖ DB: PostgreSQL 18 (already present)
‚úÖ UI: HTMX + Jinja2 (already present)
‚úÖ Charts: ECharts 5.5.0 (local assets)
‚úÖ Logs: structlog (already present)
‚úÖ Cache: Redis (already present)
‚úÖ New: Server-Sent Events (SSE) - Native browser API
```

### Syst√®me
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ UI: /ui/monitoring/advanced                                     ‚îÇ
‚îÇ ‚îú‚îÄ 4+ KPI Cards (API, Redis, PostgreSQL, System)               ‚îÇ
‚îÇ ‚îú‚îÄ 4 Charts (Latency, Redis Memory, PG Connections, Resources) ‚îÇ
‚îÇ ‚îú‚îÄ Metrics Table (d√©tails)                                     ‚îÇ
‚îÇ ‚îî‚îÄ Logs Stream (SSE real-time)                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì HTMX polling (10s) + SSE
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FastAPI Backend                                                 ‚îÇ
‚îÇ ‚îú‚îÄ MetricsMiddleware (record latency + trace_id)               ‚îÇ
‚îÇ ‚îú‚îÄ MetricsCollector (aggregate from PostgreSQL + Redis INFO)   ‚îÇ
‚îÇ ‚îî‚îÄ LogsBuffer (circular buffer for SSE streaming)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚Üì                    ‚Üì                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PostgreSQL       ‚îÇ  ‚îÇ Redis            ‚îÇ  ‚îÇ structlog        ‚îÇ
‚îÇ Table: metrics   ‚îÇ  ‚îÇ INFO commands    ‚îÇ  ‚îÇ Logs buffer      ‚îÇ
‚îÇ - Latency/req    ‚îÇ  ‚îÇ - Memory stats   ‚îÇ  ‚îÇ - Circular       ‚îÇ
‚îÇ - Indexed        ‚îÇ  ‚îÇ - Hit/miss       ‚îÇ  ‚îÇ - Max 1000 logs  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìù Stories & Status

### üü¢ Phase 1: MVP (5 pts) - ‚úÖ **COMPLETED**

#### ‚úÖ Story 22.1: Metrics Infrastructure (2 pts)
**Status**: ‚úÖ Completed (2025-10-24)
**Files**:
- `db/migrations/v5_to_v6_metrics_table.sql` (migration)
- `api/services/metrics_collector.py` (service layer)
- `api/middleware/metrics_middleware.py` (auto-recording)
- `api/routes/monitoring_routes_advanced.py` (endpoints)

**Deliverables**:
- [x] Table `metrics` cr√©√©e avec indexes optimis√©s
- [x] 158+ m√©triques API d√©j√† collect√©es
- [x] MetricsMiddleware record latency automatiquement
- [x] trace_id (UUID) inject√© dans headers et logs
- [x] Endpoint `/api/monitoring/advanced/summary` fonctionnel

**Voir**: `EPIC-22_STORY_22.1_COMPLETION_REPORT.md`

---

#### ‚úÖ Story 22.2: Dashboard Unifi√© UI (2 pts)
**Status**: ‚úÖ Completed (2025-10-24)
**Files**:
- `templates/monitoring_advanced.html` (dashboard UI)
- `static/vendor/echarts.min.js` (local assets)
- `static/vendor/prism*.js` (local assets)

**Deliverables**:
- [x] Page `/ui/monitoring/advanced` accessible
- [x] 6 KPI cards (API P95, Redis hit rate, PG cache, CPU, Memory, RPS)
- [x] 4 ECharts (Latency, Redis Memory, PG Connections, System Resources)
- [x] Auto-refresh HTMX (10s interval)
- [x] SCADA theme coh√©rent (GitHub dark)
- [x] Metrics table d√©taill√©e avec status colors

**Voir**: `EPIC-22_STORY_22.2_COMPLETION_REPORT.md`

---

#### ‚úÖ Story 22.3: Logs Streaming Temps R√©el (1 pt)
**Status**: ‚úÖ Completed (2025-10-24)
**Files**:
- `api/services/logs_buffer.py` (circular buffer)
- `api/routes/monitoring_routes_advanced.py` (SSE endpoint)
- `templates/monitoring_advanced.html` (EventSource client)

**Deliverables**:
- [x] SSE endpoint `/api/monitoring/advanced/logs/stream` actif
- [x] LogsBuffer (circular, max 1000 logs, ~1MB)
- [x] Logs affich√©s temps r√©el avec colorisation
- [x] Auto-scroll et filtres (level, search)
- [x] Int√©gration structlog ‚Üí buffer ‚Üí SSE

**Voir**: `EPIC-22_STORY_22.3_COMPLETION_REPORT.md`

---

**Phase 1 Summary**: `EPIC-22_PHASE_1_COMPLETION_REPORT.md`

---

### üü° Phase 2: Standard (6 pts) - üü° **IN PROGRESS** (5/6 pts = 83%)

#### ‚è∏Ô∏è Story 22.4: Redis Monitoring D√©taill√© (2 pts) - **SKIPPED**
**Status**: ‚è∏Ô∏è Skipped (YAGNI - deferred to Phase 3)
**Raison**: Cache vide actuellement (0 keys), pas de probl√®me identifi√©. Manual diagnosis suffisant.
**Trigger pour r√©activation**: Redis keys > 5000 OU (hit_rate < 70% ET memory > 80%)
**Objectif**: Breakdown Redis par cache type

**Features**:
- Hit rate par type (search_results, embeddings, graph_traversal)
- Memory usage d√©taill√©
- Keys count par prefix
- Evictions timeline
- Top keys (SCAN)

**Acceptance**:
- [ ] Endpoint `/api/monitoring/redis/detailed`
- [ ] UI: Cards breakdown par cache type
- [ ] Gauge memory avec alertes

---

#### ‚úÖ Story 22.5: API Performance Par Endpoint (3 pts)
**Status**: ‚úÖ Completed (2025-10-24)
**Objectif**: Latency breakdown par endpoint
**Dur√©e**: 3.25h (estim√©: 4.5h) ‚ö° **28% plus rapide**

**Features Delivered**:
- ‚úÖ Service `EndpointPerformanceService` (3 methods: stats, slow endpoints, error hotspots)
- ‚úÖ 3 REST API endpoints (`/performance/endpoints`, `/performance/slow-endpoints`, `/performance/error-hotspots`)
- ‚úÖ Endpoint normalization (UUIDs ‚Üí :uuid, IDs ‚Üí :id, hashes ‚Üí :hash)
- ‚úÖ UI Table: 20 endpoints avec P50/P95/P99, error rate, RPS
- ‚úÖ UI Panel: "Slow Endpoints" avec impact calculation (time wasted/hour)
- ‚úÖ Color-coding dynamique (latency + error rate)
- ‚úÖ S√©lecteur p√©riode (1h/24h/7d)
- ‚úÖ Auto-refresh 10s int√©gr√©

**Acceptance**:
- [x] Agr√©gation depuis `metrics` table (PERCENTILE_CONT)
- [x] UI: Table triable (endpoint, method, latency, errors)
- [x] Endpoint normalization middleware
- [x] Slow endpoints panel avec impact calculation
- [x] Query performance < 50ms ‚úÖ
- [x] 250+ m√©triques analys√©es

**Files**:
- `api/services/endpoint_performance_service.py` (NEW, 313 LOC)
- `api/routes/monitoring_routes_advanced.py` (+142 LOC)
- `api/middleware/metrics_middleware.py` (+48 LOC)
- `api/dependencies.py` (+28 LOC)
- `templates/monitoring_advanced.html` (+273 LOC)

**Voir**: `EPIC-22_STORY_22.5_COMPLETION_REPORT.md`

---

#### ‚úÖ Story 22.6: Request Tracing (2 pts)
**Status**: ‚úÖ Completed (2025-10-24)
**Objectif**: trace_id end-to-end cliquable
**Dur√©e**: 2h (design + implementation + testing + documentation)

**Features Delivered**:
- ‚úÖ contextvars-based trace_id propagation (zero boilerplate)
- ‚úÖ Clickable trace_id badges in logs UI (üîç a1b2c3d4)
- ‚úÖ Filter by trace_id with live match indicator
- ‚úÖ X-Trace-ID header in all responses
- ‚úÖ LogsBuffer integration with trace_id in metadata
- ‚úÖ YAGNI: Timeline visualization deferred (single service, no distributed tracing need)

**Acceptance**:
- [x] Tous logs ont trace_id (via structlog processor)
- [x] UI: trace_id cliquable dans logs stream
- [x] Filter input + clear button + match count
- [x] Auto-filter new logs when filter active

**Files**:
- `api/utils/logging_config.py` (NEW, 95 LOC)
- `api/main.py` (+3 LOC - configure_logging call)
- `api/middleware/metrics_middleware.py` (+3 LOC - contextvars.set)
- `templates/monitoring_advanced.html` (+172 LOC - UI badges & filter)

**Voir**: `EPIC-22_STORY_22.6_COMPLETION_REPORT.md`

---

#### ‚è≥ Story 22.7: Smart Alerting (1 pt)
**Status**: ‚è≥ Not Started
**Objectif**: Alertes automatiques seuils

**Features**:
- Service AlertingService (check thresholds)
- Table `alerts` (id, type, severity, message, ack)
- Endpoint `/api/monitoring/alerts`
- UI: Badge navbar (count alerts)
- Modal alerts avec acknowledge

**Seuils**:
- Cache hit rate < 70% ‚Üí Warning
- Memory > 80% ‚Üí Critical
- Slow queries > 1s ‚Üí Warning
- Evictions > 100/h ‚Üí Info
- Error rate > 5% ‚Üí Critical

**Acceptance**:
- [ ] Alertes cr√©√©es automatiquement (background task 1min)
- [ ] UI badge + modal
- [ ] Acknowledge ‚Üí archivage

---

### üîµ Phase 3: Nice-to-Have (8 pts) - ‚è∏Ô∏è **YAGNI**

Stories 22.8-22.12:
- Historical Trends (comparaison temporelle)
- Slow Query Explain Auto
- Export & Reporting (CSV/JSON)
- Prometheus Export (optionnel)
- Anomaly Detection (ML simple)

**D√©cision**: Reporter apr√®s Phase 2 valid√©e

---

## üìä M√©triques Cl√©s (√âtat Actuel)

D'apr√®s `/api/monitoring/advanced/summary` (2025-10-24):

**API**:
- P95 Latency: 108.96ms
- P99 Latency: 115.33ms
- Request count: 158 (derni√®re 1h)
- Throughput: 0.04 req/s
- Error rate: 5.7% (9 errors)

**Redis**:
- Connected: ‚úÖ Yes
- Memory: 1.05 MB / 2048 MB (0.05%)
- Hit rate: 0% (cache vide actuellement)
- Keys: 0
- Evicted: 0

**PostgreSQL**:
- Connections: 6 / 100 (1 active, 5 idle)
- Cache hit ratio: 95.36% ‚úÖ
- DB size: 26.11 MB
- Slow queries (>100ms): 58

**System**:
- CPU: 15% (16 cores)
- Memory: 73.4% (38.7 GB / 58 GB)
- Disk: 81.8% (728 GB / 937 GB)

---

## üé® UI Design (SCADA Theme)

Dashboard `/ui/monitoring/advanced`:
- **Status Banner**: üü¢ Operational | Auto-refresh toggle
- **KPI Grid**: 6 cards (API, Redis, PostgreSQL, CPU, Memory, RPS)
- **Charts Grid**: 4 ECharts (Latency, Redis Memory, PG Connections, Resources)
- **Metrics Table**: Detailed breakdown avec status colors
- **Logs Stream**: SSE real-time avec filtres

**Theme**: GitHub Dark + SCADA Industrial (zero rounded corners, monospace fonts, cyan/green accents)

---

## üîó Fichiers Cl√©s

### Backend
```
api/
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îî‚îÄ‚îÄ metrics_middleware.py          # Auto-record latency + trace_id
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ monitoring_routes_advanced.py  # /api/monitoring/advanced/*
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ metrics_collector.py           # Collect from PostgreSQL/Redis/System
‚îÇ   ‚îî‚îÄ‚îÄ logs_buffer.py                 # Circular buffer for SSE
db/migrations/
‚îî‚îÄ‚îÄ v5_to_v6_metrics_table.sql         # CREATE TABLE metrics
```

### Frontend
```
templates/
‚îî‚îÄ‚îÄ monitoring_advanced.html            # Dashboard UI
static/vendor/
‚îú‚îÄ‚îÄ echarts.min.js                      # Charts (local)
‚îú‚îÄ‚îÄ prism*.js                           # Syntax highlighting (local)
‚îî‚îÄ‚îÄ prism-okaidia.min.css               # Prism theme (local)
```

---

## ‚ö†Ô∏è Consid√©rations Techniques

### Performance Impact
- **MetricsMiddleware overhead**: ~1-2ms par request (async INSERT)
- **Batch inserts** possible si volume √©lev√© (100 metrics/batch)
- **Retention**: 30 jours (cleanup cron job)

### Scalabilit√©
- **Single instance** (actuel): ‚úÖ Table `metrics` PostgreSQL suffisante
- **Multi-instance** (futur): ‚è∏Ô∏è Besoin Prometheus + shared Redis

### S√©curit√©
- `/ui/monitoring/advanced` = Admin only (TODO: add auth check)
- API endpoints prot√©g√©s
- Logs: Ne jamais logger passwords/tokens

---

## üß™ Tests

**Unit Tests**:
- `tests/test_metrics_collector.py`
- `tests/test_metrics_middleware.py`

**Integration Tests**:
- `tests/integration/test_monitoring_advanced_ui.py`
- `tests/integration/test_sse_streaming.py`

**Coverage**:
- MetricsCollector: ‚úÖ Tested
- MetricsMiddleware: ‚úÖ Tested
- SSE endpoint: ‚úÖ Tested
- UI: ‚è≥ Manual testing only

---

## üìà Timeline & Effort

| Phase | Stories | Points | Dur√©e Estim√©e | Dur√©e R√©elle | Status |
|-------|---------|--------|---------------|--------------|--------|
| Phase 1: MVP | 22.1-22.3 | 5 pts | 5 jours | 3 jours ‚ö° | ‚úÖ Done |
| Phase 2: Standard | 22.5-22.7 | 6 pts | 4 jours | 0.5 jour (partial) | üü° In Progress (50%) |
| Phase 3: Nice-to-Have | 22.4, 22.8-22.12 | 8 pts | 6 jours | - | ‚è∏Ô∏è YAGNI |
| **Total** | 11 stories | **19 pts** | **15 jours** | **3.5 jours** | **42% done** |

**Notes**:
- Story 22.4 (Redis breakdown) deferred to Phase 3 (YAGNI - no current need)
- Phase 1 delivered 40% faster than estimated (3 days vs 5 days)
- Phase 2 Story 22.5 delivered 28% faster (3.25h vs 4.5h)

**Velocity**: 8 pts / 3.5 days = **2.29 pts/day** (excellent)

---

## üéØ Prochaines √âtapes

### Imm√©diat (Phase 2)
1. **Story 22.4**: Redis breakdown par cache type
2. **Story 22.5**: API performance par endpoint (P95 heatmap)
3. **Story 22.6**: Request tracing cliquable
4. **Story 22.7**: Smart alerting

### Nice-to-Have (Phase 3)
- Attendre validation Phase 2
- √âvaluer besoin r√©el (YAGNI test)

---

## üìö Documentation

- **Design**: `EPIC-22_OBSERVABILITY_ULTRATHINK.md`
- **Implementation**: `EPIC-22_PHASE_1_IMPLEMENTATION_ULTRATHINK.md`
- **Phase 1 Summary**: `EPIC-22_PHASE_1_COMPLETION_REPORT.md`
- **Phase 1 Story Reports**:
  - `EPIC-22_STORY_22.1_COMPLETION_REPORT.md` (Metrics Infrastructure)
  - `EPIC-22_STORY_22.2_COMPLETION_REPORT.md` (Dashboard UI)
  - `EPIC-22_STORY_22.3_COMPLETION_REPORT.md` (Logs Streaming)
- **Phase 2 Story Reports**:
  - `EPIC-22_STORY_22.4_ULTRATHINK.md` (Redis Monitoring - SKIPPED)
  - `EPIC-22_STORY_22.5_ULTRATHINK.md` (API Performance - Design)
  - `EPIC-22_STORY_22.5_COMPLETION_REPORT.md` (API Performance - Completed ‚úÖ)

---

## ‚úÖ Acceptance Criteria (Phase 1)

### Global
- [x] Dashboard `/ui/monitoring/advanced` accessible et fonctionnel
- [x] M√©triques temps r√©el (auto-refresh 10s)
- [x] Logs streaming SSE connect√©
- [x] Zero d√©pendances externes (pas de Prometheus/Grafana)
- [x] SCADA theme coh√©rent
- [x] Assets locaux (echarts, prism)

### M√©triques
- [x] Table `metrics` cr√©√©e avec indexes
- [x] API latency enregistr√©e automatiquement
- [x] trace_id dans tous headers/logs
- [x] Agr√©gation P50/P95/P99 fonctionnelle
- [x] Redis/PostgreSQL/System metrics collect√©s

### UI/UX
- [x] KPI cards affichent valeurs r√©elles
- [x] Charts ECharts initialis√©s et mis √† jour
- [x] Logs stream affiche logs temps r√©el
- [x] Filtres logs fonctionnels
- [x] Auto-scroll activable

---

**Cr√©√©**: 2025-10-24
**Derni√®re mise √† jour**: 2025-10-24
**Auteur**: Claude Code + User
**Status**: Phase 1 ‚úÖ Complete | Phase 2 ‚è≥ Pending
**Version**: 1.0.0
