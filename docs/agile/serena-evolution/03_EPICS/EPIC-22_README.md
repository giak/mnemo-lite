# EPIC-22: Advanced Observability & Real-Time Monitoring

**Date de crÃ©ation**: 2025-10-24
**Status**: ğŸŸ¡ **PHASE 2 IN PROGRESS** (Story 22.5 âœ… | 22.6 âœ… | 22.7 â³)
**PrioritÃ©**: P1 (Production-Critical)
**Points totaux**: 19 pts (Phase 1: 5 pts âœ… | Phase 2: 6 pts ğŸŸ¡ | Phase 3: 8 pts â¸ï¸)
**Progress**: 10/19 pts = **53% Complete**

---

## ğŸ“Š Vision

**"En 30 secondes, l'admin peut diagnostiquer n'importe quel problÃ¨me production depuis l'UI"**

Production-ready observability intÃ©grÃ©e nativement dans MnemoLite, **sans dÃ©pendances externes** (pas de Prometheus/Grafana/ELK).

---

## ğŸ¯ Objectifs

### ProblÃ¨mes RÃ©solus
1. âŒ **Avant**: Monitoring dispersÃ© entre `/ui/monitoring` (events), `/performance/*` (API), `/v1/cache/*` (cache)
2. âŒ **Avant**: Pas de visibilitÃ© Redis dÃ©taillÃ©e (memory, hit rate par type, evictions)
3. âŒ **Avant**: Pas de latency par endpoint (impossible de trouver les endpoints lents)
4. âŒ **Avant**: Pas de logs streaming temps rÃ©el (besoin SSH + docker logs)
5. âŒ **Avant**: RÃ©actif au lieu de proactif (pas d'alerting)

### Solutions ApportÃ©es (Phase 1 âœ…)
1. âœ… **Dashboard unifiÃ©** `/ui/monitoring/advanced` â†’ Tout sur 1 page
2. âœ… **MÃ©triques persistÃ©es** â†’ Table PostgreSQL `metrics` avec historique
3. âœ… **Logs streaming** â†’ SSE temps rÃ©el avec filtres
4. âœ… **KPIs temps rÃ©el** â†’ API latency, Redis hit rate, PostgreSQL connections, System resources
5. âœ… **Request tracing** â†’ trace_id (UUID) dans headers et logs

---

## ğŸ—ï¸ Architecture

### Stack (Zero Nouvelle DÃ©pendance)
```
âœ… Backend: FastAPI (already present)
âœ… DB: PostgreSQL 18 (already present)
âœ… UI: HTMX + Jinja2 (already present)
âœ… Charts: ECharts 5.5.0 (local assets)
âœ… Logs: structlog (already present)
âœ… Cache: Redis (already present)
âœ… New: Server-Sent Events (SSE) - Native browser API
```

### SystÃ¨me
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI: /ui/monitoring/advanced                                     â”‚
â”‚ â”œâ”€ 4+ KPI Cards (API, Redis, PostgreSQL, System)               â”‚
â”‚ â”œâ”€ 4 Charts (Latency, Redis Memory, PG Connections, Resources) â”‚
â”‚ â”œâ”€ Metrics Table (dÃ©tails)                                     â”‚
â”‚ â””â”€ Logs Stream (SSE real-time)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“ HTMX polling (10s) + SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI Backend                                                 â”‚
â”‚ â”œâ”€ MetricsMiddleware (record latency + trace_id)               â”‚
â”‚ â”œâ”€ MetricsCollector (aggregate from PostgreSQL + Redis INFO)   â”‚
â”‚ â””â”€ LogsBuffer (circular buffer for SSE streaming)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“                    â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL       â”‚  â”‚ Redis            â”‚  â”‚ structlog        â”‚
â”‚ Table: metrics   â”‚  â”‚ INFO commands    â”‚  â”‚ Logs buffer      â”‚
â”‚ - Latency/req    â”‚  â”‚ - Memory stats   â”‚  â”‚ - Circular       â”‚
â”‚ - Indexed        â”‚  â”‚ - Hit/miss       â”‚  â”‚ - Max 1000 logs  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Stories & Status

### ğŸŸ¢ Phase 1: MVP (5 pts) - âœ… **COMPLETED**

#### âœ… Story 22.1: Metrics Infrastructure (2 pts)
**Status**: âœ… Completed (2025-10-24)
**Files**:
- `db/migrations/v5_to_v6_metrics_table.sql` (migration)
- `api/services/metrics_collector.py` (service layer)
- `api/middleware/metrics_middleware.py` (auto-recording)
- `api/routes/monitoring_routes_advanced.py` (endpoints)

**Deliverables**:
- [x] Table `metrics` crÃ©Ã©e avec indexes optimisÃ©s
- [x] 158+ mÃ©triques API dÃ©jÃ  collectÃ©es
- [x] MetricsMiddleware record latency automatiquement
- [x] trace_id (UUID) injectÃ© dans headers et logs
- [x] Endpoint `/api/monitoring/advanced/summary` fonctionnel

**Voir**: `EPIC-22_STORY_22.1_COMPLETION_REPORT.md`

---

#### âœ… Story 22.2: Dashboard UnifiÃ© UI (2 pts)
**Status**: âœ… Completed (2025-10-24)
**Files**:
- `templates/monitoring_advanced.html` (dashboard UI)
- `static/vendor/echarts.min.js` (local assets)
- `static/vendor/prism*.js` (local assets)

**Deliverables**:
- [x] Page `/ui/monitoring/advanced` accessible
- [x] 6 KPI cards (API P95, Redis hit rate, PG cache, CPU, Memory, RPS)
- [x] 4 ECharts (Latency, Redis Memory, PG Connections, System Resources)
- [x] Auto-refresh HTMX (10s interval)
- [x] SCADA theme cohÃ©rent (GitHub dark)
- [x] Metrics table dÃ©taillÃ©e avec status colors

**Voir**: `EPIC-22_STORY_22.2_COMPLETION_REPORT.md`

---

#### âœ… Story 22.3: Logs Streaming Temps RÃ©el (1 pt)
**Status**: âœ… Completed (2025-10-24)
**Files**:
- `api/services/logs_buffer.py` (circular buffer)
- `api/routes/monitoring_routes_advanced.py` (SSE endpoint)
- `templates/monitoring_advanced.html` (EventSource client)

**Deliverables**:
- [x] SSE endpoint `/api/monitoring/advanced/logs/stream` actif
- [x] LogsBuffer (circular, max 1000 logs, ~1MB)
- [x] Logs affichÃ©s temps rÃ©el avec colorisation
- [x] Auto-scroll et filtres (level, search)
- [x] IntÃ©gration structlog â†’ buffer â†’ SSE

**Voir**: `EPIC-22_STORY_22.3_COMPLETION_REPORT.md`

---

**Phase 1 Summary**: `EPIC-22_PHASE_1_COMPLETION_REPORT.md`

---

### ğŸŸ¡ Phase 2: Standard (6 pts) - ğŸŸ¡ **IN PROGRESS** (5/6 pts = 83%)

#### â¸ï¸ Story 22.4: Redis Monitoring DÃ©taillÃ© (2 pts) - **SKIPPED**
**Status**: â¸ï¸ Skipped (YAGNI - deferred to Phase 3)
**Raison**: Cache vide actuellement (0 keys), pas de problÃ¨me identifiÃ©. Manual diagnosis suffisant.
**Trigger pour rÃ©activation**: Redis keys > 5000 OU (hit_rate < 70% ET memory > 80%)
**Objectif**: Breakdown Redis par cache type

**Features**:
- Hit rate par type (search_results, embeddings, graph_traversal)
- Memory usage dÃ©taillÃ©
- Keys count par prefix
- Evictions timeline
- Top keys (SCAN)

**Acceptance**:
- [ ] Endpoint `/api/monitoring/redis/detailed`
- [ ] UI: Cards breakdown par cache type
- [ ] Gauge memory avec alertes

---

#### âœ… Story 22.5: API Performance Par Endpoint (3 pts)
**Status**: âœ… Completed (2025-10-24)
**Objectif**: Latency breakdown par endpoint
**DurÃ©e**: 3.25h (estimÃ©: 4.5h) âš¡ **28% plus rapide**

**Features Delivered**:
- âœ… Service `EndpointPerformanceService` (3 methods: stats, slow endpoints, error hotspots)
- âœ… 3 REST API endpoints (`/performance/endpoints`, `/performance/slow-endpoints`, `/performance/error-hotspots`)
- âœ… Endpoint normalization (UUIDs â†’ :uuid, IDs â†’ :id, hashes â†’ :hash)
- âœ… UI Table: 20 endpoints avec P50/P95/P99, error rate, RPS
- âœ… UI Panel: "Slow Endpoints" avec impact calculation (time wasted/hour)
- âœ… Color-coding dynamique (latency + error rate)
- âœ… SÃ©lecteur pÃ©riode (1h/24h/7d)
- âœ… Auto-refresh 10s intÃ©grÃ©

**Acceptance**:
- [x] AgrÃ©gation depuis `metrics` table (PERCENTILE_CONT)
- [x] UI: Table triable (endpoint, method, latency, errors)
- [x] Endpoint normalization middleware
- [x] Slow endpoints panel avec impact calculation
- [x] Query performance < 50ms âœ…
- [x] 250+ mÃ©triques analysÃ©es

**Files**:
- `api/services/endpoint_performance_service.py` (NEW, 313 LOC)
- `api/routes/monitoring_routes_advanced.py` (+142 LOC)
- `api/middleware/metrics_middleware.py` (+48 LOC)
- `api/dependencies.py` (+28 LOC)
- `templates/monitoring_advanced.html` (+273 LOC)

**Voir**: `EPIC-22_STORY_22.5_COMPLETION_REPORT.md`

---

#### âœ… Story 22.6: Request Tracing (2 pts)
**Status**: âœ… Completed (2025-10-24)
**Objectif**: trace_id end-to-end cliquable
**DurÃ©e**: 2h (design + implementation + testing + documentation)

**Features Delivered**:
- âœ… contextvars-based trace_id propagation (zero boilerplate)
- âœ… Clickable trace_id badges in logs UI (ğŸ” a1b2c3d4)
- âœ… Filter by trace_id with live match indicator
- âœ… X-Trace-ID header in all responses
- âœ… LogsBuffer integration with trace_id in metadata
- âœ… YAGNI: Timeline visualization deferred (single service, no distributed tracing need)

**Acceptance**:
- [x] Tous logs ont trace_id (via structlog processor)
- [x] UI: trace_id cliquable dans logs stream
- [x] Filter input + clear button + match count
- [x] Auto-filter new logs when filter active

**Files**:
- `api/utils/logging_config.py` (NEW, 95 LOC)
- `api/main.py` (+3 LOC - configure_logging call)
- `api/middleware/metrics_middleware.py` (+3 LOC - contextvars.set)
- `templates/monitoring_advanced.html` (+172 LOC - UI badges & filter)

**Voir**: `EPIC-22_STORY_22.6_COMPLETION_REPORT.md`

---

#### â³ Story 22.7: Smart Alerting (1 pt)
**Status**: â³ Not Started
**Objectif**: Alertes automatiques seuils

**Features**:
- Service AlertingService (check thresholds)
- Table `alerts` (id, type, severity, message, ack)
- Endpoint `/api/monitoring/alerts`
- UI: Badge navbar (count alerts)
- Modal alerts avec acknowledge

**Seuils**:
- Cache hit rate < 70% â†’ Warning
- Memory > 80% â†’ Critical
- Slow queries > 1s â†’ Warning
- Evictions > 100/h â†’ Info
- Error rate > 5% â†’ Critical

**Acceptance**:
- [ ] Alertes crÃ©Ã©es automatiquement (background task 1min)
- [ ] UI badge + modal
- [ ] Acknowledge â†’ archivage

---

### ğŸ”µ Phase 3: Nice-to-Have (8 pts) - â¸ï¸ **YAGNI**

Stories 22.8-22.12:
- Historical Trends (comparaison temporelle)
- Slow Query Explain Auto
- Export & Reporting (CSV/JSON)
- Prometheus Export (optionnel)
- Anomaly Detection (ML simple)

**DÃ©cision**: Reporter aprÃ¨s Phase 2 validÃ©e

---

## ğŸ“Š MÃ©triques ClÃ©s (Ã‰tat Actuel)

D'aprÃ¨s `/api/monitoring/advanced/summary` (2025-10-24):

**API**:
- P95 Latency: 108.96ms
- P99 Latency: 115.33ms
- Request count: 158 (derniÃ¨re 1h)
- Throughput: 0.04 req/s
- Error rate: 5.7% (9 errors)

**Redis**:
- Connected: âœ… Yes
- Memory: 1.05 MB / 2048 MB (0.05%)
- Hit rate: 0% (cache vide actuellement)
- Keys: 0
- Evicted: 0

**PostgreSQL**:
- Connections: 6 / 100 (1 active, 5 idle)
- Cache hit ratio: 95.36% âœ…
- DB size: 26.11 MB
- Slow queries (>100ms): 58

**System**:
- CPU: 15% (16 cores)
- Memory: 73.4% (38.7 GB / 58 GB)
- Disk: 81.8% (728 GB / 937 GB)

---

## ğŸ¨ UI Design (SCADA Theme)

Dashboard `/ui/monitoring/advanced`:
- **Status Banner**: ğŸŸ¢ Operational | Auto-refresh toggle
- **KPI Grid**: 6 cards (API, Redis, PostgreSQL, CPU, Memory, RPS)
- **Charts Grid**: 4 ECharts (Latency, Redis Memory, PG Connections, Resources)
- **Metrics Table**: Detailed breakdown avec status colors
- **Logs Stream**: SSE real-time avec filtres

**Theme**: GitHub Dark + SCADA Industrial (zero rounded corners, monospace fonts, cyan/green accents)

---

## ğŸ”— Fichiers ClÃ©s

### Backend
```
api/
â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ metrics_middleware.py          # Auto-record latency + trace_id
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ monitoring_routes_advanced.py  # /api/monitoring/advanced/*
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ metrics_collector.py           # Collect from PostgreSQL/Redis/System
â”‚   â””â”€â”€ logs_buffer.py                 # Circular buffer for SSE
db/migrations/
â””â”€â”€ v5_to_v6_metrics_table.sql         # CREATE TABLE metrics
```

### Frontend
```
templates/
â””â”€â”€ monitoring_advanced.html            # Dashboard UI
static/vendor/
â”œâ”€â”€ echarts.min.js                      # Charts (local)
â”œâ”€â”€ prism*.js                           # Syntax highlighting (local)
â””â”€â”€ prism-okaidia.min.css               # Prism theme (local)
```

---

## âš ï¸ ConsidÃ©rations Techniques

### Performance Impact
- **MetricsMiddleware overhead**: ~1-2ms par request (async INSERT)
- **Batch inserts** possible si volume Ã©levÃ© (100 metrics/batch)
- **Retention**: 30 jours (cleanup cron job)

### ScalabilitÃ©
- **Single instance** (actuel): âœ… Table `metrics` PostgreSQL suffisante
- **Multi-instance** (futur): â¸ï¸ Besoin Prometheus + shared Redis

### SÃ©curitÃ©
- `/ui/monitoring/advanced` = Admin only (TODO: add auth check)
- API endpoints protÃ©gÃ©s
- Logs: Ne jamais logger passwords/tokens

---

## ğŸ§ª Tests

**Test Coverage**: âœ… **29 passed, 1 skipped** (97% pass rate)

### Routes Tests (20 tests)
**File**: `tests/routes/test_monitoring_routes_advanced.py`
- âœ… GET `/summary` - Metrics aggregation (empty + with data + custom period)
- âœ… GET `/logs/stream` - SSE streaming (1 skipped - infinite stream)
- âœ… GET `/performance/endpoints` - Endpoint stats (empty + with data + limit)
- âœ… GET `/performance/slow-endpoints` - Slow endpoint detection (threshold validation)
- âœ… GET `/performance/error-hotspots` - Error analysis
- âœ… GET `/alerts` - Alerts retrieval (empty + unacknowledged + limit)
- âœ… GET `/alerts/counts` - Alert counts by severity
- âœ… POST `/alerts/{alert_id}/acknowledge` - Alert acknowledgment (success + not found + invalid UUID)
- âœ… Parameter validation tests (period_hours, threshold_ms)

### Service Tests (7 tests)
**MetricsCollector** (`tests/services/test_metrics_collector.py` - 2 tests):
- âœ… collect_all() via endpoint (API + Redis + PostgreSQL + System)
- âœ… Custom period_hours filtering

**EndpointPerformanceService** (`tests/services/test_endpoint_performance_service.py` - 3 tests):
- âœ… Endpoint stats aggregation
- âœ… Slow endpoints detection with impact calculation
- âœ… Error hotspots analysis

**MonitoringAlertService** (`tests/services/test_monitoring_alert_service.py` - 2 tests):
- âœ… Alert retrieval
- âœ… Alert counts by severity

### Middleware Tests (2 tests)
**MetricsMiddleware** (`tests/middleware/test_metrics_middleware.py`):
- âœ… X-Trace-ID header injection
- âœ… Request metrics recording to PostgreSQL

### Test Infrastructure
**Setup**:
- âœ… `conftest.py` updated with `metrics` and `alerts` table cleanup
- âœ… PostgreSQL test DB migrations applied (v5â†’v6 metrics, v6â†’v7 alerts)
- âœ… Helper fixtures for inserting test data (asyncpg raw connection)
- âœ… All tests use `EMBEDDING_MODE=mock` for speed

**Coverage Areas**:
- âœ… All 8 monitoring endpoints tested
- âœ… Metrics collection (API, Redis, PostgreSQL, System)
- âœ… Performance analysis by endpoint
- âœ… Alert system (creation, retrieval, acknowledgment)
- âœ… Middleware tracing and recording
- â¸ï¸ SSE streaming (skipped - requires timeout handling)
- â¸ï¸ UI (manual testing only)

---

## ğŸ“ˆ Timeline & Effort

| Phase | Stories | Points | DurÃ©e EstimÃ©e | DurÃ©e RÃ©elle | Status |
|-------|---------|--------|---------------|--------------|--------|
| Phase 1: MVP | 22.1-22.3 | 5 pts | 5 jours | 3 jours âš¡ | âœ… Done |
| Phase 2: Standard | 22.5-22.7 | 6 pts | 4 jours | 0.5 jour (partial) | ğŸŸ¡ In Progress (50%) |
| Phase 3: Nice-to-Have | 22.4, 22.8-22.12 | 8 pts | 6 jours | - | â¸ï¸ YAGNI |
| **Total** | 11 stories | **19 pts** | **15 jours** | **3.5 jours** | **42% done** |

**Notes**:
- Story 22.4 (Redis breakdown) deferred to Phase 3 (YAGNI - no current need)
- Phase 1 delivered 40% faster than estimated (3 days vs 5 days)
- Phase 2 Story 22.5 delivered 28% faster (3.25h vs 4.5h)

**Velocity**: 8 pts / 3.5 days = **2.29 pts/day** (excellent)

---

## ğŸ¯ Prochaines Ã‰tapes

### ImmÃ©diat (Phase 2)
1. **Story 22.4**: Redis breakdown par cache type
2. **Story 22.5**: API performance par endpoint (P95 heatmap)
3. **Story 22.6**: Request tracing cliquable
4. **Story 22.7**: Smart alerting

### Nice-to-Have (Phase 3)
- Attendre validation Phase 2
- Ã‰valuer besoin rÃ©el (YAGNI test)

---

## ğŸ“š Documentation

- **Design**: `EPIC-22_OBSERVABILITY_ULTRATHINK.md`
- **Implementation**: `EPIC-22_PHASE_1_IMPLEMENTATION_ULTRATHINK.md`
- **Phase 1 Summary**: `EPIC-22_PHASE_1_COMPLETION_REPORT.md`
- **Phase 1 Story Reports**:
  - `EPIC-22_STORY_22.1_COMPLETION_REPORT.md` (Metrics Infrastructure)
  - `EPIC-22_STORY_22.2_COMPLETION_REPORT.md` (Dashboard UI)
  - `EPIC-22_STORY_22.3_COMPLETION_REPORT.md` (Logs Streaming)
- **Phase 2 Story Reports**:
  - `EPIC-22_STORY_22.4_ULTRATHINK.md` (Redis Monitoring - SKIPPED)
  - `EPIC-22_STORY_22.5_ULTRATHINK.md` (API Performance - Design)
  - `EPIC-22_STORY_22.5_COMPLETION_REPORT.md` (API Performance - Completed âœ…)

---

## âœ… Acceptance Criteria (Phase 1)

### Global
- [x] Dashboard `/ui/monitoring/advanced` accessible et fonctionnel
- [x] MÃ©triques temps rÃ©el (auto-refresh 10s)
- [x] Logs streaming SSE connectÃ©
- [x] Zero dÃ©pendances externes (pas de Prometheus/Grafana)
- [x] SCADA theme cohÃ©rent
- [x] Assets locaux (echarts, prism)

### MÃ©triques
- [x] Table `metrics` crÃ©Ã©e avec indexes
- [x] API latency enregistrÃ©e automatiquement
- [x] trace_id dans tous headers/logs
- [x] AgrÃ©gation P50/P95/P99 fonctionnelle
- [x] Redis/PostgreSQL/System metrics collectÃ©s

### UI/UX
- [x] KPI cards affichent valeurs rÃ©elles
- [x] Charts ECharts initialisÃ©s et mis Ã  jour
- [x] Logs stream affiche logs temps rÃ©el
- [x] Filtres logs fonctionnels
- [x] Auto-scroll activable

---

**CrÃ©Ã©**: 2025-10-24
**DerniÃ¨re mise Ã  jour**: 2025-10-30 (Test coverage complete)
**Auteur**: Claude Code + User
**Status**: Phase 1 âœ… Complete | Phase 2 â³ Pending | Tests âœ… Complete (29/30)
**Version**: 1.1.0
