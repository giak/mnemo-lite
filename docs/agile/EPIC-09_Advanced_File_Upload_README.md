# EPIC-09: Advanced File Upload & Batch Processing

**Version**: 1.0.0
**Date**: 2025-10-17
**Status**: ğŸš§ **PROPOSED** (0/35 pts)
**Dependencies**: âœ… EPIC-07 (UI Infrastructure)

---

## ğŸ“š Documentation Structure

```
EPIC-09/
â”œâ”€ EPIC-09_Advanced_File_Upload_README.md  â† VOUS ÃŠTES ICI (point d'entrÃ©e)
â”œâ”€ STORIES_EPIC-09_Upload.md               (Detailed user stories)
â””â”€ EPIC-09_COMPLETION_REPORT.md            (Future: implementation results)
```

---

## ğŸ¯ Executive Summary (2 min)

### Le ProblÃ¨me Actuel

L'interface actuelle ne supporte que l'upload **fichier par fichier**. Pour indexer un projet entier, l'utilisateur doit :
- SÃ©lectionner manuellement chaque fichier ğŸ˜±
- Pas de support pour les dossiers avec parcours rÃ©cursif
- Pas de support pour les archives ZIP contenant des codebases complÃ¨tes
- Pas de support pour git clone
- Processus fastidieux et error-prone

**Cas d'usage critiques non supportÃ©s** :
1. **Glisser-dÃ©poser un dossier projet complet** â†’ Parcours rÃ©cursif de TOUS les sous-dossiers
2. **Upload d'un ZIP de projet** â†’ Extraction avec prÃ©servation de la structure complÃ¨te

**Impact** : Pour un projet de 1000+ fichiers â†’ Impossible actuellement !

### Vision

Transformer l'upload en un systÃ¨me **intelligent et efficace** capable de traiter :
- ğŸ“ **Dossiers entiers** (rÃ©cursif avec filtres)
- ğŸ—œï¸ **Archives ZIP/TAR**
- ğŸ”— **Git repositories** (clone direct)
- ğŸ“¦ **Batch processing** optimisÃ©
- ğŸ¯ **Smart filtering** (.gitignore aware)

### Principe Fondamental

> "One click to index an entire codebase"

### Valeur MÃ©tier ImmÃ©diate

| Avant | AprÃ¨s | Gain |
|-------|-------|------|
| 100 fichiers = 100 clics | 1 dossier = 1 clic | **100x plus rapide** |
| Pas de ZIP | ZIP upload direct | **Convenience** |
| Pas de git | Git clone URL | **Integration** |
| Manuel uniquement | Automation ready | **Scalability** |

---

## ğŸ—ï¸ Architecture Overview

### Current State (Limitation)
```html
<input type="file" multiple accept=".py,.js,...">
<!-- Ne supporte que des fichiers individuels -->
```

### Target State
```html
<!-- Multiple input modes -->
<input type="file" webkitdirectory>  <!-- Folders -->
<input type="file" accept=".zip,.tar.gz">  <!-- Archives -->
<input type="url" placeholder="https://github.com/...">  <!-- Git -->
```

### Processing Pipeline
```
Upload Sources â†’ Filter & Validate â†’ Extract & Parse â†’ Batch Process â†’ Index
      â†“              â†“                   â†“                â†“            â†“
   Folder         .gitignore          Unzip/Clone      Queue       Database
   ZIP/TAR        Extensions          Tree-walk        Chunking    Storage
   Git URL        Size limits         Encoding         Progress    Graph
```

---

## ğŸ”„ Architecture UnifiÃ©e: Convergence Folder & ZIP

Les deux modes principaux (Dossier RÃ©cursif et ZIP) convergent vers le mÃªme pipeline de traitement :

### Pipeline Convergent
```
[Dossier RÃ©cursif] â”€â”€â”
                      â”œâ”€â”€â†’ [Structure Tree] â†’ [Smart Filter] â†’ [Preview UI] â†’ [Batch Process] â†’ [Index]
[ZIP Upload] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Structure de DonnÃ©es UnifiÃ©e
```typescript
interface ProjectStructure {
  name: string;
  type: 'root' | 'folder' | 'file';
  path: string;  // Chemin relatif prÃ©servÃ© depuis la racine
  children?: Map<string, ProjectStructure>;

  // Pour les fichiers
  content?: string | ArrayBuffer | LazyLoader;
  size?: number;
  language?: string;
  selected?: boolean;

  // MÃ©tadonnÃ©es projet
  stats?: {
    totalFiles: number;
    totalSize: number;
    selectedFiles: number;
    selectedSize: number;
    languages: Set<string>;
    depth: number;  // Profondeur max de l'arbre
    projectType?: 'node' | 'python' | 'java' | 'unknown';
  };
}
```

### Points de Convergence
| Aspect | Dossier RÃ©cursif | ZIP Upload | RÃ©sultat UnifiÃ© |
|--------|------------------|------------|-----------------|
| **Structure** | Parcours rÃ©cursif complet | Extraction avec hiÃ©rarchie | Arbre identique |
| **Filtrage** | .gitignore + smart filter | MÃªme filtres dans ZIP | Fichiers pertinents |
| **Preview** | Tree view interactive | Tree view identique | UX cohÃ©rente |
| **Performance** | Chunking + Workers | Streaming + Workers | Scalable |
| **MÃ©moire** | IndexedDB cache | Extraction lazy | OptimisÃ© |

---

## ğŸ“Š Stories Overview (35 points total)

### Phase 1: Core Upload Capabilities (15 pts)

#### Story 1: Recursive Folder Upload with Complete Structure (8 pts) â­ CRITICAL
**Goal**: Support rÃ©cursif COMPLET des dossiers avec prÃ©servation de la structure

**Use Case Principal**:
```bash
# User glisse son projet entier
my-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/    # 234 fichiers
â”‚   â”œâ”€â”€ services/      # 156 fichiers
â”‚   â””â”€â”€ utils/         # 89 fichiers
â”œâ”€â”€ tests/             # 456 fichiers
â””â”€â”€ docs/              # 234 fichiers
# â†’ TOUT est parcouru rÃ©cursivement et indexÃ© avec structure prÃ©servÃ©e
```

**Acceptance Criteria**:
- [ ] Upload de dossiers entiers via drag & drop
- [ ] Parcours rÃ©cursif COMPLET de TOUS les sous-dossiers
- [ ] Conservation intÃ©grale de la structure des chemins
- [ ] Filtrage intelligent automatique (.gitignore, node_modules, etc.)
- [ ] Progress bar avec dÃ©tails par dossier
- [ ] Support jusqu'Ã  10,000+ fichiers avec chunking
- [ ] Preview en arbre avant validation
- [ ] Web Workers pour ne pas bloquer l'UI

**Technical Implementation AvancÃ©e**:
```javascript
// Parcours rÃ©cursif COMPLET avec Web Workers
async function traverseDirectoryRecursive(dirHandle, basePath = '') {
  const files = [];

  for await (const entry of dirHandle.values()) {
    const path = basePath ? `${basePath}/${entry.name}` : entry.name;

    if (entry.kind === 'file') {
      const file = await entry.getFile();
      // PrÃ©server le chemin complet
      files.push({
        path: path,
        file: file,
        size: file.size,
        modified: file.lastModified,
        relativePath: path  // Critique pour reconstruction
      });
    } else if (entry.kind === 'directory') {
      // RÃ‰CURSIF - descendre dans TOUS les sous-dossiers
      const subFiles = await traverseDirectoryRecursive(entry, path);
      files.push(...subFiles);
    }
  }

  return files;
}

// Smart filtering intÃ©grÃ©
const smartFilter = {
  autoExclude: [
    'node_modules/**',
    '.git/**',
    '**/.DS_Store',
    '**/__pycache__/**',
    'dist/**',
    'build/**',
    '.env*'
  ],
  maxFileSize: 10 * 1024 * 1024, // 10MB par fichier
  includeOnly: ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.go', '.rs']
};

// Chunked processing pour gros projets
class ChunkedProcessor {
  async processLargeProject(files) {
    const CHUNK_SIZE = 100;
    const chunks = [];

    for (let i = 0; i < files.length; i += CHUNK_SIZE) {
      chunks.push(files.slice(i, i + CHUNK_SIZE));
    }

    for (const chunk of chunks) {
      await this.processChunk(chunk);
      this.updateProgress(chunks.indexOf(chunk) / chunks.length * 100);
    }
  }
}
```

**DÃ©fis & Solutions**:
| DÃ©fi | Solution |
|------|----------|
| WebKit API limitÃ©e | Fallback pour autres browsers |
| 10k+ fichiers | Streaming + chunking |
| Performance | Web Workers + virtual scrolling |
| MÃ©moire | IndexedDB pour cache temporaire |

---

#### Story 2: Complete Codebase ZIP Upload with Structure Preservation (7 pts) â­ CRITICAL
**Goal**: Upload et extraction d'archives ZIP contenant des codebases complÃ¨tes

**Use Case Principal**:
```bash
# DÃ©veloppeur crÃ©e un ZIP de son projet
cd my-awesome-project/
zip -r project.zip . -x "node_modules/*" ".git/*" "*.pyc"
# Taille: 98MB, 2847 fichiers, structure complÃ¨te prÃ©servÃ©e
# â†’ Upload ce ZIP â†’ MnemoLite extrait et indexe TOUT avec structure
```

**Acceptance Criteria**:
- [ ] Support ZIP contenant des projets complets (jusqu'Ã  500MB)
- [ ] Extraction cÃ´tÃ© client avec prÃ©servation COMPLÃˆTE de la structure
- [ ] Preview en arbre du contenu ENTIER avant import
- [ ] Reconnaissance automatique de la structure (package.json, requirements.txt, etc.)
- [ ] Filtrage intelligent mÃªme dans le ZIP
- [ ] Gestion des encodages (UTF-8, Latin-1, etc.)
- [ ] Support streaming pour gros ZIP
- [ ] Validation CRC32 pour intÃ©gritÃ©

**Technical Implementation - ZIP avec Structure ComplÃ¨te**:
```javascript
async function processZipWithFullStructure(zipFile) {
  const zip = new JSZip();

  // Load avec streaming pour gros fichiers
  const contents = await zip.loadAsync(zipFile, {
    streamFiles: true,
    onProgress: (metadata) => updateProgress(metadata.percent)
  });

  // Construire l'arbre COMPLET du projet
  const projectStructure = {
    name: zipFile.name.replace('.zip', ''),
    type: 'root',
    children: {},
    stats: {
      totalFiles: 0,
      totalSize: 0,
      languages: new Set(),
      depth: 0
    }
  };

  // Parcourir TOUS les fichiers du ZIP
  for (let [fullPath, zipEntry] of Object.entries(contents.files)) {
    if (!zipEntry.dir) {
      // Reconstituer la hiÃ©rarchie complÃ¨te
      const pathParts = fullPath.split('/');
      let currentLevel = projectStructure.children;

      // CrÃ©er tous les dossiers parents
      for (let i = 0; i < pathParts.length - 1; i++) {
        const folderName = pathParts[i];
        if (!currentLevel[folderName]) {
          currentLevel[folderName] = {
            name: folderName,
            type: 'folder',
            children: {},
            selected: true,
            path: pathParts.slice(0, i + 1).join('/')
          };
        }
        currentLevel = currentLevel[folderName].children;
      }

      // Ajouter le fichier avec mÃ©tadonnÃ©es
      const fileName = pathParts[pathParts.length - 1];
      const language = detectLanguage(fileName);
      const shouldInclude = smartFilter.shouldInclude(fullPath);

      currentLevel[fileName] = {
        name: fileName,
        type: 'file',
        path: fullPath,
        size: zipEntry._data?.uncompressedSize || 0,
        compressed: zipEntry._data?.compressedSize || 0,
        language: language,
        selected: shouldInclude,
        zipEntry: zipEntry  // Pour extraction lazy
      };

      // Stats globales
      projectStructure.stats.totalFiles++;
      projectStructure.stats.totalSize += currentLevel[fileName].size;
      if (language) projectStructure.stats.languages.add(language);
      projectStructure.stats.depth = Math.max(projectStructure.stats.depth, pathParts.length);
    }
  }

  return projectStructure;
}

// Extraction sÃ©lective avec progress
async function extractSelectedFiles(projectStructure, selectedPaths) {
  const extractedFiles = [];
  const total = selectedPaths.length;
  let processed = 0;

  for (const path of selectedPaths) {
    const file = findFileInStructure(projectStructure, path);
    if (file?.zipEntry) {
      const content = await file.zipEntry.async('string');
      extractedFiles.push({
        path: file.path,
        content: content,
        language: file.language,
        size: file.size
      });

      processed++;
      updateProgress((processed / total) * 100);
    }
  }

  return extractedFiles;
}
```

**Preview UI pour ZIP de Projet Complet**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¦ project.zip (2,847 files, 98.5 MB)            â”‚
â”‚ Detected: Node.js project (package.json found)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Project Structure:                                â”‚
â”‚                                                   â”‚
â”‚ â–¼ ğŸ“ my-awesome-project/          [âœ“] 2.8k files â”‚
â”‚   â–¼ ğŸ“ src/                       [âœ“] 1.2k      â”‚
â”‚     â–¼ ğŸ“ components/              [âœ“] 234       â”‚
â”‚       ğŸ“„ Button.tsx               [âœ“] 12KB      â”‚
â”‚       ğŸ“„ Modal.tsx                [âœ“] 8KB       â”‚
â”‚     â–¶ ğŸ“ services/               [âœ“] 156       â”‚
â”‚     â–¶ ğŸ“ utils/                  [âœ“] 89        â”‚
â”‚   â–¼ ğŸ“ tests/                    [?] 456       â”‚
â”‚   â–¶ ğŸ“ docs/                     [âœ“] 234       â”‚
â”‚   ğŸ“„ package.json                [âœ“] 2KB       â”‚
â”‚   ğŸ“„ README.md                   [âœ“] 15KB      â”‚
â”‚   ğŸ“„ tsconfig.json               [âœ“] 1KB       â”‚
â”‚                                                   â”‚
â”‚ Auto-excluded (in ZIP but filtered):             â”‚
â”‚ âŒ node_modules/ (would be 35k files)            â”‚
â”‚ âŒ .git/ (would be 1.2k files)                   â”‚
â”‚ âŒ dist/ (would be 456 files)                    â”‚
â”‚                                                   â”‚
â”‚ Languages detected: TypeScript, JavaScript, JSON  â”‚
â”‚ Selected: 1,847 / 2,847 files (45.3 MB)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [âŒ Cancel]                   [ğŸš€ Start Import]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DÃ©fis SpÃ©cifiques ZIP & Solutions**:
| DÃ©fi | Impact | Solution |
|------|--------|----------|
| ZIP de 500MB+ | Out of memory | Streaming extraction avec JSZip |
| Structure complexe | Perte hiÃ©rarchie | Reconstruction complÃ¨te de l'arbre |
| Encodage mixte | CaractÃ¨res cassÃ©s | DÃ©tection auto + conversion UTF-8 |
| ZIP corrompu | Crash | Validation CRC32 avant extraction |
| Gros fichiers dans ZIP | Blocage UI | Extraction lazy + Web Workers |

---

### Phase 2: Advanced Features (12 pts)

#### Story 3: Git Repository Import (5 pts)
**Goal**: Clone et import depuis URL Git

**Acceptance Criteria**:
- [ ] Support GitHub/GitLab/Bitbucket URLs
- [ ] Clone shallow (--depth=1)
- [ ] Branch selection
- [ ] Private repos avec token
- [ ] .gitignore respect

**API Endpoint**:
```python
POST /v1/code/import/git
{
  "url": "https://github.com/user/repo.git",
  "branch": "main",
  "token": "optional_for_private",
  "shallow": true
}
```

---

#### Story 4: Smart Filtering System (4 pts)
**Goal**: Filtrage intelligent des fichiers

**Features**:
- [ ] .gitignore parsing et respect
- [ ] Custom ignore patterns
- [ ] File size limits
- [ ] Binary file detection
- [ ] Duplicate detection
- [ ] Language auto-detection

**Configuration**:
```javascript
const filterConfig = {
  respectGitignore: true,
  maxFileSize: "10MB",
  excludePatterns: ["node_modules/**", "*.min.js"],
  includeOnly: [".py", ".js", ".ts"],
  excludeBinary: true,
  detectDuplicates: true
};
```

---

#### Story 5: Batch Processing Optimization (3 pts)
**Goal**: Traitement optimisÃ© par batch

**Acceptance Criteria**:
- [ ] Queue de traitement avec prioritÃ©s
- [ ] Chunking adaptatif (10-100 fichiers/batch)
- [ ] Parallel processing (Web Workers)
- [ ] Retry mechanism
- [ ] Partial failure handling

---

### Phase 3: UI/UX Enhancements (8 pts)

#### Story 6: Enhanced Upload UI (4 pts)
**Goal**: Interface amÃ©liorÃ©e multi-mode

**Features**:
- [ ] Tabs pour modes (Files/Folder/ZIP/Git)
- [ ] Drag & drop zone intelligente
- [ ] File tree preview
- [ ] SÃ©lection/dÃ©sÃ©lection en masse
- [ ] Search/filter dans la preview

**Mockup**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¤ Upload Code                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Files] [Folder] [ZIP] [Git] [URL]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚     ğŸ“ Drop folder or click         â”‚
â”‚        to browse                    â”‚
â”‚                                     â”‚
â”‚   âœ“ Include subfolders             â”‚
â”‚   âœ“ Respect .gitignore             â”‚
â”‚   â–¡ Include tests                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Files to upload (247 found):       â”‚
â”‚ â–¼ src/                   [âœ“]       â”‚
â”‚   â–¼ components/          [âœ“]       â”‚
â”‚     â–  Button.tsx         [âœ“]       â”‚
â”‚     â–  Modal.tsx          [âœ“]       â”‚
â”‚   â–¶ utils/              [âœ“]       â”‚
â”‚ â–¶ tests/                [â–¡]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### Story 7: Progress & Monitoring (2 pts)
**Goal**: Feedback dÃ©taillÃ© du progress

**Features**:
- [ ] Real-time progress par fichier
- [ ] ETA calculation
- [ ] Pause/Resume capability
- [ ] Error reporting inline
- [ ] Success/failure summary

---

#### Story 8: Bulk Operations (2 pts)
**Goal**: OpÃ©rations en masse post-upload

**Features**:
- [ ] Select all/none
- [ ] Filter by status
- [ ] Bulk retry failed
- [ ] Bulk delete
- [ ] Export results

---

## ğŸ¯ Technical Implementation Details

### Frontend Changes

#### 1. Multi-mode Upload Component
```typescript
interface UploadMode {
  files: FileUploadHandler;
  folder: FolderUploadHandler;
  archive: ArchiveUploadHandler;
  git: GitImportHandler;
  url: URLFetchHandler;
}

class AdvancedUploader {
  private mode: keyof UploadMode;
  private filters: FilterConfig;
  private queue: UploadQueue;

  async processUpload(input: UploadInput): Promise<UploadResult> {
    const files = await this.extractFiles(input);
    const filtered = await this.applyFilters(files);
    const batches = this.createBatches(filtered);
    return await this.processBatches(batches);
  }
}
```

#### 2. File Tree Component
```typescript
interface FileTreeNode {
  name: string;
  path: string;
  type: 'file' | 'folder';
  selected: boolean;
  children?: FileTreeNode[];
  size?: number;
  language?: string;
}
```

### Backend Changes

#### 1. New Endpoints
```python
# Folder upload
POST /v1/code/upload/folder
Content-Type: multipart/form-data

# Archive upload
POST /v1/code/upload/archive
Content-Type: multipart/form-data

# Git import
POST /v1/code/import/git
{
  "url": "...",
  "branch": "main"
}

# Batch status
GET /v1/code/upload/batch/{batch_id}/status
```

#### 2. Batch Processing Service
```python
class BatchProcessingService:
    def __init__(self, concurrency: int = 5):
        self.queue = asyncio.Queue()
        self.workers = []
        self.concurrency = concurrency

    async def process_batch(
        self,
        files: List[FileInput],
        options: BatchOptions
    ) -> BatchResult:
        # Chunking
        chunks = self.create_chunks(files, options.chunk_size)

        # Queue processing
        tasks = []
        for chunk in chunks:
            task = self.queue.put(chunk)
            tasks.append(task)

        # Wait for completion
        results = await asyncio.gather(*tasks)
        return self.merge_results(results)
```

### Database Schema

```sql
-- Batch tracking
CREATE TABLE upload_batches (
    id UUID PRIMARY KEY,
    user_id UUID,
    upload_type VARCHAR(20), -- 'folder', 'archive', 'git'
    total_files INT,
    processed_files INT,
    failed_files INT,
    status VARCHAR(20), -- 'pending', 'processing', 'completed', 'failed'
    started_at TIMESTAMPTZ,
    completed_at TIMESTAMPTZ,
    metadata JSONB
);

-- File processing queue
CREATE TABLE file_queue (
    id UUID PRIMARY KEY,
    batch_id UUID REFERENCES upload_batches(id),
    file_path TEXT,
    status VARCHAR(20),
    error_message TEXT,
    retry_count INT DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

---

## ğŸ“ˆ Expected Outcomes

### Performance Metrics

| Metric | Current | Target | Improvement |
|--------|---------|--------|-------------|
| **Files per operation** | 1-10 | **10,000+** | **1000x** |
| **Time to index project** | Impossible (>1000 files) | **< 2 min** | **âˆ** |
| **User clicks required** | 1000+ (1 per file) | **1** | **99.9% reduction** |
| **Structure preservation** | None | **100%** | **Complete** |
| **ZIP support** | 0 | **500MB projects** | **Game changer** |
| **Folder recursion** | 0 | **Unlimited depth** | **Critical** |
| **Success rate** | 95% | **99.9%** | **Near perfect** |

### User Experience Transformation

| Scenario | Before | After |
|----------|--------|-------|
| **Upload React project (2000 files)** | "Impossible, j'abandonne" | "Glisser-dÃ©poser â†’ 30s â†’ Done!" |
| **Import from ZIP backup** | "Pas supportÃ©" | "Upload ZIP â†’ Preview â†’ Import" |
| **Preserve folder structure** | "Tout aplati" | "Structure complÃ¨te prÃ©servÃ©e" |
| **Filter unwanted files** | "Manuel file by file" | "Auto-filter + preview" |

---

## âš ï¸ Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Browser memory limits | HIGH | Streaming processing, chunking |
| Large archives | MEDIUM | Size limits, server-side processing option |
| Git rate limits | LOW | Caching, token rotation |
| Network failures | MEDIUM | Resume capability, retry logic |

---

## ğŸš€ Implementation Roadmap

### Week 1: Foundation
- [ ] Folder upload (Story 1)
- [ ] Basic filtering (Story 4 partial)

### Week 2: Archives & Git
- [ ] ZIP support (Story 2)
- [ ] Git import (Story 3)

### Week 3: Optimization
- [ ] Batch processing (Story 5)
- [ ] Advanced filtering (Story 4 complete)

### Week 4: Polish
- [ ] Enhanced UI (Story 6)
- [ ] Progress monitoring (Story 7)
- [ ] Bulk operations (Story 8)

---

## ğŸ“Š Story Points Summary

| Phase | Stories | Points | Priority |
|-------|---------|--------|----------|
| **Phase 1** | Core Upload (2 stories) | 15 pts | CRITICAL |
| **Phase 2** | Advanced Features (3 stories) | 12 pts | HIGH |
| **Phase 3** | UI/UX (3 stories) | 8 pts | MEDIUM |
| **TOTAL** | **8 stories** | **35 pts** | **HIGH** |

---

## ğŸ“ Success Criteria

- [ ] Support folder upload with 1000+ files
- [ ] Support ZIP files up to 500MB
- [ ] Git import functional
- [ ] Processing time <30s for 100 files
- [ ] UI intuitive (user test score >4/5)
- [ ] 99% success rate
- [ ] Documentation complete

---

## ğŸ“ Notes

Cette EPIC rÃ©pond Ã  un besoin **CRITIQUE** et **BLOQUANT** : sans la capacitÃ© d'uploader des projets complets (dossiers rÃ©cursifs ou ZIP), MnemoLite est **inutilisable pour des vrais projets**.

### Pourquoi c'est CRITIQUE

| Sans cette EPIC | Avec cette EPIC |
|-----------------|-----------------|
| âŒ Max 10-20 fichiers rÃ©aliste | âœ… 10,000+ fichiers possible |
| âŒ Perte de structure des dossiers | âœ… Structure complÃ¨te prÃ©servÃ©e |
| âŒ Import manuel fastidieux | âœ… Un clic = projet entier |
| âŒ Pas de ZIP support | âœ… ZIP de projets complets |
| âŒ Adoption limitÃ©e | âœ… Production-ready |

### Impact Business Direct

- **De 0 Ã  Hero**: Passe de "gadget" Ã  "outil professionnel"
- **Adoption x100**: Les dÃ©veloppeurs peuvent VRAIMENT l'utiliser
- **Time to Value**: 30 minutes â†’ 30 secondes pour indexer un projet

**Slogan**: "From files to forests - upload ENTIRE codebases at once!"

âš¡ **Cette EPIC est LA fonctionnalitÃ© qui rend MnemoLite utilisable en production**

---

**Date**: 2025-10-17
**Version**: 1.0.0
**Status**: ğŸš§ **PROPOSED**
**Author**: MnemoLite Team
**Estimated Duration**: 4 weeks
**Business Value**: CRITICAL
**Technical Complexity**: MEDIUM

**Approval**: _Pending_